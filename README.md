Project Title
"Image Captioning with Multilingual Audio Description"

Introduction and model used
This project aims to develop an advanced model that perfectly combines image captioning with audio descriptions, to significantly improve ease for individuals with visual impairments.I also like to compare CNN-LSTM model with Vision-Transformer to findout which model generate contextually relevant and detailed descriptions  
first am implementing cnn-lstm model

Multilingual Audio Description
Use of Google Text-to-Speech (gTTS) for generating audio.
Use of Google Translate for translating captions into different languages.

Metrics used
BLEU and METEOR is used to evaluate the performance of model

Results
Transformer model give better output in predicting quality captions
quality of generated auido by TTS system and translator is reliable, although it depend upon the output of model



