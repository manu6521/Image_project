Introduction
This project aims to develop an advanced model that perfectly combines image captioning with audio descriptions, to significantly improve ease for individuals with visual impairments.I also like to compare CNN-LSTM model with Vision-Transformer to findout which model generate contextually relevant and detailed descriptions  
As the first step i am importing all the required libraries and load the flickr8k dataset
