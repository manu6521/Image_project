{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manu6521/Image_project/blob/main/Hyperparameter_tuning_transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QI9xv79yQGr8",
        "outputId": "f43e7957-03ef-4713-9280-9f1248ab0ed1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-2.21.0-py3-none-any.whl (527 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, pyarrow, dill, multiprocess, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.21.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-17.0.0 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgDyoTkKsZ6c",
        "outputId": "4c20eb54-2942-4104-bd77-9aa569d270d6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOXdLxXw1IGo",
        "outputId": "92f3db27-007b-4056-de53-001f3a71e16a",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.21.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.15.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgXhUNxhijsk",
        "outputId": "c7a0c264-1e22-45bf-fcaf-2f075f898afe",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.5)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=6687a2e6dc424073120ddef9c20a274ef8d80c0d2f0a66e704e4add6969a1c69\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuJK9L9-sk10",
        "outputId": "bdaff1e9-b72a-4804-f845-3e9200c3d200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQGktsZ5ZUSJ"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvDqSbNCX3xh",
        "outputId": "cd8f04e5-840e-47ac-e30d-2ad6eda86c99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "an9_z-OAVGoY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import datasets\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n",
        "import multiprocessing as mp\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import io, transforms\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from transformers import Seq2SeqTrainer ,Seq2SeqTrainingArguments\n",
        "from transformers import VisionEncoderDecoderModel , ViTFeatureExtractor\n",
        "from transformers import AutoTokenizer ,  GPT2Config , default_data_collator\n",
        "\n",
        "# if torch.cuda.is_available():\n",
        "\n",
        "#     device = torch.device(\"cuda\")\n",
        "\n",
        "#     print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "#     print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# else:\n",
        "#     print('No GPU available, using the CPU instead.')\n",
        "#     device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import VisionEncoderDecoderModel, AutoTokenizer, AutoFeatureExtractor\n",
        "\n",
        "image_encoder_model = \"google/vit-base-patch16-224-in21k\"\n",
        "text_decode_model = \"gpt2\"\n",
        "\n",
        "# model = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(\n",
        "#     image_encoder_model, text_decode_model)"
      ],
      "metadata": {
        "id": "ZtvSPgeIdxOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image feature extractor\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained(image_encoder_model)\n",
        "# text tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(text_decode_model, add_prefix_space=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400,
          "referenced_widgets": [
            "c8346a9659944bc1a3109afb2aa2f87b",
            "c48ce7cf38f54226b8e35c1789833d64",
            "aaf79cdd42df4185abf020b5e85cc76b",
            "7ac5b96c5a3c440aad5eb6758ba8deee",
            "b7121f214a744050ae80fc24c55abb22",
            "387b30bf21ed4b00ac797cfe707a607b",
            "3e1a1c881bf94657bca5a56bee3bc852",
            "564849fcfd2a44ae98bb20353cef71b1",
            "922a0e13a12540fc8410fe8caa8e5f83",
            "761fa8061df649368c9b2e091652af02",
            "1ad57d58fa62484a817266101d2e4d8f",
            "6e3693a08c0b42ff8e1a099ced150438",
            "895400a9df9b47889683135da9cbf0b7",
            "2e2416d3315d46a4a30917240872a349",
            "130b39ba133640069ecd06d848dc629a",
            "dfe71389b6c049b5b1db88d8d3a74fca",
            "ad62f344c44e43a18d93d153a93f0e60",
            "854fdd49fd0141e285514bd68f061453",
            "1fc3423cd3174fc1951626d4bb2d64b9",
            "0cc7ffc991e242ed9551ecdd1b0527cc",
            "5ae0dd9eb5834702b82b1a3a7a778b29",
            "d236a93f9a2746b8aeb41015ff7ef785",
            "86c2b76bd0a8465b8c9e052e5955e52d",
            "250c413a71164457be7d6c398ee63790",
            "ca666bca40ed4fdca9d8e8a739484098",
            "2de809244c3c4c36bdf9df2ae698f0dc",
            "dbfb243092ed4a0eb41a56ed43d9f61d",
            "8c2d874aaa3a4c0dac7aedd795be5204",
            "e2d9567aa8bd45829a69faa10002fb9a",
            "669cdd83fd65459496814ac4e52d8aac",
            "9155d02fb82a4e408ecff170a6073725",
            "45ac68c0175144ea903a65262007c53e",
            "6859e3ae303d4d72abfa523d2094361f",
            "b035b1eaafac40ec95395d4fd07dadff",
            "5d2b232290bc4edcb78f6c1ee3de10a6",
            "b9b5c1d60f3c4aedbaa9f763ef97187a",
            "d4729bebe2564e9e9a4de6f9bbe708c4",
            "594d5188c145403c92467dd8dfba80ce",
            "d4cb585e24a44e80aaceedd4798e56a8",
            "3c5457fb7e22442b9bcb625a5b4e48c2",
            "03196e9c428a4aee96369a74c16b71d0",
            "5dd0683d45744bdb830cc2d236ad14f2",
            "783a29d818d34a2190dfb937b0e7356d",
            "14ed875e175846f48860146fb7d04faf",
            "7c95cfa17591425b98763db52d7770a2",
            "3d41adc0bb5249e59c47e277f3c0121a",
            "dbaaa4555377434ea8bb590a93a52acd",
            "5196acf1b3f048309d8887d0edc3429c",
            "c3352947e7b542c7b37ba0eba15047e5",
            "7f82535222764aaea4eca3a6419814c6",
            "2def9644176041019d56971bb4874c13",
            "02760ba510f74517a50d75c7983d85e2",
            "16d31b6b093f4cd781640bb283cc7a81",
            "011794bb501b49e49cd842d178d63be0",
            "1d2936e913f94f648f3c1a8b5a22dbfc",
            "202c200dac944a8ea6d615bd12fed5f9",
            "e3271b5281484b93a97ed2beaee68758",
            "0d7b87708be447ffa6a3da6998477e01",
            "33e9d1caa744492faeff219072d1e93a",
            "2153a1422ee64cd891eff12df43633dc",
            "46512ed135564a13aa2dd46c0887da72",
            "eb46d7d76555484787c309d165272525",
            "36a83fa54d5242f6a670cbc4b967d826",
            "2ba15d6cb64b4d5ea1892e76471fc63d",
            "d2df751346f046a393d4a4e472d9a7af",
            "12cc5252fc324bea8503dd08fbf7ad43",
            "e374fa9ba7ae4ffda8dba6049a0ad69f",
            "b8e0b5596566460490984c23577a8bd1",
            "8a0dd7d0321d47f2ac93aa6dc4df6cd4",
            "4a1dbf3f888e423ab18098076d744c7e",
            "7a7f73b776cd49ad98bb52b8a1c79387",
            "52e0375031cf4991862ebfa9ca2cf71a",
            "a5414aed27e443bca080dbba144b6845",
            "a3f52c910f3a4350b71e79b3f9dbe99a",
            "5c50b215b94941f7b042616373cc792b",
            "0bc5b9b157f94590a08d7e9878a2fcae",
            "1073aaa758454612a4bcf15b0d0cbc3f"
          ]
        },
        "id": "d5jwvCnudykn",
        "outputId": "ebbf31c3-f53f-4cd7-bac7-9edf4e5ddec6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8346a9659944bc1a3109afb2aa2f87b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e3693a08c0b42ff8e1a099ced150438"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86c2b76bd0a8465b8c9e052e5955e52d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b035b1eaafac40ec95395d4fd07dadff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c95cfa17591425b98763db52d7770a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "202c200dac944a8ea6d615bd12fed5f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e374fa9ba7ae4ffda8dba6049a0ad69f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the search space\n",
        "def model_init():\n",
        "    # Load the model\n",
        "    model = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(\n",
        "        image_encoder_model, text_decode_model\n",
        "    )\n",
        "\n",
        "    # Set the decoder_start_token_id, eos_token_id, and pad_token_id attributes\n",
        "    model.config.decoder_start_token_id = tokenizer.bos_token_id\n",
        "    model.config.eos_token_id = tokenizer.eos_token_id\n",
        "    model.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jCwkgFNYbGPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-wlaUFK5xSUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT2 only has bos/eos tokens but not decoder_start/pad tokens\n",
        "if tokenizer.pad_token is None:\n",
        "  tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "VudfH6CBgk9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_DIR = '/content/drive/MyDrive/flicker_final'\n",
        "ds = datasets.load_dataset(\"atasoglu/flickr8k-dataset\", data_dir=data_DIR)"
      ],
      "metadata": {
        "id": "S_j237EMWybO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266,
          "referenced_widgets": [
            "9f67b533d44d4c0bb6ae2352adc3e4e8",
            "504519c4802141a6811973288ce00085",
            "cd67146131cf4b7aa3aa03877020924a",
            "e983649caf9c4c0c838b9314dd37c5b5",
            "02c9312b4e4c4a2b8380ab8c3b0ce6c2",
            "ba0adf6afc9946469e5b7f6151d648f3",
            "7f65b9856e324e19971050d73d0e62b1",
            "46a7b148a8ee43c4ba5cd993523901c3",
            "d1f55904845742379b7b8727b2bc2c0b",
            "100b1f3f94bd4a25ac8b943286102ac9",
            "729261233d504ca58accc1cfde689773",
            "29da2e2812ed4f2c9165b8b1bb403e66",
            "f98a85a885fd4d2ba98988411376ac90",
            "6e92babd9efe4e2895c5a62f12409892",
            "ffcca17bcb4e4ced905eb27efba8f63d",
            "92bcc154ea8f4560841bf65681d0f7a8",
            "522aa4d9dff6458ba324f91d995bec52",
            "8be5fc3a3597498eae789593749a7894",
            "dd55876ec6be488c910101df657a50e3",
            "b45a9af3884a4e6fac1bedad0c6eae63",
            "d83f92c033bc4455ad65a2e65e6a56c7",
            "dc1c4e4389594855955e40c17ee39fcd",
            "04fbb41304be4a1b8716fb5e66a4770d",
            "710d02aedb9945ef803707f215e7374b",
            "51c57c2f59e74d20b169e07bf58da524",
            "45592865abc24e7fb670a628348dc5e3",
            "414abc5860ee4a1e96efe7011f147085",
            "d14556762a5b460c9da32db786c78f20",
            "110c4f36acce4caf83758c8caac6d551",
            "b17112bf1e924677808d8c49a10b4d29",
            "730eccdc87bd443b9cb4cc567ccc843c",
            "7b3b7a166ffa410992ea31b4127592a8",
            "852372aa56f84cf484542603ee76f79c",
            "ad4a3405218e48178a4bad414387aba6",
            "e0834c3ea4204add8546c737fa3742bb",
            "a65cd1b4f72b446dbc344cb0bbeed530",
            "d3cd71a9d2724a17977484a4185ffc30",
            "ed95addafb8744f1933648a141bd25b0",
            "7d2f52a4374a43a091e4d9723230425d",
            "e00f83f0224a46a488520d09fc1d7bdf",
            "b8eeb31a3ff44f2ca5253044f29e58ed",
            "149f7982971e4d7a8da81d9fc875420a",
            "e8fbfa4d6b6b4a7dab3507ed8807e02d",
            "21c9e164bd4d4e128fec99f1057cb648",
            "d606410f1f7544f2940f97c41e31c90a",
            "5a751bda0cd04d038ba4d6aa9cf177ac",
            "af871f043eef476c98a6e12d847098f7",
            "35d8a7b4c8e8480a855544e4d8b78a3e",
            "70c4948e459d4293924ff8dd4aec34fb",
            "8c03c0feb188403892ed2726160a5b38",
            "afcd21eeaeb84e3a95c39ad41d89249a",
            "fc21c54a59f64bb183ec0af2c2a77152",
            "dd3f3da062e447949514feb8aeae55a5",
            "2aa82482dab04c2fae451850fd6e50b4",
            "97c9b9c3efa74d538c7318a82224f0dc"
          ]
        },
        "outputId": "f1c4ad61-15ff-4cad-df68-4a52b72b36e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/3.54k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f67b533d44d4c0bb6ae2352adc3e4e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/923 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "29da2e2812ed4f2c9165b8b1bb403e66"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The repository for atasoglu/flickr8k-dataset contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/atasoglu/flickr8k-dataset.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] Y\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "04fbb41304be4a1b8716fb5e66a4770d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad4a3405218e48178a4bad414387aba6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d606410f1f7544f2940f97c41e31c90a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkpco5WAcpqt",
        "outputId": "fa8a7f4d-d6f0-4d5e-aa92-e744373f2757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['image_id', 'image_path', 'captions'],\n",
              "        num_rows: 6000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['image_id', 'image_path', 'captions'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['image_id', 'image_path', 'captions'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print single example\n",
        "ds['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-umnTrnvczKR",
        "outputId": "a06aa3ff-a18c-49b3-eddd-2563a5cb1257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'image_id': '2513260012_03d33305cf',\n",
              " 'image_path': '/root/.cache/huggingface/datasets/downloads/extracted/725d8f35a92872cf740ec57799b49fe4e24525cf5349b0f73b10fb46e41ed840/Flicker8k_Dataset/2513260012_03d33305cf.jpg',\n",
              " 'captions': ['A black dog is running after a white dog in the snow .',\n",
              "  'Black dog chasing brown dog through snow',\n",
              "  'Two dogs chase each other across the snowy ground .',\n",
              "  'Two dogs play together in the snow .',\n",
              "  'Two dogs running through a low lying body of water .']}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "# text preprocessing step\n",
        "def tokenization_fn(captions, max_target_length):\n",
        "    \"\"\"Run tokenization on captions.\"\"\"\n",
        "    labels = tokenizer(captions,\n",
        "                      padding=\"max_length\",\n",
        "                      max_length=max_target_length,\n",
        "                       is_split_into_words=True).input_ids\n",
        "\n",
        "    return labels\n",
        "\n",
        "# image preprocessing step\n",
        "def feature_extraction_fn(image_paths, check_image=True):\n",
        "    \"\"\"\n",
        "    Run feature extraction on images\n",
        "    If `check_image` is `True`, the examples that fails during `Image.open()` will be caught and discarded.\n",
        "    Otherwise, an exception will be thrown.\n",
        "    \"\"\"\n",
        "\n",
        "    model_inputs = {}\n",
        "\n",
        "    if check_image:\n",
        "        images = []\n",
        "        to_keep = []\n",
        "        for image_file in image_paths:\n",
        "            try:\n",
        "                img = Image.open(image_file)\n",
        "                images.append(img)\n",
        "                to_keep.append(True)\n",
        "            except Exception:\n",
        "                to_keep.append(False)\n",
        "    else:\n",
        "        images = [Image.open(image_file) for image_file in image_paths]\n",
        "\n",
        "    encoder_inputs = feature_extractor(images=images, return_tensors=\"np\")\n",
        "\n",
        "    return encoder_inputs.pixel_values\n",
        "\n",
        "def preprocess_fn(examples, max_target_length, check_image = True):\n",
        "    \"\"\"Run tokenization + image feature extraction\"\"\"\n",
        "    image_paths = examples['image_path']\n",
        "    captions = examples['captions']\n",
        "\n",
        "    model_inputs = {}\n",
        "    # This contains image path column\n",
        "    model_inputs['labels'] = tokenization_fn(captions, max_target_length)\n",
        "    model_inputs['pixel_values'] = feature_extraction_fn(image_paths, check_image=check_image)\n",
        "\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "43tEkmK0c3zG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    predict_with_generate=True,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    output_dir=\"./image-captioning-output\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HtyNg3wc4-d",
        "outputId": "091b34b9-e46f-48c1-e084-8a8cc057f216"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_dataset = ds.map(\n",
        "    function=preprocess_fn,\n",
        "    batched=True,\n",
        "    fn_kwargs={\"max_target_length\": 128},\n",
        "    remove_columns=ds['train'].column_names\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "8c77ccf9fdca4696b4e89b9b1586beef",
            "908e2e7349b44d5a9af9c59816677cf3",
            "d37ca6f611054470b42f0cb3d0a5e7ea",
            "30ec3c7b1edf4dfbac81dd4170b9161a",
            "a70808d4d638477f9cc417916cb22759",
            "0118616952964f10b9cdc2fa1e7b7071",
            "c20f3a464af1464ebb32da11aef2a302",
            "4313254204b5444f9e7bc2672b4d4b23",
            "f23bb5eee7014c9581882e42ae6b10c2",
            "844b2f19833f46cabb9a7a89f3c2baeb",
            "6710d69b082a4e18b448b7fa5fe5f629",
            "cc1a600c274a40a8b066d547ba043abc",
            "a7240dbd3f5f4df790b0b657736f1a6e",
            "026597d8c212491f98ab9f6434723755",
            "1131040efbd84d4badb9cc829cd4c3dd",
            "fcff2761b9e64c699a87d73b375c9e18",
            "437bc5428ef646428e506ea30f222227",
            "9c30b489575e48d68512bf966d4538bb",
            "116a0970d373400ba3167df7e239bda5",
            "e574e3520afa4a6382db6a06963bc9e0",
            "1b513d151df147d181ea0518f20fd29e",
            "880267d077234c0090de40c0a367146b",
            "b71b93375ca546b09fb658967b3ad8cc",
            "cd0ea5d6cb5b49ecb8541767285d1918",
            "103dee40e18240ec91aa773cefef4236",
            "b46f927bd84e4eb39b7a73b6bdf2638a",
            "5de358a1c55b4d83aa4146b2e559a2c8",
            "634f4e6abf9f4c1dac154b941686905f",
            "f51e9f5533104be9ab68e7b8f34cd3ba",
            "46d605ebda1840c080804e26ae32d9cd",
            "728ec47ca75e49d895c82be3c6d7fa44",
            "24ba2f227eba4e2784924e6188a22046",
            "804733ac73e64a6eb8f69a41b20385fd"
          ]
        },
        "id": "eh6_Xv4PgDZr",
        "outputId": "cd1cae07-8a60-4de1-f4e9-2f6dfff8da32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/6000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c77ccf9fdca4696b4e89b9b1586beef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc1a600c274a40a8b066d547ba043abc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b71b93375ca546b09fb658967b3ad8cc"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ray[tune]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZsIST6-8NINN",
        "outputId": "85e689bc-9208-4bae-f094-d9cac55d2f29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ray[tune]\n",
            "  Downloading ray-2.34.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (3.15.4)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (4.23.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (24.1)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (6.0.2)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (2.32.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (2.1.4)\n",
            "Collecting tensorboardX>=1.9 (from ray[tune])\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (17.0.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (2024.6.1)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow>=6.0.1->ray[tune]) (1.26.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (0.20.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->ray[tune]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ray[tune]) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ray[tune]) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (2024.7.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->ray[tune]) (1.16.0)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.34.0-cp310-cp310-manylinux2014_x86_64.whl (64.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.9/64.9 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardX, ray\n",
            "Successfully installed ray-2.34.0 tensorboardX-2.6.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import default_data_collator\n",
        "from ray import tune"
      ],
      "metadata": {
        "id": "cuuhlbr0M5tQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "metric = evaluate.load(\"rouge\")"
      ],
      "metadata": {
        "id": "Vu65R6NZc5De",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d6f0ddf440e8450e8aa6336a32c93f7d",
            "3aff9eb968ef4492826dae5b8e6d6e49",
            "6f12f7daf3244d3fb49b2778529c10b1",
            "236aebf489844c7e934324cc368f0ea4",
            "1b4d99e0c60d49259c1226e8768e503c",
            "0e47710118e84d36bcc463d27472da80",
            "1060966bf06746b2bf7fcc3a17b04df1",
            "8d594c8182904a6e982f5552ae7abcb1",
            "cf64e0a562834a37b93b3789dc4024db",
            "e010864c7aad44dd976f49a8b3e8c24b",
            "97dd757227db47f89707b548eb2d38c7"
          ]
        },
        "outputId": "63c0600f-40c9-4ee9-dfa4-f19eddee7ef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d6f0ddf440e8450e8aa6336a32c93f7d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "ignore_pad_token_for_loss = True\n",
        "\n",
        "\n",
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [label.strip() for label in labels]\n",
        "\n",
        "    # rougeLSum expects newline after each sentence\n",
        "    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
        "    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
        "\n",
        "    return preds, labels\n",
        "\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    if ignore_pad_token_for_loss:\n",
        "        # Replace -100 in the labels as we can't decode them.\n",
        "        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Some simple post-processing\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds,\n",
        "                                                     decoded_labels)\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds,\n",
        "                            references=decoded_labels,\n",
        "                            use_stemmer=True)\n",
        "    result = {k: round(v * 100, 4) for k, v in result.items()}\n",
        "    prediction_lens = [\n",
        "        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds\n",
        "    ]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    return result"
      ],
      "metadata": {
        "id": "FyzOLVGhc5Hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "64r78kY2f-8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import default_data_collator\n",
        "\n",
        "# instantiate trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model_init=model_init,\n",
        "    tokenizer=feature_extractor,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=processed_dataset['train'],\n",
        "    eval_dataset=processed_dataset['validation'],\n",
        "    data_collator=default_data_collator,\n",
        ")"
      ],
      "metadata": {
        "id": "S5Pd9b5Sc5Li",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168,
          "referenced_widgets": [
            "81a3480b1edb4613a52ed2dfdc628a69",
            "0009a7e5976b457880641fd033ef467e",
            "be227ba7950d49f29ff8861f1f80d138",
            "f69f42d78dbc4b45bd577d77449b9e00",
            "06e512261eb9469287820cae85074601",
            "755ae29629f54573b31d8699d9ea437e",
            "3bd8768a6c6740ec97e59b0723e75142",
            "254c86ea12da48a1a7bc401e49390ab3",
            "23ee56dd8afc495f807854ae23f7db2a",
            "cd28913cb80c4bc086402528479db476",
            "ad63e057b3a34c34963a03d52f7f9070",
            "cc620d6023d84b30b29778a0c22d5ea9",
            "e3e9074c48804f7b965e6ddf75bb6689",
            "57398c42d91a4b218286ad6c3201e6d4",
            "dc875ad0121849228a635412f9820947",
            "f03caeac52ed4a96a7403fc5e18d1c4c",
            "959d8b0deae146cf9aece0adb1670e23",
            "813021d9084b42e5ae6ed8e2a9ad5101",
            "a65a8d8ffe36409ca4036e300d56ea31",
            "0555dfa20b3346959b0fac52f60032f3",
            "65244703ce564fba983ede9ac2c289e2",
            "a2cca16549e5450fba32c27a0bafec40",
            "4c44c0d78ad04b98b10155cb0303d06c",
            "564abac2c4c34394bb7079cca8d901db",
            "feea1f5ed93442d0a9f96a5fb6790371",
            "48dc2e4a7f144ff482e5422ab7c30fed",
            "73c95f77bb8a44a6812aae9f1c8e8660",
            "60b41ffe0cfe45ea8354f02aa7a3d835",
            "0f9d77d1029c4f11ba819767a694f956",
            "fd63f6387aa34ef5806b2b21f633a4f2",
            "ba8b539d69d542c79fbb1be56bf60ea1",
            "538c20c0dfc34e4380aa2349c9e36125",
            "287a5c89b77c4dc0ac10d25c70898863"
          ]
        },
        "outputId": "ad91899b-0c36-4ac5-e7b9-71558e3c8e26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "81a3480b1edb4613a52ed2dfdc628a69"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc620d6023d84b30b29778a0c22d5ea9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.crossattention.c_attn.bias', 'h.0.crossattention.c_attn.weight', 'h.0.crossattention.c_proj.bias', 'h.0.crossattention.c_proj.weight', 'h.0.crossattention.q_attn.bias', 'h.0.crossattention.q_attn.weight', 'h.0.ln_cross_attn.bias', 'h.0.ln_cross_attn.weight', 'h.1.crossattention.c_attn.bias', 'h.1.crossattention.c_attn.weight', 'h.1.crossattention.c_proj.bias', 'h.1.crossattention.c_proj.weight', 'h.1.crossattention.q_attn.bias', 'h.1.crossattention.q_attn.weight', 'h.1.ln_cross_attn.bias', 'h.1.ln_cross_attn.weight', 'h.10.crossattention.c_attn.bias', 'h.10.crossattention.c_attn.weight', 'h.10.crossattention.c_proj.bias', 'h.10.crossattention.c_proj.weight', 'h.10.crossattention.q_attn.bias', 'h.10.crossattention.q_attn.weight', 'h.10.ln_cross_attn.bias', 'h.10.ln_cross_attn.weight', 'h.11.crossattention.c_attn.bias', 'h.11.crossattention.c_attn.weight', 'h.11.crossattention.c_proj.bias', 'h.11.crossattention.c_proj.weight', 'h.11.crossattention.q_attn.bias', 'h.11.crossattention.q_attn.weight', 'h.11.ln_cross_attn.bias', 'h.11.ln_cross_attn.weight', 'h.2.crossattention.c_attn.bias', 'h.2.crossattention.c_attn.weight', 'h.2.crossattention.c_proj.bias', 'h.2.crossattention.c_proj.weight', 'h.2.crossattention.q_attn.bias', 'h.2.crossattention.q_attn.weight', 'h.2.ln_cross_attn.bias', 'h.2.ln_cross_attn.weight', 'h.3.crossattention.c_attn.bias', 'h.3.crossattention.c_attn.weight', 'h.3.crossattention.c_proj.bias', 'h.3.crossattention.c_proj.weight', 'h.3.crossattention.q_attn.bias', 'h.3.crossattention.q_attn.weight', 'h.3.ln_cross_attn.bias', 'h.3.ln_cross_attn.weight', 'h.4.crossattention.c_attn.bias', 'h.4.crossattention.c_attn.weight', 'h.4.crossattention.c_proj.bias', 'h.4.crossattention.c_proj.weight', 'h.4.crossattention.q_attn.bias', 'h.4.crossattention.q_attn.weight', 'h.4.ln_cross_attn.bias', 'h.4.ln_cross_attn.weight', 'h.5.crossattention.c_attn.bias', 'h.5.crossattention.c_attn.weight', 'h.5.crossattention.c_proj.bias', 'h.5.crossattention.c_proj.weight', 'h.5.crossattention.q_attn.bias', 'h.5.crossattention.q_attn.weight', 'h.5.ln_cross_attn.bias', 'h.5.ln_cross_attn.weight', 'h.6.crossattention.c_attn.bias', 'h.6.crossattention.c_attn.weight', 'h.6.crossattention.c_proj.bias', 'h.6.crossattention.c_proj.weight', 'h.6.crossattention.q_attn.bias', 'h.6.crossattention.q_attn.weight', 'h.6.ln_cross_attn.bias', 'h.6.ln_cross_attn.weight', 'h.7.crossattention.c_attn.bias', 'h.7.crossattention.c_attn.weight', 'h.7.crossattention.c_proj.bias', 'h.7.crossattention.c_proj.weight', 'h.7.crossattention.q_attn.bias', 'h.7.crossattention.q_attn.weight', 'h.7.ln_cross_attn.bias', 'h.7.ln_cross_attn.weight', 'h.8.crossattention.c_attn.bias', 'h.8.crossattention.c_attn.weight', 'h.8.crossattention.c_proj.bias', 'h.8.crossattention.c_proj.weight', 'h.8.crossattention.q_attn.bias', 'h.8.crossattention.q_attn.weight', 'h.8.ln_cross_attn.bias', 'h.8.ln_cross_attn.weight', 'h.9.crossattention.c_attn.bias', 'h.9.crossattention.c_attn.weight', 'h.9.crossattention.c_proj.bias', 'h.9.crossattention.c_proj.weight', 'h.9.crossattention.q_attn.bias', 'h.9.crossattention.q_attn.weight', 'h.9.ln_cross_attn.bias', 'h.9.ln_cross_attn.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c44c0d78ad04b98b10155cb0303d06c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hyperparameter_search_function(trial):\n",
        "    return {\n",
        "        \"learning_rate\": tune.loguniform(1e-5, 5e-4),\n",
        "        \"per_device_train_batch_size\": tune.choice([16,32, 64]),\n",
        "        \"per_device_eval_batch_size\": tune.choice([2, 4, 8]),\n",
        "        \"num_train_epochs\": tune.choice([2,3]),\n",
        "        \"weight_decay\": tune.uniform(0.01, 0.1),\n",
        "    }"
      ],
      "metadata": {
        "id": "1mC3chMZxVOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "82_MioMi5aV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform hyperparameter search\n",
        "best_run = trainer.hyperparameter_search(\n",
        "    hp_space=hyperparameter_search_function,\n",
        "    direction=\"maximize\",\n",
        "    n_trials=2,  # Number of trials\n",
        "    backend=\"ray\",  # Use Ray for distributed search\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvojykwYNXxc",
        "outputId": "ff4e2a2e-f368-4a07-d6d7-779fd73b2e11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = _posixsubprocess.fork_exec(\n",
            "/usr/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = _posixsubprocess.fork_exec(\n",
            "2024-08-17 11:37:26,586\tINFO worker.py:1781 -- Started a local Ray instance.\n",
            "2024-08-17 11:37:30,057\tINFO tune.py:253 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.\n",
            "2024-08-17 11:37:30,219\tWARNING tune.py:902 -- AIR_VERBOSITY is set, ignoring passed-in ProgressReporter for now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------------+\n",
            "| Configuration for experiment     _objective_2024-08-17_11-37-30   |\n",
            "+-------------------------------------------------------------------+\n",
            "| Search algorithm                 BasicVariantGenerator            |\n",
            "| Scheduler                        FIFOScheduler                    |\n",
            "| Number of trials                 2                                |\n",
            "+-------------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /root/ray_results/_objective_2024-08-17_11-37-30\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2024-08-17_11-37-24_916388_1514/artifacts/2024-08-17_11-37-30/_objective_2024-08-17_11-37-30/driver_artifacts`\n",
            "\n",
            "Trial status: 2 PENDING\n",
            "Current time: 2024-08-17 11:37:30. Total running time: 0s\n",
            "Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   PENDING        4.32845e-05                       16                        8                    2        0.0801722 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial _objective_15fb9_00000 started with configuration:\n",
            "+-------------------------------------------------+\n",
            "| Trial _objective_15fb9_00000 config             |\n",
            "+-------------------------------------------------+\n",
            "| learning_rate                             4e-05 |\n",
            "| num_train_epochs                              2 |\n",
            "| per_device_eval_batch_size                    8 |\n",
            "| per_device_train_batch_size                  16 |\n",
            "| weight_decay                            0.08017 |\n",
            "+-------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_objective pid=10843)\u001b[0m 2024-08-17 11:37:34.737195: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m 2024-08-17 11:37:34.762806: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m 2024-08-17 11:37:34.770610: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m 2024-08-17 11:37:35.878255: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.crossattention.c_attn.bias', 'h.0.crossattention.c_attn.weight', 'h.0.crossattention.c_proj.bias', 'h.0.crossattention.c_proj.weight', 'h.0.crossattention.q_attn.bias', 'h.0.crossattention.q_attn.weight', 'h.0.ln_cross_attn.bias', 'h.0.ln_cross_attn.weight', 'h.1.crossattention.c_attn.bias', 'h.1.crossattention.c_attn.weight', 'h.1.crossattention.c_proj.bias', 'h.1.crossattention.c_proj.weight', 'h.1.crossattention.q_attn.bias', 'h.1.crossattention.q_attn.weight', 'h.1.ln_cross_attn.bias', 'h.1.ln_cross_attn.weight', 'h.10.crossattention.c_attn.bias', 'h.10.crossattention.c_attn.weight', 'h.10.crossattention.c_proj.bias', 'h.10.crossattention.c_proj.weight', 'h.10.crossattention.q_attn.bias', 'h.10.crossattention.q_attn.weight', 'h.10.ln_cross_attn.bias', 'h.10.ln_cross_attn.weight', 'h.11.crossattention.c_attn.bias', 'h.11.crossattention.c_attn.weight', 'h.11.crossattention.c_proj.bias', 'h.11.crossattention.c_proj.weight', 'h.11.crossattention.q_attn.bias', 'h.11.crossattention.q_attn.weight', 'h.11.ln_cross_attn.bias', 'h.11.ln_cross_attn.weight', 'h.2.crossattention.c_attn.bias', 'h.2.crossattention.c_attn.weight', 'h.2.crossattention.c_proj.bias', 'h.2.crossattention.c_proj.weight', 'h.2.crossattention.q_attn.bias', 'h.2.crossattention.q_attn.weight', 'h.2.ln_cross_attn.bias', 'h.2.ln_cross_attn.weight', 'h.3.crossattention.c_attn.bias', 'h.3.crossattention.c_attn.weight', 'h.3.crossattention.c_proj.bias', 'h.3.crossattention.c_proj.weight', 'h.3.crossattention.q_attn.bias', 'h.3.crossattention.q_attn.weight', 'h.3.ln_cross_attn.bias', 'h.3.ln_cross_attn.weight', 'h.4.crossattention.c_attn.bias', 'h.4.crossattention.c_attn.weight', 'h.4.crossattention.c_proj.bias', 'h.4.crossattention.c_proj.weight', 'h.4.crossattention.q_attn.bias', 'h.4.crossattention.q_attn.weight', 'h.4.ln_cross_attn.bias', 'h.4.ln_cross_attn.weight', 'h.5.crossattention.c_attn.bias', 'h.5.crossattention.c_attn.weight', 'h.5.crossattention.c_proj.bias', 'h.5.crossattention.c_proj.weight', 'h.5.crossattention.q_attn.bias', 'h.5.crossattention.q_attn.weight', 'h.5.ln_cross_attn.bias', 'h.5.ln_cross_attn.weight', 'h.6.crossattention.c_attn.bias', 'h.6.crossattention.c_attn.weight', 'h.6.crossattention.c_proj.bias', 'h.6.crossattention.c_proj.weight', 'h.6.crossattention.q_attn.bias', 'h.6.crossattention.q_attn.weight', 'h.6.ln_cross_attn.bias', 'h.6.ln_cross_attn.weight', 'h.7.crossattention.c_attn.bias', 'h.7.crossattention.c_attn.weight', 'h.7.crossattention.c_proj.bias', 'h.7.crossattention.c_proj.weight', 'h.7.crossattention.q_attn.bias', 'h.7.crossattention.q_attn.weight', 'h.7.ln_cross_attn.bias', 'h.7.ln_cross_attn.weight', 'h.8.crossattention.c_attn.bias', 'h.8.crossattention.c_attn.weight', 'h.8.crossattention.c_proj.bias', 'h.8.crossattention.c_proj.weight', 'h.8.crossattention.q_attn.bias', 'h.8.crossattention.q_attn.weight', 'h.8.ln_cross_attn.bias', 'h.8.ln_cross_attn.weight', 'h.9.crossattention.c_attn.bias', 'h.9.crossattention.c_attn.weight', 'h.9.crossattention.c_proj.bias', 'h.9.crossattention.c_proj.weight', 'h.9.crossattention.q_attn.bias', 'h.9.crossattention.q_attn.weight', 'h.9.ln_cross_attn.bias', 'h.9.ln_cross_attn.weight']\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "  0%|          | 0/750 [00:00<?, ?it/s]\n",
            "  0%|          | 1/750 [00:05<1:09:58,  5.61s/it]\n",
            "  0%|          | 2/750 [00:07<43:24,  3.48s/it]  \n",
            "  0%|          | 3/750 [00:09<35:12,  2.83s/it]\n",
            "  1%|          | 4/750 [00:11<31:16,  2.52s/it]\n",
            "  1%|          | 5/750 [00:13<29:08,  2.35s/it]\n",
            "  1%|          | 6/750 [00:15<27:41,  2.23s/it]\n",
            "  1%|          | 7/750 [00:17<26:48,  2.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:38:00. Total running time: 30s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 8/750 [00:19<26:09,  2.12s/it]\n",
            "  1%|          | 9/750 [00:21<25:49,  2.09s/it]\n",
            "  1%|â–         | 10/750 [00:23<25:27,  2.06s/it]\n",
            "  1%|â–         | 11/750 [00:25<25:16,  2.05s/it]\n",
            "  2%|â–         | 12/750 [00:27<25:10,  2.05s/it]\n",
            "  2%|â–         | 13/750 [00:29<25:05,  2.04s/it]\n",
            "  2%|â–         | 14/750 [00:31<25:10,  2.05s/it]\n",
            "  2%|â–         | 15/750 [00:34<25:10,  2.05s/it]\n",
            "  2%|â–         | 16/750 [00:36<25:16,  2.07s/it]\n",
            "  2%|â–         | 17/750 [00:38<25:03,  2.05s/it]\n",
            "  2%|â–         | 18/750 [00:40<24:54,  2.04s/it]\n",
            "  3%|â–         | 19/750 [00:42<24:47,  2.03s/it]\n",
            "  3%|â–         | 20/750 [00:44<24:47,  2.04s/it]\n",
            "  3%|â–         | 21/750 [00:46<24:51,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:38:30. Total running time: 1min 0s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|â–         | 22/750 [00:48<24:49,  2.05s/it]\n",
            "  3%|â–         | 23/750 [00:50<24:42,  2.04s/it]\n",
            "  3%|â–         | 24/750 [00:52<24:37,  2.04s/it]\n",
            "  3%|â–         | 25/750 [00:54<24:23,  2.02s/it]\n",
            "  3%|â–         | 26/750 [00:56<24:19,  2.02s/it]\n",
            "  4%|â–         | 27/750 [00:58<24:24,  2.03s/it]\n",
            "  4%|â–         | 28/750 [01:00<24:24,  2.03s/it]\n",
            "  4%|â–         | 29/750 [01:02<25:25,  2.12s/it]\n",
            "  4%|â–         | 30/750 [01:04<25:03,  2.09s/it]\n",
            "  4%|â–         | 31/750 [01:06<24:49,  2.07s/it]\n",
            "  4%|â–         | 32/750 [01:08<24:41,  2.06s/it]\n",
            "  4%|â–         | 33/750 [01:10<24:33,  2.06s/it]\n",
            "  5%|â–         | 34/750 [01:12<24:29,  2.05s/it]\n",
            "  5%|â–         | 35/750 [01:15<24:34,  2.06s/it]\n",
            "  5%|â–         | 36/750 [01:17<24:28,  2.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:39:00. Total running time: 1min 30s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|â–         | 37/750 [01:19<24:28,  2.06s/it]\n",
            "  5%|â–Œ         | 38/750 [01:21<24:22,  2.05s/it]\n",
            "  5%|â–Œ         | 39/750 [01:23<24:21,  2.05s/it]\n",
            "  5%|â–Œ         | 40/750 [01:25<24:15,  2.05s/it]\n",
            "  5%|â–Œ         | 41/750 [01:27<24:22,  2.06s/it]\n",
            "  6%|â–Œ         | 42/750 [01:29<24:18,  2.06s/it]\n",
            "  6%|â–Œ         | 43/750 [01:31<24:10,  2.05s/it]\n",
            "  6%|â–Œ         | 44/750 [01:33<24:05,  2.05s/it]\n",
            "  6%|â–Œ         | 45/750 [01:35<24:02,  2.05s/it]\n",
            "  6%|â–Œ         | 46/750 [01:37<23:57,  2.04s/it]\n",
            "  6%|â–‹         | 47/750 [01:39<23:54,  2.04s/it]\n",
            "  6%|â–‹         | 48/750 [01:41<23:50,  2.04s/it]\n",
            "  7%|â–‹         | 49/750 [01:43<23:47,  2.04s/it]\n",
            "  7%|â–‹         | 50/750 [01:45<23:45,  2.04s/it]\n",
            "  7%|â–‹         | 51/750 [01:47<23:44,  2.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:39:30. Total running time: 2min 0s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|â–‹         | 52/750 [01:49<23:46,  2.04s/it]\n",
            "  7%|â–‹         | 53/750 [01:51<23:52,  2.05s/it]\n",
            "  7%|â–‹         | 54/750 [01:53<23:51,  2.06s/it]\n",
            "  7%|â–‹         | 55/750 [01:56<23:45,  2.05s/it]\n",
            "  7%|â–‹         | 56/750 [01:58<23:41,  2.05s/it]\n",
            "  8%|â–Š         | 57/750 [02:00<23:37,  2.05s/it]\n",
            "  8%|â–Š         | 58/750 [02:02<23:29,  2.04s/it]\n",
            "  8%|â–Š         | 59/750 [02:04<24:34,  2.13s/it]\n",
            "  8%|â–Š         | 60/750 [02:06<24:15,  2.11s/it]\n",
            "  8%|â–Š         | 61/750 [02:08<23:52,  2.08s/it]\n",
            "  8%|â–Š         | 62/750 [02:10<23:42,  2.07s/it]\n",
            "  8%|â–Š         | 63/750 [02:12<23:37,  2.06s/it]\n",
            "  9%|â–Š         | 64/750 [02:14<23:24,  2.05s/it]\n",
            "  9%|â–Š         | 65/750 [02:16<23:18,  2.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:40:00. Total running time: 2min 30s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|â–‰         | 66/750 [02:18<23:15,  2.04s/it]\n",
            "  9%|â–‰         | 67/750 [02:20<23:10,  2.04s/it]\n",
            "  9%|â–‰         | 68/750 [02:22<23:09,  2.04s/it]\n",
            "  9%|â–‰         | 69/750 [02:24<23:05,  2.04s/it]\n",
            "  9%|â–‰         | 70/750 [02:26<23:04,  2.04s/it]\n",
            "  9%|â–‰         | 71/750 [02:28<23:01,  2.03s/it]\n",
            " 10%|â–‰         | 72/750 [02:30<23:04,  2.04s/it]\n",
            " 10%|â–‰         | 73/750 [02:32<23:06,  2.05s/it]\n",
            " 10%|â–‰         | 74/750 [02:35<23:04,  2.05s/it]\n",
            " 10%|â–ˆ         | 75/750 [02:37<23:04,  2.05s/it]\n",
            " 10%|â–ˆ         | 76/750 [02:39<23:02,  2.05s/it]\n",
            " 10%|â–ˆ         | 77/750 [02:41<22:54,  2.04s/it]\n",
            " 10%|â–ˆ         | 78/750 [02:43<22:50,  2.04s/it]\n",
            " 11%|â–ˆ         | 79/750 [02:45<22:45,  2.03s/it]\n",
            " 11%|â–ˆ         | 80/750 [02:47<22:52,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:40:30. Total running time: 3min 0s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|â–ˆ         | 81/750 [02:49<22:48,  2.05s/it]\n",
            " 11%|â–ˆ         | 82/750 [02:51<22:45,  2.04s/it]\n",
            " 11%|â–ˆ         | 83/750 [02:53<22:45,  2.05s/it]\n",
            " 11%|â–ˆ         | 84/750 [02:55<22:38,  2.04s/it]\n",
            " 11%|â–ˆâ–        | 85/750 [02:57<22:36,  2.04s/it]\n",
            " 11%|â–ˆâ–        | 86/750 [02:59<23:36,  2.13s/it]\n",
            " 12%|â–ˆâ–        | 87/750 [03:01<23:12,  2.10s/it]\n",
            " 12%|â–ˆâ–        | 88/750 [03:03<22:51,  2.07s/it]\n",
            " 12%|â–ˆâ–        | 89/750 [03:05<22:44,  2.06s/it]\n",
            " 12%|â–ˆâ–        | 90/750 [03:07<22:39,  2.06s/it]\n",
            " 12%|â–ˆâ–        | 91/750 [03:10<22:40,  2.06s/it]\n",
            " 12%|â–ˆâ–        | 92/750 [03:12<22:33,  2.06s/it]\n",
            " 12%|â–ˆâ–        | 93/750 [03:14<22:28,  2.05s/it]\n",
            " 13%|â–ˆâ–        | 94/750 [03:16<22:20,  2.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:41:00. Total running time: 3min 30s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|â–ˆâ–        | 95/750 [03:18<22:24,  2.05s/it]\n",
            " 13%|â–ˆâ–        | 96/750 [03:20<22:19,  2.05s/it]\n",
            " 13%|â–ˆâ–        | 97/750 [03:22<22:16,  2.05s/it]\n",
            " 13%|â–ˆâ–        | 98/750 [03:24<22:13,  2.05s/it]\n",
            " 13%|â–ˆâ–        | 99/750 [03:26<22:06,  2.04s/it]\n",
            " 13%|â–ˆâ–        | 100/750 [03:28<22:04,  2.04s/it]\n",
            " 13%|â–ˆâ–        | 101/750 [03:30<22:06,  2.04s/it]\n",
            " 14%|â–ˆâ–        | 102/750 [03:32<21:56,  2.03s/it]\n",
            " 14%|â–ˆâ–        | 103/750 [03:34<21:56,  2.03s/it]\n",
            " 14%|â–ˆâ–        | 104/750 [03:36<21:53,  2.03s/it]\n",
            " 14%|â–ˆâ–        | 105/750 [03:38<21:57,  2.04s/it]\n",
            " 14%|â–ˆâ–        | 106/750 [03:40<21:59,  2.05s/it]\n",
            " 14%|â–ˆâ–        | 107/750 [03:42<21:54,  2.04s/it]\n",
            " 14%|â–ˆâ–        | 108/750 [03:44<21:45,  2.03s/it]\n",
            " 15%|â–ˆâ–        | 109/750 [03:46<21:40,  2.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:41:30. Total running time: 4min 0s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|â–ˆâ–        | 110/750 [03:49<22:27,  2.11s/it]\n",
            " 15%|â–ˆâ–        | 111/750 [03:51<22:13,  2.09s/it]\n",
            " 15%|â–ˆâ–        | 112/750 [03:53<22:14,  2.09s/it]\n",
            " 15%|â–ˆâ–Œ        | 113/750 [03:55<22:03,  2.08s/it]\n",
            " 15%|â–ˆâ–Œ        | 114/750 [03:57<21:58,  2.07s/it]\n",
            " 15%|â–ˆâ–Œ        | 115/750 [03:59<21:57,  2.07s/it]\n",
            " 15%|â–ˆâ–Œ        | 116/750 [04:01<21:56,  2.08s/it]\n",
            " 16%|â–ˆâ–Œ        | 117/750 [04:03<21:52,  2.07s/it]\n",
            " 16%|â–ˆâ–Œ        | 118/750 [04:05<21:48,  2.07s/it]\n",
            " 16%|â–ˆâ–Œ        | 119/750 [04:07<21:41,  2.06s/it]\n",
            " 16%|â–ˆâ–Œ        | 120/750 [04:09<21:34,  2.06s/it]\n",
            " 16%|â–ˆâ–Œ        | 121/750 [04:11<21:32,  2.05s/it]\n",
            " 16%|â–ˆâ–‹        | 122/750 [04:13<21:22,  2.04s/it]\n",
            " 16%|â–ˆâ–‹        | 123/750 [04:15<21:18,  2.04s/it]\n",
            " 17%|â–ˆâ–‹        | 124/750 [04:17<21:20,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:42:00. Total running time: 4min 30s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|â–ˆâ–‹        | 125/750 [04:19<21:34,  2.07s/it]\n",
            " 17%|â–ˆâ–‹        | 126/750 [04:21<21:30,  2.07s/it]\n",
            " 17%|â–ˆâ–‹        | 127/750 [04:24<21:23,  2.06s/it]\n",
            " 17%|â–ˆâ–‹        | 128/750 [04:26<21:18,  2.06s/it]\n",
            " 17%|â–ˆâ–‹        | 129/750 [04:28<21:15,  2.05s/it]\n",
            " 17%|â–ˆâ–‹        | 130/750 [04:30<21:05,  2.04s/it]\n",
            " 17%|â–ˆâ–‹        | 131/750 [04:32<21:08,  2.05s/it]\n",
            " 18%|â–ˆâ–Š        | 132/750 [04:34<21:06,  2.05s/it]\n",
            " 18%|â–ˆâ–Š        | 133/750 [04:36<21:02,  2.05s/it]\n",
            " 18%|â–ˆâ–Š        | 134/750 [04:38<20:59,  2.04s/it]\n",
            " 18%|â–ˆâ–Š        | 135/750 [04:40<20:57,  2.04s/it]\n",
            " 18%|â–ˆâ–Š        | 136/750 [04:42<21:04,  2.06s/it]\n",
            " 18%|â–ˆâ–Š        | 137/750 [04:44<21:04,  2.06s/it]\n",
            " 18%|â–ˆâ–Š        | 138/750 [04:46<21:02,  2.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:42:30. Total running time: 5min 0s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|â–ˆâ–Š        | 139/750 [04:48<20:54,  2.05s/it]\n",
            " 19%|â–ˆâ–Š        | 140/750 [04:50<20:45,  2.04s/it]\n",
            " 19%|â–ˆâ–‰        | 141/750 [04:53<21:40,  2.14s/it]\n",
            " 19%|â–ˆâ–‰        | 142/750 [04:55<21:20,  2.11s/it]\n",
            " 19%|â–ˆâ–‰        | 143/750 [04:57<21:02,  2.08s/it]\n",
            " 19%|â–ˆâ–‰        | 144/750 [04:59<20:52,  2.07s/it]\n",
            " 19%|â–ˆâ–‰        | 145/750 [05:01<20:46,  2.06s/it]\n",
            " 19%|â–ˆâ–‰        | 146/750 [05:03<20:39,  2.05s/it]\n",
            " 20%|â–ˆâ–‰        | 147/750 [05:05<20:35,  2.05s/it]\n",
            " 20%|â–ˆâ–‰        | 148/750 [05:07<20:27,  2.04s/it]\n",
            " 20%|â–ˆâ–‰        | 149/750 [05:09<20:26,  2.04s/it]\n",
            " 20%|â–ˆâ–ˆ        | 150/750 [05:11<20:24,  2.04s/it]\n",
            " 20%|â–ˆâ–ˆ        | 151/750 [05:13<20:22,  2.04s/it]\n",
            " 20%|â–ˆâ–ˆ        | 152/750 [05:15<20:24,  2.05s/it]\n",
            " 20%|â–ˆâ–ˆ        | 153/750 [05:17<20:30,  2.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:43:00. Total running time: 5min 30s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|â–ˆâ–ˆ        | 154/750 [05:19<20:25,  2.06s/it]\n",
            " 21%|â–ˆâ–ˆ        | 155/750 [05:21<20:19,  2.05s/it]\n",
            " 21%|â–ˆâ–ˆ        | 156/750 [05:23<20:20,  2.06s/it]\n",
            " 21%|â–ˆâ–ˆ        | 157/750 [05:25<20:21,  2.06s/it]\n",
            " 21%|â–ˆâ–ˆ        | 158/750 [05:27<20:16,  2.06s/it]\n",
            " 21%|â–ˆâ–ˆ        | 159/750 [05:29<20:16,  2.06s/it]\n",
            " 21%|â–ˆâ–ˆâ–       | 160/750 [05:31<20:13,  2.06s/it]\n",
            " 21%|â–ˆâ–ˆâ–       | 161/750 [05:33<20:13,  2.06s/it]\n",
            " 22%|â–ˆâ–ˆâ–       | 162/750 [05:36<20:08,  2.06s/it]\n",
            " 22%|â–ˆâ–ˆâ–       | 163/750 [05:38<20:08,  2.06s/it]\n",
            " 22%|â–ˆâ–ˆâ–       | 164/750 [05:40<20:13,  2.07s/it]\n",
            " 22%|â–ˆâ–ˆâ–       | 165/750 [05:42<20:05,  2.06s/it]\n",
            " 22%|â–ˆâ–ˆâ–       | 166/750 [05:44<20:10,  2.07s/it]\n",
            " 22%|â–ˆâ–ˆâ–       | 167/750 [05:46<19:55,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:43:30. Total running time: 6min 0s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|â–ˆâ–ˆâ–       | 168/750 [05:48<19:44,  2.04s/it]\n",
            " 23%|â–ˆâ–ˆâ–       | 169/750 [05:50<19:38,  2.03s/it]\n",
            " 23%|â–ˆâ–ˆâ–       | 170/750 [05:52<19:42,  2.04s/it]\n",
            " 23%|â–ˆâ–ˆâ–       | 171/750 [05:54<20:33,  2.13s/it]\n",
            " 23%|â–ˆâ–ˆâ–       | 172/750 [05:56<20:19,  2.11s/it]\n",
            " 23%|â–ˆâ–ˆâ–       | 173/750 [05:58<20:02,  2.08s/it]\n",
            " 23%|â–ˆâ–ˆâ–       | 174/750 [06:00<19:50,  2.07s/it]\n",
            " 23%|â–ˆâ–ˆâ–       | 175/750 [06:02<19:43,  2.06s/it]\n",
            " 23%|â–ˆâ–ˆâ–       | 176/750 [06:04<19:42,  2.06s/it]\n",
            " 24%|â–ˆâ–ˆâ–       | 177/750 [06:07<19:39,  2.06s/it]\n",
            " 24%|â–ˆâ–ˆâ–       | 178/750 [06:09<19:39,  2.06s/it]\n",
            " 24%|â–ˆâ–ˆâ–       | 179/750 [06:11<19:34,  2.06s/it]\n",
            " 24%|â–ˆâ–ˆâ–       | 180/750 [06:13<19:32,  2.06s/it]\n",
            " 24%|â–ˆâ–ˆâ–       | 181/750 [06:15<19:19,  2.04s/it]\n",
            " 24%|â–ˆâ–ˆâ–       | 182/750 [06:17<19:19,  2.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:44:00. Total running time: 6min 30s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|â–ˆâ–ˆâ–       | 183/750 [06:19<19:20,  2.05s/it]\n",
            " 25%|â–ˆâ–ˆâ–       | 184/750 [06:21<19:21,  2.05s/it]\n",
            " 25%|â–ˆâ–ˆâ–       | 185/750 [06:23<19:17,  2.05s/it]\n",
            " 25%|â–ˆâ–ˆâ–       | 186/750 [06:25<19:15,  2.05s/it]\n",
            " 25%|â–ˆâ–ˆâ–       | 187/750 [06:27<19:10,  2.04s/it]\n",
            " 25%|â–ˆâ–ˆâ–Œ       | 188/750 [06:29<19:06,  2.04s/it]\n",
            " 25%|â–ˆâ–ˆâ–Œ       | 189/750 [06:31<19:08,  2.05s/it]\n",
            " 25%|â–ˆâ–ˆâ–Œ       | 190/750 [06:33<19:07,  2.05s/it]\n",
            " 25%|â–ˆâ–ˆâ–Œ       | 191/750 [06:35<19:04,  2.05s/it]\n",
            " 26%|â–ˆâ–ˆâ–Œ       | 192/750 [06:37<19:02,  2.05s/it]\n",
            " 26%|â–ˆâ–ˆâ–Œ       | 193/750 [06:39<19:03,  2.05s/it]\n",
            " 26%|â–ˆâ–ˆâ–Œ       | 194/750 [06:41<18:58,  2.05s/it]\n",
            " 26%|â–ˆâ–ˆâ–Œ       | 195/750 [06:43<19:01,  2.06s/it]\n",
            " 26%|â–ˆâ–ˆâ–Œ       | 196/750 [06:45<19:03,  2.06s/it]\n",
            " 26%|â–ˆâ–ˆâ–‹       | 197/750 [06:47<18:53,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:44:30. Total running time: 7min 0s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|â–ˆâ–ˆâ–‹       | 198/750 [06:50<19:34,  2.13s/it]\n",
            " 27%|â–ˆâ–ˆâ–‹       | 199/750 [06:52<19:14,  2.10s/it]\n",
            " 27%|â–ˆâ–ˆâ–‹       | 200/750 [06:54<18:56,  2.07s/it]\n",
            " 27%|â–ˆâ–ˆâ–‹       | 201/750 [06:56<18:53,  2.07s/it]\n",
            " 27%|â–ˆâ–ˆâ–‹       | 202/750 [06:58<18:52,  2.07s/it]\n",
            " 27%|â–ˆâ–ˆâ–‹       | 203/750 [07:00<18:42,  2.05s/it]\n",
            " 27%|â–ˆâ–ˆâ–‹       | 204/750 [07:02<18:42,  2.06s/it]\n",
            " 27%|â–ˆâ–ˆâ–‹       | 205/750 [07:04<18:35,  2.05s/it]\n",
            " 27%|â–ˆâ–ˆâ–‹       | 206/750 [07:06<18:29,  2.04s/it]\n",
            " 28%|â–ˆâ–ˆâ–Š       | 207/750 [07:08<18:26,  2.04s/it]\n",
            " 28%|â–ˆâ–ˆâ–Š       | 208/750 [07:10<18:28,  2.05s/it]\n",
            " 28%|â–ˆâ–ˆâ–Š       | 209/750 [07:12<18:31,  2.05s/it]\n",
            " 28%|â–ˆâ–ˆâ–Š       | 210/750 [07:14<18:29,  2.05s/it]\n",
            " 28%|â–ˆâ–ˆâ–Š       | 211/750 [07:16<18:28,  2.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:45:00. Total running time: 7min 30s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|â–ˆâ–ˆâ–Š       | 212/750 [07:18<18:24,  2.05s/it]\n",
            " 28%|â–ˆâ–ˆâ–Š       | 213/750 [07:20<18:27,  2.06s/it]\n",
            " 29%|â–ˆâ–ˆâ–Š       | 214/750 [07:23<18:31,  2.07s/it]\n",
            " 29%|â–ˆâ–ˆâ–Š       | 215/750 [07:25<18:31,  2.08s/it]\n",
            " 29%|â–ˆâ–ˆâ–‰       | 216/750 [07:27<18:26,  2.07s/it]\n",
            " 29%|â–ˆâ–ˆâ–‰       | 217/750 [07:29<18:20,  2.06s/it]\n",
            " 29%|â–ˆâ–ˆâ–‰       | 218/750 [07:31<18:14,  2.06s/it]\n",
            " 29%|â–ˆâ–ˆâ–‰       | 219/750 [07:33<18:11,  2.06s/it]\n",
            " 29%|â–ˆâ–ˆâ–‰       | 220/750 [07:35<18:06,  2.05s/it]\n",
            " 29%|â–ˆâ–ˆâ–‰       | 221/750 [07:37<18:03,  2.05s/it]\n",
            " 30%|â–ˆâ–ˆâ–‰       | 222/750 [07:39<18:47,  2.14s/it]\n",
            " 30%|â–ˆâ–ˆâ–‰       | 223/750 [07:41<18:29,  2.10s/it]\n",
            " 30%|â–ˆâ–ˆâ–‰       | 224/750 [07:43<18:20,  2.09s/it]\n",
            " 30%|â–ˆâ–ˆâ–ˆ       | 225/750 [07:45<18:12,  2.08s/it]\n",
            " 30%|â–ˆâ–ˆâ–ˆ       | 226/750 [07:48<18:05,  2.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:45:30. Total running time: 8min 0s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|â–ˆâ–ˆâ–ˆ       | 227/750 [07:50<17:55,  2.06s/it]\n",
            " 30%|â–ˆâ–ˆâ–ˆ       | 228/750 [07:52<17:44,  2.04s/it]\n",
            " 31%|â–ˆâ–ˆâ–ˆ       | 229/750 [07:54<17:46,  2.05s/it]\n",
            " 31%|â–ˆâ–ˆâ–ˆ       | 230/750 [07:56<17:41,  2.04s/it]\n",
            " 31%|â–ˆâ–ˆâ–ˆ       | 231/750 [07:58<17:37,  2.04s/it]\n",
            " 31%|â–ˆâ–ˆâ–ˆ       | 232/750 [08:00<17:33,  2.03s/it]\n",
            " 31%|â–ˆâ–ˆâ–ˆ       | 233/750 [08:02<17:32,  2.04s/it]\n",
            " 31%|â–ˆâ–ˆâ–ˆ       | 234/750 [08:04<17:33,  2.04s/it]\n",
            " 31%|â–ˆâ–ˆâ–ˆâ–      | 235/750 [08:06<17:33,  2.05s/it]\n",
            " 31%|â–ˆâ–ˆâ–ˆâ–      | 236/750 [08:08<17:25,  2.03s/it]\n",
            " 32%|â–ˆâ–ˆâ–ˆâ–      | 237/750 [08:10<17:23,  2.03s/it]\n",
            " 32%|â–ˆâ–ˆâ–ˆâ–      | 238/750 [08:12<17:23,  2.04s/it]\n",
            " 32%|â–ˆâ–ˆâ–ˆâ–      | 239/750 [08:14<17:20,  2.04s/it]\n",
            " 32%|â–ˆâ–ˆâ–ˆâ–      | 240/750 [08:16<17:16,  2.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:46:00. Total running time: 8min 30s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|â–ˆâ–ˆâ–ˆâ–      | 241/750 [08:18<17:17,  2.04s/it]\n",
            " 32%|â–ˆâ–ˆâ–ˆâ–      | 242/750 [08:20<17:13,  2.03s/it]\n",
            " 32%|â–ˆâ–ˆâ–ˆâ–      | 243/750 [08:22<17:06,  2.02s/it]\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–      | 244/750 [08:24<17:09,  2.03s/it]\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–      | 245/750 [08:26<17:10,  2.04s/it]\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–      | 246/750 [08:28<17:07,  2.04s/it]\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–      | 247/750 [08:30<17:11,  2.05s/it]\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–      | 248/750 [08:32<17:12,  2.06s/it]\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–      | 249/750 [08:34<17:08,  2.05s/it]\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–      | 250/750 [08:36<17:01,  2.04s/it]\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–      | 251/750 [08:38<16:55,  2.04s/it]\n",
            " 34%|â–ˆâ–ˆâ–ˆâ–      | 252/750 [08:40<16:53,  2.03s/it]\n",
            " 34%|â–ˆâ–ˆâ–ˆâ–      | 253/750 [08:43<17:39,  2.13s/it]\n",
            " 34%|â–ˆâ–ˆâ–ˆâ–      | 254/750 [08:45<17:24,  2.11s/it]\n",
            " 34%|â–ˆâ–ˆâ–ˆâ–      | 255/750 [08:47<17:15,  2.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:46:30. Total running time: 9min 0s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|â–ˆâ–ˆâ–ˆâ–      | 256/750 [08:49<17:08,  2.08s/it]\n",
            " 34%|â–ˆâ–ˆâ–ˆâ–      | 257/750 [08:51<16:56,  2.06s/it]\n",
            " 34%|â–ˆâ–ˆâ–ˆâ–      | 258/750 [08:53<16:46,  2.05s/it]\n",
            " 35%|â–ˆâ–ˆâ–ˆâ–      | 259/750 [08:55<16:43,  2.04s/it]\n",
            " 35%|â–ˆâ–ˆâ–ˆâ–      | 260/750 [08:57<16:40,  2.04s/it]\n",
            " 35%|â–ˆâ–ˆâ–ˆâ–      | 261/750 [08:59<16:37,  2.04s/it]\n",
            " 35%|â–ˆâ–ˆâ–ˆâ–      | 262/750 [09:01<16:35,  2.04s/it]\n",
            " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 263/750 [09:03<16:31,  2.04s/it]\n",
            " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 264/750 [09:05<16:24,  2.03s/it]\n",
            " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 265/750 [09:07<16:26,  2.03s/it]\n",
            " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 266/750 [09:09<16:24,  2.03s/it]\n",
            " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 267/750 [09:11<16:24,  2.04s/it]\n",
            " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 268/750 [09:13<16:21,  2.04s/it]\n",
            " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 269/750 [09:15<16:19,  2.04s/it]\n",
            " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 270/750 [09:17<16:12,  2.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:47:00. Total running time: 9min 30s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 271/750 [09:19<16:15,  2.04s/it]\n",
            " 36%|â–ˆâ–ˆâ–ˆâ–‹      | 272/750 [09:22<16:17,  2.05s/it]\n",
            " 36%|â–ˆâ–ˆâ–ˆâ–‹      | 273/750 [09:24<16:17,  2.05s/it]\n",
            " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 274/750 [09:26<16:14,  2.05s/it]\n",
            " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 275/750 [09:28<16:13,  2.05s/it]\n",
            " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 276/750 [09:30<16:05,  2.04s/it]\n",
            " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 277/750 [09:32<16:02,  2.03s/it]\n",
            " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 278/750 [09:34<16:01,  2.04s/it]\n",
            " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 279/750 [09:36<15:57,  2.03s/it]\n",
            " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 280/750 [09:38<15:57,  2.04s/it]\n",
            " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 281/750 [09:40<15:56,  2.04s/it]\n",
            " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 282/750 [09:42<15:57,  2.05s/it]\n",
            " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 283/750 [09:44<16:38,  2.14s/it]\n",
            " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 284/750 [09:46<16:24,  2.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:47:30. Total running time: 10min 0s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 285/750 [09:48<16:11,  2.09s/it]\n",
            " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 286/750 [09:50<16:07,  2.09s/it]\n",
            " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 287/750 [09:52<15:55,  2.06s/it]\n",
            " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 288/750 [09:54<15:48,  2.05s/it]\n",
            " 39%|â–ˆâ–ˆâ–ˆâ–Š      | 289/750 [09:57<15:44,  2.05s/it]\n",
            " 39%|â–ˆâ–ˆâ–ˆâ–Š      | 290/750 [09:59<15:43,  2.05s/it]\n",
            " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 291/750 [10:01<15:39,  2.05s/it]\n",
            " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 292/750 [10:03<15:44,  2.06s/it]\n",
            " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 293/750 [10:05<15:46,  2.07s/it]\n",
            " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 294/750 [10:07<15:42,  2.07s/it]\n",
            " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 295/750 [10:09<15:36,  2.06s/it]\n",
            " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 296/750 [10:11<15:33,  2.06s/it]\n",
            " 40%|â–ˆâ–ˆâ–ˆâ–‰      | 297/750 [10:13<15:29,  2.05s/it]\n",
            " 40%|â–ˆâ–ˆâ–ˆâ–‰      | 298/750 [10:15<15:24,  2.05s/it]\n",
            " 40%|â–ˆâ–ˆâ–ˆâ–‰      | 299/750 [10:17<15:23,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:48:00. Total running time: 10min 30s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 300/750 [10:19<15:22,  2.05s/it]\n",
            " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 301/750 [10:21<15:21,  2.05s/it]\n",
            " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 302/750 [10:23<15:18,  2.05s/it]\n",
            " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 303/750 [10:25<15:12,  2.04s/it]\n",
            " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 304/750 [10:27<15:10,  2.04s/it]\n",
            " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 305/750 [10:29<15:10,  2.05s/it]\n",
            " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 306/750 [10:31<15:09,  2.05s/it]\n",
            " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 307/750 [10:33<15:09,  2.05s/it]\n",
            " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 308/750 [10:36<15:06,  2.05s/it]\n",
            " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 309/750 [10:38<15:04,  2.05s/it]\n",
            " 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 310/750 [10:40<15:45,  2.15s/it]\n",
            " 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 311/750 [10:42<15:33,  2.13s/it]\n",
            " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 312/750 [10:44<15:21,  2.10s/it]\n",
            " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 313/750 [10:46<15:14,  2.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:48:30. Total running time: 11min 0s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 314/750 [10:48<15:04,  2.08s/it]\n",
            " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 315/750 [10:50<14:57,  2.06s/it]\n",
            " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 316/750 [10:52<14:50,  2.05s/it]\n",
            " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 317/750 [10:54<14:50,  2.06s/it]\n",
            " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 318/750 [10:56<14:50,  2.06s/it]\n",
            " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 319/750 [10:58<14:50,  2.07s/it]\n",
            " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 320/750 [11:01<14:47,  2.06s/it]\n",
            " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 321/750 [11:03<14:42,  2.06s/it]\n",
            " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 322/750 [11:05<14:36,  2.05s/it]\n",
            " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 323/750 [11:07<14:34,  2.05s/it]\n",
            " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 324/750 [11:09<14:28,  2.04s/it]\n",
            " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 325/750 [11:11<14:33,  2.06s/it]\n",
            " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 326/750 [11:13<14:31,  2.06s/it]\n",
            " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 327/750 [11:15<14:28,  2.05s/it]\n",
            " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 328/750 [11:17<14:27,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:49:00. Total running time: 11min 30s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 329/750 [11:19<14:26,  2.06s/it]\n",
            " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 330/750 [11:21<14:21,  2.05s/it]\n",
            " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 331/750 [11:23<14:23,  2.06s/it]\n",
            " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 332/750 [11:25<14:24,  2.07s/it]\n",
            " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 333/750 [11:27<14:25,  2.08s/it]\n",
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 334/750 [11:30<14:52,  2.14s/it]\n",
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 335/750 [11:32<14:35,  2.11s/it]\n",
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 336/750 [11:34<14:21,  2.08s/it]\n",
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 337/750 [11:36<14:19,  2.08s/it]\n",
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 338/750 [11:38<14:16,  2.08s/it]\n",
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 339/750 [11:40<14:12,  2.07s/it]\n",
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 340/750 [11:42<14:01,  2.05s/it]\n",
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 341/750 [11:44<13:57,  2.05s/it]\n",
            " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 342/750 [11:46<13:56,  2.05s/it]\n",
            " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 343/750 [11:48<13:49,  2.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:49:30. Total running time: 12min 0s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 344/750 [11:50<13:47,  2.04s/it]\n",
            " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 345/750 [11:52<13:53,  2.06s/it]\n",
            " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 346/750 [11:54<13:46,  2.05s/it]\n",
            " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 347/750 [11:56<13:48,  2.06s/it]\n",
            " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 348/750 [11:58<13:48,  2.06s/it]\n",
            " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 349/750 [12:00<13:44,  2.06s/it]\n",
            " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 350/750 [12:02<13:40,  2.05s/it]\n",
            " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 351/750 [12:04<13:44,  2.07s/it]\n",
            " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 352/750 [12:06<13:40,  2.06s/it]\n",
            " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 353/750 [12:09<13:39,  2.06s/it]\n",
            " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 354/750 [12:11<13:35,  2.06s/it]\n",
            " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 355/750 [12:13<13:33,  2.06s/it]\n",
            " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 356/750 [12:15<13:30,  2.06s/it]\n",
            " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 357/750 [12:17<13:29,  2.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:50:00. Total running time: 12min 30s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 358/750 [12:19<13:25,  2.06s/it]\n",
            " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 359/750 [12:21<13:18,  2.04s/it]\n",
            " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 360/750 [12:23<13:16,  2.04s/it]\n",
            " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 361/750 [12:25<13:15,  2.04s/it]\n",
            " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 362/750 [12:27<13:12,  2.04s/it]\n",
            " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 363/750 [12:29<13:15,  2.05s/it]\n",
            " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 364/750 [12:31<13:16,  2.06s/it]\n",
            " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 365/750 [12:33<13:48,  2.15s/it]\n",
            " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 366/750 [12:36<13:34,  2.12s/it]\n",
            " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 367/750 [12:38<13:22,  2.10s/it]\n",
            " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 368/750 [12:40<13:18,  2.09s/it]\n",
            " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 369/750 [12:42<13:14,  2.09s/it]\n",
            " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 370/750 [12:44<13:07,  2.07s/it]\n",
            " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 371/750 [12:46<13:08,  2.08s/it]\n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 372/750 [12:48<13:01,  2.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:50:30. Total running time: 13min 0s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 373/750 [12:50<12:55,  2.06s/it]\n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 374/750 [12:52<12:50,  2.05s/it]\n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 375/750 [12:53<10:05,  1.62s/it]\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m /usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            "  0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            "  2%|â–         | 2/125 [00:01<01:08,  1.79it/s]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            "  2%|â–         | 3/125 [00:02<01:36,  1.27it/s]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            "  3%|â–         | 4/125 [00:03<01:50,  1.10it/s]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            "  4%|â–         | 5/125 [00:04<01:56,  1.03it/s]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            "  5%|â–         | 6/125 [00:05<01:59,  1.01s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            "  6%|â–Œ         | 7/125 [00:06<02:02,  1.03s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            "  6%|â–‹         | 8/125 [00:07<02:02,  1.05s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            "  7%|â–‹         | 9/125 [00:08<02:03,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            "  8%|â–Š         | 10/125 [00:09<02:02,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            "  9%|â–‰         | 11/125 [00:10<02:01,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 10%|â–‰         | 12/125 [00:11<02:01,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 10%|â–ˆ         | 13/125 [00:13<02:00,  1.08s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 11%|â–ˆ         | 14/125 [00:14<02:00,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 12%|â–ˆâ–        | 15/125 [00:15<02:00,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 13%|â–ˆâ–        | 16/125 [00:16<01:59,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 14%|â–ˆâ–        | 17/125 [00:17<01:57,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 14%|â–ˆâ–        | 18/125 [00:18<01:56,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 15%|â–ˆâ–Œ        | 19/125 [00:19<01:55,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 16%|â–ˆâ–Œ        | 20/125 [00:20<01:55,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 17%|â–ˆâ–‹        | 21/125 [00:21<01:53,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 18%|â–ˆâ–Š        | 22/125 [00:22<01:52,  1.10s/it]\u001b[A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:51:00. Total running time: 13min 30s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 18%|â–ˆâ–Š        | 23/125 [00:24<01:51,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 19%|â–ˆâ–‰        | 24/125 [00:25<01:51,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 20%|â–ˆâ–ˆ        | 25/125 [00:26<01:49,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 21%|â–ˆâ–ˆ        | 26/125 [00:27<01:48,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 22%|â–ˆâ–ˆâ–       | 27/125 [00:28<01:48,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 22%|â–ˆâ–ˆâ–       | 28/125 [00:29<01:47,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 23%|â–ˆâ–ˆâ–       | 29/125 [00:30<01:45,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 24%|â–ˆâ–ˆâ–       | 30/125 [00:31<01:44,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 25%|â–ˆâ–ˆâ–       | 31/125 [00:32<01:43,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 26%|â–ˆâ–ˆâ–Œ       | 32/125 [00:34<01:43,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 26%|â–ˆâ–ˆâ–‹       | 33/125 [00:35<01:41,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 27%|â–ˆâ–ˆâ–‹       | 34/125 [00:36<01:40,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 28%|â–ˆâ–ˆâ–Š       | 35/125 [00:37<01:39,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 29%|â–ˆâ–ˆâ–‰       | 36/125 [00:38<01:37,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 30%|â–ˆâ–ˆâ–‰       | 37/125 [00:39<01:36,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 30%|â–ˆâ–ˆâ–ˆ       | 38/125 [00:40<01:36,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 31%|â–ˆâ–ˆâ–ˆ       | 39/125 [00:41<01:34,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 32%|â–ˆâ–ˆâ–ˆâ–      | 40/125 [00:42<01:33,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 33%|â–ˆâ–ˆâ–ˆâ–      | 41/125 [00:43<01:31,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 34%|â–ˆâ–ˆâ–ˆâ–      | 42/125 [00:44<01:30,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 34%|â–ˆâ–ˆâ–ˆâ–      | 43/125 [00:46<01:29,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 44/125 [00:47<01:28,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 45/125 [00:48<01:28,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 46/125 [00:49<01:26,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 47/125 [00:50<01:24,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 48/125 [00:51<01:24,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 49/125 [00:52<01:23,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:51:30. Total running time: 14min 0s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \r 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 50/125 [00:53<01:21,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 51/125 [00:54<01:21,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 52/125 [00:55<01:20,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 53/125 [00:57<01:18,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 54/125 [00:58<01:17,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 55/125 [00:59<01:17,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 56/125 [01:00<01:17,  1.12s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 57/125 [01:01<01:15,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 58/125 [01:02<01:13,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 59/125 [01:03<01:12,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 60/125 [01:04<01:10,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 61/125 [01:05<01:10,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 62/125 [01:06<01:09,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 63/125 [01:08<01:08,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 64/125 [01:09<01:07,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 65/125 [01:10<01:05,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 66/125 [01:11<01:04,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 67/125 [01:12<01:03,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 68/125 [01:13<01:02,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 69/125 [01:14<01:01,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 70/125 [01:15<01:00,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 71/125 [01:16<00:58,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 72/125 [01:17<00:57,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 73/125 [01:18<00:56,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 74/125 [01:20<00:55,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 75/125 [01:21<00:54,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 76/125 [01:22<00:54,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 77/125 [01:23<00:52,  1.10s/it]\u001b[A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:52:00. Total running time: 14min 30s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 78/125 [01:24<00:50,  1.08s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 79/125 [01:25<00:53,  1.17s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 80/125 [01:26<00:51,  1.14s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 81/125 [01:27<00:49,  1.13s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 82/125 [01:29<00:47,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 83/125 [01:30<00:46,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 84/125 [01:31<00:45,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 85/125 [01:32<00:43,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 86/125 [01:33<00:42,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 87/125 [01:34<00:41,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 88/125 [01:35<00:40,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 89/125 [01:36<00:39,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 90/125 [01:37<00:38,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 91/125 [01:38<00:37,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 92/125 [01:39<00:36,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 93/125 [01:41<00:35,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 94/125 [01:42<00:33,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 95/125 [01:43<00:32,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 96/125 [01:44<00:31,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 97/125 [01:45<00:30,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 98/125 [01:46<00:29,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 99/125 [01:47<00:28,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 100/125 [01:48<00:27,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 101/125 [01:49<00:26,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 102/125 [01:50<00:25,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 103/125 [01:51<00:23,  1.08s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 104/125 [01:53<00:22,  1.09s/it]\u001b[A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:52:30. Total running time: 15min 0s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275 |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 105/125 [01:54<00:21,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 106/125 [01:55<00:20,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 107/125 [01:56<00:19,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 108/125 [01:57<00:18,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 109/125 [01:58<00:17,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 110/125 [01:59<00:16,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 111/125 [02:00<00:15,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 112/125 [02:01<00:14,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 113/125 [02:02<00:13,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 114/125 [02:04<00:11,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 115/125 [02:05<00:10,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 116/125 [02:06<00:09,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 117/125 [02:07<00:08,  1.08s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 118/125 [02:08<00:07,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 119/125 [02:09<00:06,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 120/125 [02:10<00:05,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 121/125 [02:11<00:04,  1.08s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 122/125 [02:12<00:03,  1.08s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 123/125 [02:13<00:02,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 124/125 [02:14<00:01,  1.10s/it]\u001b[AThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [02:15<00:00,  1.12it/s]\u001b[A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial _objective_15fb9_00000 finished iteration 1 at 2024-08-17 11:52:55. Total running time: 15min 25s\n",
            "+-------------------------------------------------+\n",
            "| Trial _objective_15fb9_00000 result             |\n",
            "+-------------------------------------------------+\n",
            "| checkpoint_dir_name                             |\n",
            "| time_this_iter_s                        922.143 |\n",
            "| time_total_s                            922.143 |\n",
            "| training_iteration                            1 |\n",
            "| epoch                                         1 |\n",
            "| eval_gen_len                                 19 |\n",
            "| eval_loss                                1.1345 |\n",
            "| eval_rouge1                             26.5934 |\n",
            "| eval_rouge2                              8.4223 |\n",
            "| eval_rougeL                             23.0981 |\n",
            "| eval_rougeLsum                           25.366 |\n",
            "| eval_runtime                            140.556 |\n",
            "| eval_samples_per_second                   7.115 |\n",
            "| eval_steps_per_second                     0.889 |\n",
            "| objective                                102.48 |\n",
            "+-------------------------------------------------+\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m {'eval_loss': 1.13450026512146, 'eval_rouge1': 26.5934, 'eval_rouge2': 8.4223, 'eval_rougeL': 23.0981, 'eval_rougeLsum': 25.366, 'eval_gen_len': 19.0, 'eval_runtime': 140.5559, 'eval_samples_per_second': 7.115, 'eval_steps_per_second': 0.889, 'epoch': 1.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_objective pid=10843)\u001b[0m \r                                                 \n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \r                                                 \r\u001b[A\r 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 375/750 [15:13<10:05,  1.62s/it]\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \r100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [02:18<00:00,  1.12it/s]\u001b[A\n",
            "                                                 \u001b[A\n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 376/750 [15:16<4:36:09, 44.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:53:00. Total running time: 15min 30s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722        1            922.143        1.1345         26.5934          8.4223         23.0981 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 377/750 [15:19<3:16:35, 31.62s/it]\n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 378/750 [15:21<2:21:04, 22.75s/it]\n",
            " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 379/750 [15:23<1:42:17, 16.54s/it]\n",
            " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 380/750 [15:25<1:15:09, 12.19s/it]\n",
            " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 381/750 [15:27<56:11,  9.14s/it]  \n",
            " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 382/750 [15:29<42:54,  7.00s/it]\n",
            " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 383/750 [15:31<33:39,  5.50s/it]\n",
            " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 384/750 [15:33<27:13,  4.46s/it]\n",
            " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 385/750 [15:35<22:47,  3.75s/it]\n",
            " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 386/750 [15:37<19:35,  3.23s/it]\n",
            " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 387/750 [15:39<17:25,  2.88s/it]\n",
            " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 388/750 [15:41<15:48,  2.62s/it]\n",
            " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 389/750 [15:43<14:39,  2.44s/it]\n",
            " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 390/750 [15:45<13:55,  2.32s/it]\n",
            " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 391/750 [15:47<13:53,  2.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:53:30. Total running time: 16min 0s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722        1            922.143        1.1345         26.5934          8.4223         23.0981 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 392/750 [15:49<13:25,  2.25s/it]\n",
            " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 393/750 [15:51<13:08,  2.21s/it]\n",
            " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 394/750 [15:54<12:47,  2.16s/it]\n",
            " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 395/750 [15:56<12:29,  2.11s/it]\n",
            " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 396/750 [15:58<12:16,  2.08s/it]\n",
            " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 397/750 [16:00<12:04,  2.05s/it]\n",
            " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 398/750 [16:02<11:56,  2.03s/it]\n",
            " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 399/750 [16:04<11:53,  2.03s/it]\n",
            " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 400/750 [16:06<11:53,  2.04s/it]\n",
            " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 401/750 [16:08<11:49,  2.03s/it]\n",
            " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 402/750 [16:10<11:50,  2.04s/it]\n",
            " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 403/750 [16:12<11:47,  2.04s/it]\n",
            " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 404/750 [16:14<11:40,  2.03s/it]\n",
            " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 405/750 [16:16<11:41,  2.03s/it]\n",
            " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 406/750 [16:18<11:38,  2.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:54:00. Total running time: 16min 30s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722        1            922.143        1.1345         26.5934          8.4223         23.0981 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 407/750 [16:20<11:34,  2.03s/it]\n",
            " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 408/750 [16:22<11:33,  2.03s/it]\n",
            " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 409/750 [16:24<11:29,  2.02s/it]\n",
            " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 410/750 [16:26<11:27,  2.02s/it]\n",
            " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 411/750 [16:28<11:32,  2.04s/it]\n",
            " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 412/750 [16:30<11:35,  2.06s/it]\n",
            " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 413/750 [16:32<11:30,  2.05s/it]\n",
            " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 414/750 [16:34<11:26,  2.04s/it]\n",
            " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 415/750 [16:36<11:25,  2.05s/it]\n",
            " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 416/750 [16:38<11:21,  2.04s/it]\n",
            " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 417/750 [16:40<11:18,  2.04s/it]\n",
            " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 418/750 [16:43<11:45,  2.12s/it]\n",
            " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 419/750 [16:45<11:32,  2.09s/it]\n",
            " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 420/750 [16:47<11:22,  2.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:54:31. Total running time: 17min 0s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722        1            922.143        1.1345         26.5934          8.4223         23.0981 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 421/750 [16:49<11:15,  2.05s/it]\n",
            " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 422/750 [16:51<11:12,  2.05s/it]\n",
            " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 423/750 [16:53<11:08,  2.05s/it]\n",
            " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 424/750 [16:55<11:04,  2.04s/it]\n",
            " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 425/750 [16:57<11:03,  2.04s/it]\n",
            " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 426/750 [16:59<11:04,  2.05s/it]\n",
            " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 427/750 [17:01<11:01,  2.05s/it]\n",
            " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 428/750 [17:03<10:55,  2.04s/it]\n",
            " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 429/750 [17:05<10:49,  2.02s/it]\n",
            " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 430/750 [17:07<10:47,  2.02s/it]\n",
            " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 431/750 [17:09<10:44,  2.02s/it]\n",
            " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 432/750 [17:11<10:46,  2.03s/it]\n",
            " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 433/750 [17:13<10:45,  2.04s/it]\n",
            " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 434/750 [17:15<10:41,  2.03s/it]\n",
            " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 435/750 [17:17<10:39,  2.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:55:01. Total running time: 17min 30s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722        1            922.143        1.1345         26.5934          8.4223         23.0981 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 436/750 [17:19<10:37,  2.03s/it]\n",
            " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 437/750 [17:21<10:41,  2.05s/it]\n",
            " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 438/750 [17:23<10:44,  2.07s/it]\n",
            " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 439/750 [17:25<10:43,  2.07s/it]\n",
            " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 440/750 [17:27<10:38,  2.06s/it]\n",
            " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 441/750 [17:29<10:33,  2.05s/it]\n",
            " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 442/750 [17:32<10:56,  2.13s/it]\n",
            " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 443/750 [17:34<10:48,  2.11s/it]\n",
            " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 444/750 [17:36<10:41,  2.10s/it]\n",
            " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 445/750 [17:38<10:34,  2.08s/it]\n",
            " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 446/750 [17:40<10:28,  2.07s/it]\n",
            " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 447/750 [17:42<10:21,  2.05s/it]\n",
            " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 448/750 [17:44<10:20,  2.06s/it]\n",
            " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 449/750 [17:46<10:16,  2.05s/it]\n",
            " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 450/750 [17:48<10:13,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:55:31. Total running time: 18min 0s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722        1            922.143        1.1345         26.5934          8.4223         23.0981 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 451/750 [17:50<10:10,  2.04s/it]\n",
            " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 452/750 [17:52<10:09,  2.04s/it]\n",
            " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 453/750 [17:54<10:07,  2.04s/it]\n",
            " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 454/750 [17:56<10:04,  2.04s/it]\n",
            " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 455/750 [17:58<09:59,  2.03s/it]\n",
            " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 456/750 [18:00<09:55,  2.02s/it]\n",
            " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 457/750 [18:02<09:50,  2.02s/it]\n",
            " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 458/750 [18:04<09:47,  2.01s/it]\n",
            " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 459/750 [18:06<09:40,  2.00s/it]\n",
            " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 460/750 [18:08<09:42,  2.01s/it]\n",
            " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 461/750 [18:10<09:46,  2.03s/it]\n",
            " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 462/750 [18:12<09:47,  2.04s/it]\n",
            " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 463/750 [18:14<09:44,  2.04s/it]\n",
            " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 464/750 [18:16<09:45,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:56:01. Total running time: 18min 30s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722        1            922.143        1.1345         26.5934          8.4223         23.0981 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 465/750 [18:19<09:42,  2.04s/it]\n",
            " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 466/750 [18:21<09:39,  2.04s/it]\n",
            " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 467/750 [18:23<09:35,  2.03s/it]\n",
            " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 468/750 [18:25<09:32,  2.03s/it]\n",
            " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 469/750 [18:27<09:28,  2.02s/it]\n",
            " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 470/750 [18:29<09:27,  2.03s/it]\n",
            " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 471/750 [18:31<09:26,  2.03s/it]\n",
            " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 472/750 [18:33<09:25,  2.03s/it]\n",
            " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 473/750 [18:35<09:24,  2.04s/it]\n",
            " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 474/750 [18:37<09:45,  2.12s/it]\n",
            " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 475/750 [18:39<09:37,  2.10s/it]\n",
            " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 476/750 [18:41<09:33,  2.09s/it]\n",
            " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 477/750 [18:43<09:27,  2.08s/it]\n",
            " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 478/750 [18:45<09:20,  2.06s/it]\n",
            " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 479/750 [18:47<09:16,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:56:31. Total running time: 19min 0s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722        1            922.143        1.1345         26.5934          8.4223         23.0981 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 480/750 [18:49<09:12,  2.05s/it]\n",
            " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 481/750 [18:51<09:10,  2.05s/it]\n",
            " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 482/750 [18:53<09:08,  2.05s/it]\n",
            " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 483/750 [18:56<09:07,  2.05s/it]\n",
            " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 484/750 [18:58<09:06,  2.05s/it]\n",
            " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 485/750 [19:00<09:01,  2.04s/it]\n",
            " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 486/750 [19:02<08:55,  2.03s/it]\n",
            " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 487/750 [19:04<08:50,  2.02s/it]\n",
            " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 488/750 [19:06<08:47,  2.01s/it]\n",
            " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 489/750 [19:08<08:46,  2.02s/it]\n",
            " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 490/750 [19:10<08:45,  2.02s/it]\n",
            " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 491/750 [19:12<08:48,  2.04s/it]\n",
            " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 492/750 [19:14<08:46,  2.04s/it]\n",
            " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 493/750 [19:16<08:45,  2.04s/it]\n",
            " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 494/750 [19:18<08:44,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:57:01. Total running time: 19min 30s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722        1            922.143        1.1345         26.5934          8.4223         23.0981 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 495/750 [19:20<08:39,  2.04s/it]\n",
            " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 496/750 [19:22<08:38,  2.04s/it]\n",
            " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 497/750 [19:24<08:34,  2.04s/it]\n",
            " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 498/750 [19:26<08:29,  2.02s/it]\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 499/750 [19:28<08:29,  2.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_objective pid=10843)\u001b[0m {'loss': 1.2221, 'grad_norm': 2.7870452404022217, 'learning_rate': 1.4428167404312914e-05, 'epoch': 1.33}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 500/750 [19:30<08:27,  2.03s/it]\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 501/750 [19:43<21:51,  5.27s/it]\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 502/750 [19:45<18:08,  4.39s/it]\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 503/750 [19:47<15:10,  3.69s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:57:31. Total running time: 20min 0s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722        1            922.143        1.1345         26.5934          8.4223         23.0981 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 504/750 [19:49<13:05,  3.19s/it]\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 505/750 [19:51<11:39,  2.86s/it]\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 506/750 [19:53<10:36,  2.61s/it]\n",
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 507/750 [19:55<09:49,  2.43s/it]\n",
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 508/750 [19:57<09:18,  2.31s/it]\n",
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 509/750 [19:59<08:55,  2.22s/it]\n",
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 510/750 [20:01<08:36,  2.15s/it]\n",
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 511/750 [20:03<08:28,  2.13s/it]\n",
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 512/750 [20:05<08:17,  2.09s/it]\n",
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 513/750 [20:08<08:09,  2.07s/it]\n",
            " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 514/750 [20:10<08:07,  2.06s/it]\n",
            " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 515/750 [20:12<08:02,  2.05s/it]\n",
            " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 516/750 [20:14<08:00,  2.05s/it]\n",
            " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 517/750 [20:16<07:58,  2.06s/it]\n",
            " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 518/750 [20:18<07:55,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:58:01. Total running time: 20min 31s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722        1            922.143        1.1345         26.5934          8.4223         23.0981 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 519/750 [20:20<07:50,  2.03s/it]\n",
            " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 520/750 [20:22<07:47,  2.03s/it]\n",
            " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 521/750 [20:24<07:45,  2.03s/it]\n",
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 522/750 [20:26<07:43,  2.03s/it]\n",
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 523/750 [20:28<07:44,  2.05s/it]\n",
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 524/750 [20:30<07:42,  2.05s/it]\n",
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 525/750 [20:32<07:39,  2.04s/it]\n",
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 526/750 [20:34<07:37,  2.04s/it]\n",
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 527/750 [20:36<07:34,  2.04s/it]\n",
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 528/750 [20:38<07:33,  2.04s/it]\n",
            " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 529/750 [20:40<07:53,  2.14s/it]\n",
            " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 530/750 [20:42<07:41,  2.10s/it]\n",
            " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 531/750 [20:44<07:33,  2.07s/it]\n",
            " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 532/750 [20:47<07:27,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:58:31. Total running time: 21min 1s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722        1            922.143        1.1345         26.5934          8.4223         23.0981 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 533/750 [20:49<07:24,  2.05s/it]\n",
            " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 534/750 [20:51<07:20,  2.04s/it]\n",
            " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 535/750 [20:53<07:17,  2.03s/it]\n",
            " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 536/750 [20:55<07:16,  2.04s/it]\n",
            " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 537/750 [20:57<07:15,  2.04s/it]\n",
            " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 538/750 [20:59<07:12,  2.04s/it]\n",
            " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 539/750 [21:01<07:08,  2.03s/it]\n",
            " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 540/750 [21:03<07:04,  2.02s/it]\n",
            " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 541/750 [21:05<07:04,  2.03s/it]\n",
            " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 542/750 [21:07<07:00,  2.02s/it]\n",
            " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 543/750 [21:09<07:00,  2.03s/it]\n",
            " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 544/750 [21:11<06:57,  2.03s/it]\n",
            " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 545/750 [21:13<06:52,  2.01s/it]\n",
            " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 546/750 [21:15<06:51,  2.02s/it]\n",
            " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 547/750 [21:17<06:48,  2.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:59:01. Total running time: 21min 31s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722        1            922.143        1.1345         26.5934          8.4223         23.0981 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 548/750 [21:19<06:48,  2.02s/it]\n",
            " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 549/750 [21:21<06:44,  2.01s/it]\n",
            " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 550/750 [21:23<06:43,  2.02s/it]\n",
            " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 551/750 [21:25<06:41,  2.02s/it]\n",
            " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 552/750 [21:27<06:38,  2.01s/it]\n",
            " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 553/750 [21:29<06:38,  2.02s/it]\n",
            " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 554/750 [21:31<06:53,  2.11s/it]\n",
            " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 555/750 [21:33<06:47,  2.09s/it]\n",
            " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 556/750 [21:35<06:43,  2.08s/it]\n",
            " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 557/750 [21:37<06:38,  2.06s/it]\n",
            " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 558/750 [21:39<06:35,  2.06s/it]\n",
            " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 559/750 [21:42<06:31,  2.05s/it]\n",
            " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 560/750 [21:44<06:28,  2.04s/it]\n",
            " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 561/750 [21:46<06:26,  2.04s/it]\n",
            " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 562/750 [21:48<06:24,  2.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 11:59:31. Total running time: 22min 1s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722        1            922.143        1.1345         26.5934          8.4223         23.0981 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 563/750 [21:50<06:23,  2.05s/it]\n",
            " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 564/750 [21:52<06:20,  2.04s/it]\n",
            " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 565/750 [21:54<06:16,  2.04s/it]\n",
            " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 566/750 [21:56<06:15,  2.04s/it]\n",
            " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 567/750 [21:58<06:11,  2.03s/it]\n",
            " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 568/750 [22:00<06:09,  2.03s/it]\n",
            " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 569/750 [22:02<06:08,  2.03s/it]\n",
            " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 570/750 [22:04<06:06,  2.04s/it]\n",
            " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 571/750 [22:06<06:04,  2.04s/it]\n",
            " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 572/750 [22:08<05:59,  2.02s/it]\n",
            " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 573/750 [22:10<05:57,  2.02s/it]\n",
            " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 574/750 [22:12<05:55,  2.02s/it]\n",
            " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 575/750 [22:14<05:55,  2.03s/it]\n",
            " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 576/750 [22:16<05:55,  2.04s/it]\n",
            " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 577/750 [22:18<05:50,  2.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 12:00:01. Total running time: 22min 31s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722        1            922.143        1.1345         26.5934          8.4223         23.0981 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 578/750 [22:20<05:48,  2.03s/it]\n",
            " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 579/750 [22:22<05:45,  2.02s/it]\n",
            " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 580/750 [22:24<05:43,  2.02s/it]\n",
            " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 581/750 [22:26<05:41,  2.02s/it]\n",
            " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 582/750 [22:28<05:40,  2.03s/it]\n",
            " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 583/750 [22:30<05:38,  2.03s/it]\n",
            " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 584/750 [22:32<05:36,  2.03s/it]\n",
            " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 585/750 [22:34<05:34,  2.03s/it]\n",
            " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 586/750 [22:36<05:31,  2.02s/it]\n",
            " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 587/750 [22:39<05:44,  2.12s/it]\n",
            " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 588/750 [22:41<05:39,  2.10s/it]\n",
            " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 589/750 [22:43<05:35,  2.09s/it]\n",
            " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 590/750 [22:45<05:32,  2.08s/it]\n",
            " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 591/750 [22:47<05:27,  2.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 12:00:31. Total running time: 23min 1s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722        1            922.143        1.1345         26.5934          8.4223         23.0981 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 592/750 [22:49<05:23,  2.04s/it]\n",
            " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 593/750 [22:51<05:21,  2.05s/it]\n",
            " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 594/750 [22:53<05:20,  2.05s/it]\n",
            " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 595/750 [22:55<05:18,  2.05s/it]\n",
            " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 596/750 [22:57<05:15,  2.05s/it]\n",
            " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 597/750 [22:59<05:11,  2.04s/it]\n",
            " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 598/750 [23:01<05:09,  2.04s/it]\n",
            " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 599/750 [23:03<05:08,  2.04s/it]\n",
            " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 600/750 [23:05<05:05,  2.04s/it]\n",
            " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 601/750 [23:07<05:06,  2.06s/it]\n",
            " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 602/750 [23:09<05:02,  2.05s/it]\n",
            " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 603/750 [23:11<04:58,  2.03s/it]\n",
            " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 604/750 [23:13<04:57,  2.04s/it]\n",
            " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 605/750 [23:15<04:54,  2.03s/it]\n",
            " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 606/750 [23:17<04:53,  2.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 12:01:01. Total running time: 23min 31s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722        1            922.143        1.1345         26.5934          8.4223         23.0981 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 607/750 [23:19<04:49,  2.03s/it]\n",
            " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 608/750 [23:21<04:48,  2.03s/it]\n",
            " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 609/750 [23:23<04:46,  2.03s/it]\n",
            " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 610/750 [23:25<04:43,  2.03s/it]\n",
            " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 611/750 [23:28<04:41,  2.03s/it]\n",
            " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 612/750 [23:30<04:41,  2.04s/it]\n",
            " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 613/750 [23:32<04:38,  2.03s/it]\n",
            " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 614/750 [23:34<04:38,  2.04s/it]\n",
            " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 615/750 [23:36<04:49,  2.15s/it]\n",
            " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 616/750 [23:38<04:43,  2.11s/it]\n",
            " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 617/750 [23:40<04:38,  2.09s/it]\n",
            " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 618/750 [23:42<04:34,  2.08s/it]\n",
            " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 619/750 [23:44<04:30,  2.06s/it]\n",
            " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 620/750 [23:46<04:27,  2.06s/it]\n",
            " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 621/750 [23:48<04:25,  2.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 12:01:31. Total running time: 24min 1s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722        1            922.143        1.1345         26.5934          8.4223         23.0981 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 622/750 [23:50<04:23,  2.06s/it]\n",
            " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 623/750 [23:52<04:19,  2.05s/it]\n",
            " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 624/750 [23:54<04:17,  2.04s/it]\n",
            " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 625/750 [23:56<04:14,  2.04s/it]\n",
            " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 626/750 [23:58<04:10,  2.02s/it]\n",
            " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 627/750 [24:00<04:09,  2.03s/it]\n",
            " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 628/750 [24:03<04:08,  2.04s/it]\n",
            " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 629/750 [24:05<04:06,  2.04s/it]\n",
            " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 630/750 [24:07<04:05,  2.05s/it]\n",
            " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 631/750 [24:09<04:03,  2.05s/it]\n",
            " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 632/750 [24:11<04:00,  2.04s/it]\n",
            " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 633/750 [24:13<03:57,  2.03s/it]\n",
            " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 634/750 [24:15<03:54,  2.02s/it]\n",
            " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 635/750 [24:17<03:51,  2.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 12:02:01. Total running time: 24min 31s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722        1            922.143        1.1345         26.5934          8.4223         23.0981 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 636/750 [24:19<03:49,  2.02s/it]\n",
            " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 637/750 [24:21<03:48,  2.02s/it]\n",
            " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 638/750 [24:23<03:47,  2.03s/it]\n",
            " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 639/750 [24:25<03:46,  2.04s/it]\n",
            " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 640/750 [24:27<03:43,  2.03s/it]\n",
            " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 641/750 [24:29<03:41,  2.04s/it]\n",
            " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 642/750 [24:31<03:49,  2.13s/it]\n",
            " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 643/750 [24:33<03:45,  2.11s/it]\n",
            " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 644/750 [24:35<03:40,  2.08s/it]\n",
            " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 645/750 [24:37<03:37,  2.07s/it]\n",
            " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 646/750 [24:39<03:34,  2.06s/it]\n",
            " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 647/750 [24:42<03:32,  2.06s/it]\n",
            " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 648/750 [24:44<03:29,  2.06s/it]\n",
            " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 649/750 [24:46<03:26,  2.05s/it]\n",
            " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 650/750 [24:48<03:24,  2.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 12:02:31. Total running time: 25min 1s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722        1            922.143        1.1345         26.5934          8.4223         23.0981 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 651/750 [24:50<03:22,  2.04s/it]\n",
            " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 652/750 [24:52<03:19,  2.04s/it]\n",
            " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 653/750 [24:54<03:18,  2.04s/it]\n",
            " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 654/750 [24:56<03:16,  2.05s/it]\n",
            " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 655/750 [24:58<03:13,  2.04s/it]\n",
            " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 656/750 [25:00<03:11,  2.04s/it]\n",
            " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 657/750 [25:02<03:09,  2.03s/it]\n",
            " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 658/750 [25:04<03:07,  2.03s/it]\n",
            " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 659/750 [25:06<03:05,  2.04s/it]\n",
            " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 660/750 [25:08<03:04,  2.05s/it]\n",
            " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 661/750 [25:10<03:02,  2.05s/it]\n",
            " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 662/750 [25:12<02:59,  2.04s/it]\n",
            " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 663/750 [25:14<02:56,  2.03s/it]\n",
            " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 664/750 [25:16<02:53,  2.02s/it]\n",
            " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 665/750 [25:18<02:51,  2.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 12:03:01. Total running time: 25min 31s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722        1            922.143        1.1345         26.5934          8.4223         23.0981 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 666/750 [25:20<02:57,  2.11s/it]\n",
            " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 667/750 [25:22<02:53,  2.09s/it]\n",
            " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 668/750 [25:25<02:50,  2.08s/it]\n",
            " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 669/750 [25:27<02:48,  2.07s/it]\n",
            " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 670/750 [25:29<02:44,  2.06s/it]\n",
            " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 671/750 [25:31<02:42,  2.05s/it]\n",
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 672/750 [25:33<02:39,  2.05s/it]\n",
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 673/750 [25:35<02:37,  2.04s/it]\n",
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 674/750 [25:37<02:35,  2.04s/it]\n",
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 675/750 [25:39<02:33,  2.05s/it]\n",
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 676/750 [25:41<02:31,  2.05s/it]\n",
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 677/750 [25:43<02:29,  2.04s/it]\n",
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 678/750 [25:45<02:27,  2.05s/it]\n",
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 679/750 [25:47<02:25,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 12:03:31. Total running time: 26min 1s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722        1            922.143        1.1345         26.5934          8.4223         23.0981 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 680/750 [25:49<02:23,  2.05s/it]\n",
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 681/750 [25:51<02:21,  2.04s/it]\n",
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 682/750 [25:53<02:19,  2.05s/it]\n",
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 683/750 [25:55<02:17,  2.05s/it]\n",
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 684/750 [25:57<02:15,  2.06s/it]\n",
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 685/750 [25:59<02:12,  2.04s/it]\n",
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 686/750 [26:01<02:10,  2.04s/it]\n",
            " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 687/750 [26:03<02:08,  2.04s/it]\n",
            " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 688/750 [26:05<02:06,  2.05s/it]\n",
            " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 689/750 [26:07<02:04,  2.05s/it]\n",
            " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 690/750 [26:10<02:02,  2.05s/it]\n",
            " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 691/750 [26:12<02:01,  2.05s/it]\n",
            " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 692/750 [26:14<01:58,  2.04s/it]\n",
            " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 693/750 [26:16<01:56,  2.04s/it]\n",
            " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 694/750 [26:18<01:53,  2.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 12:04:01. Total running time: 26min 31s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722        1            922.143        1.1345         26.5934          8.4223         23.0981 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 695/750 [26:20<01:51,  2.02s/it]\n",
            " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 696/750 [26:22<01:50,  2.04s/it]\n",
            " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 697/750 [26:24<01:47,  2.04s/it]\n",
            " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 698/750 [26:26<01:46,  2.04s/it]\n",
            " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 699/750 [26:28<01:48,  2.13s/it]\n",
            " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 700/750 [26:30<01:45,  2.11s/it]\n",
            " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 701/750 [26:32<01:41,  2.08s/it]\n",
            " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 702/750 [26:34<01:39,  2.06s/it]\n",
            " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 703/750 [26:36<01:36,  2.05s/it]\n",
            " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 704/750 [26:38<01:34,  2.05s/it]\n",
            " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 705/750 [26:40<01:32,  2.05s/it]\n",
            " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 706/750 [26:42<01:29,  2.04s/it]\n",
            " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 707/750 [26:44<01:27,  2.04s/it]\n",
            " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 708/750 [26:46<01:25,  2.03s/it]\n",
            " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 709/750 [26:48<01:23,  2.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 12:04:31. Total running time: 27min 1s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722        1            922.143        1.1345         26.5934          8.4223         23.0981 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 710/750 [26:51<01:21,  2.04s/it]\n",
            " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 711/750 [26:53<01:19,  2.05s/it]\n",
            " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 712/750 [26:55<01:17,  2.05s/it]\n",
            " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 713/750 [26:57<01:15,  2.04s/it]\n",
            " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 714/750 [26:59<01:13,  2.03s/it]\n",
            " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 715/750 [27:01<01:10,  2.03s/it]\n",
            " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 716/750 [27:03<01:09,  2.03s/it]\n",
            " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 717/750 [27:05<01:06,  2.03s/it]\n",
            " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 718/750 [27:07<01:05,  2.04s/it]\n",
            " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 719/750 [27:09<01:03,  2.04s/it]\n",
            " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 720/750 [27:11<01:01,  2.04s/it]\n",
            " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 721/750 [27:13<00:59,  2.04s/it]\n",
            " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 722/750 [27:15<00:56,  2.03s/it]\n",
            " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 723/750 [27:17<00:54,  2.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 12:05:01. Total running time: 27min 31s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722        1            922.143        1.1345         26.5934          8.4223         23.0981 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 724/750 [27:19<00:52,  2.01s/it]\n",
            " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 725/750 [27:21<00:50,  2.02s/it]\n",
            " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 726/750 [27:23<00:48,  2.02s/it]\n",
            " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 727/750 [27:25<00:48,  2.10s/it]\n",
            " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 728/750 [27:27<00:45,  2.09s/it]\n",
            " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 729/750 [27:29<00:43,  2.08s/it]\n",
            " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 730/750 [27:31<00:41,  2.07s/it]\n",
            " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 731/750 [27:33<00:39,  2.07s/it]\n",
            " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 732/750 [27:36<00:37,  2.06s/it]\n",
            " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 733/750 [27:38<00:35,  2.06s/it]\n",
            " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 734/750 [27:40<00:33,  2.06s/it]\n",
            " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 735/750 [27:42<00:30,  2.05s/it]\n",
            " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 736/750 [27:44<00:28,  2.04s/it]\n",
            " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 737/750 [27:46<00:26,  2.05s/it]\n",
            " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 738/750 [27:48<00:24,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 12:05:31. Total running time: 28min 1s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722        1            922.143        1.1345         26.5934          8.4223         23.0981 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 739/750 [27:50<00:22,  2.05s/it]\n",
            " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 740/750 [27:52<00:20,  2.04s/it]\n",
            " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 741/750 [27:54<00:18,  2.04s/it]\n",
            " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 742/750 [27:56<00:16,  2.04s/it]\n",
            " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 743/750 [27:58<00:14,  2.04s/it]\n",
            " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 744/750 [28:00<00:12,  2.04s/it]\n",
            " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 745/750 [28:02<00:10,  2.05s/it]\n",
            " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 746/750 [28:04<00:08,  2.04s/it]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 747/750 [28:06<00:06,  2.05s/it]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 748/750 [28:08<00:04,  2.04s/it]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 749/750 [28:10<00:02,  2.04s/it]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 750/750 [28:11<00:00,  1.61s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 12:06:01. Total running time: 28min 31s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722        1            922.143        1.1345         26.5934          8.4223         23.0981 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m /usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            "  0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            "  2%|â–         | 2/125 [00:01<01:09,  1.77it/s]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            "  2%|â–         | 3/125 [00:02<01:35,  1.28it/s]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            "  3%|â–         | 4/125 [00:03<01:48,  1.11it/s]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            "  4%|â–         | 5/125 [00:04<01:57,  1.02it/s]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            "  5%|â–         | 6/125 [00:05<02:01,  1.02s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            "  6%|â–Œ         | 7/125 [00:06<02:05,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            "  6%|â–‹         | 8/125 [00:07<02:06,  1.08s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            "  7%|â–‹         | 9/125 [00:08<02:08,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            "  8%|â–Š         | 10/125 [00:10<02:07,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            "  9%|â–‰         | 11/125 [00:11<02:07,  1.12s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 10%|â–‰         | 12/125 [00:12<02:06,  1.12s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 10%|â–ˆ         | 13/125 [00:13<02:04,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 11%|â–ˆ         | 14/125 [00:14<02:02,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 12%|â–ˆâ–        | 15/125 [00:15<02:01,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 13%|â–ˆâ–        | 16/125 [00:16<01:59,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 14%|â–ˆâ–        | 17/125 [00:17<01:58,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 14%|â–ˆâ–        | 18/125 [00:19<02:06,  1.18s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 15%|â–ˆâ–Œ        | 19/125 [00:20<02:03,  1.17s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 16%|â–ˆâ–Œ        | 20/125 [00:21<02:02,  1.17s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 17%|â–ˆâ–‹        | 21/125 [00:22<02:01,  1.17s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 18%|â–ˆâ–Š        | 22/125 [00:23<01:58,  1.15s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 18%|â–ˆâ–Š        | 23/125 [00:24<01:55,  1.13s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 19%|â–ˆâ–‰        | 24/125 [00:25<01:53,  1.12s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 20%|â–ˆâ–ˆ        | 25/125 [00:27<01:51,  1.12s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 21%|â–ˆâ–ˆ        | 26/125 [00:28<01:49,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 22%|â–ˆâ–ˆâ–       | 27/125 [00:29<01:48,  1.10s/it]\u001b[A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 12:06:31. Total running time: 29min 1s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722        1            922.143        1.1345         26.5934          8.4223         23.0981 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 22%|â–ˆâ–ˆâ–       | 28/125 [00:30<01:46,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 23%|â–ˆâ–ˆâ–       | 29/125 [00:31<01:47,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 24%|â–ˆâ–ˆâ–       | 30/125 [00:32<01:45,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 25%|â–ˆâ–ˆâ–       | 31/125 [00:33<01:44,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 26%|â–ˆâ–ˆâ–Œ       | 32/125 [00:34<01:42,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 26%|â–ˆâ–ˆâ–‹       | 33/125 [00:35<01:42,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 27%|â–ˆâ–ˆâ–‹       | 34/125 [00:36<01:40,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 28%|â–ˆâ–ˆâ–Š       | 35/125 [00:38<01:39,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 29%|â–ˆâ–ˆâ–‰       | 36/125 [00:39<01:39,  1.12s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 30%|â–ˆâ–ˆâ–‰       | 37/125 [00:40<01:38,  1.12s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 30%|â–ˆâ–ˆâ–ˆ       | 38/125 [00:41<01:37,  1.12s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 31%|â–ˆâ–ˆâ–ˆ       | 39/125 [00:42<01:36,  1.12s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 32%|â–ˆâ–ˆâ–ˆâ–      | 40/125 [00:43<01:33,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 33%|â–ˆâ–ˆâ–ˆâ–      | 41/125 [00:44<01:32,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 34%|â–ˆâ–ˆâ–ˆâ–      | 42/125 [00:45<01:31,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 34%|â–ˆâ–ˆâ–ˆâ–      | 43/125 [00:47<01:31,  1.12s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 44/125 [00:48<01:31,  1.13s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 45/125 [00:49<01:30,  1.13s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 46/125 [00:50<01:28,  1.12s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 47/125 [00:51<01:26,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 48/125 [00:52<01:25,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 49/125 [00:53<01:23,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 50/125 [00:54<01:23,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 51/125 [00:55<01:21,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 52/125 [00:57<01:21,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 53/125 [00:58<01:19,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 54/125 [00:59<01:19,  1.11s/it]\u001b[A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 12:07:01. Total running time: 29min 31s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722        1            922.143        1.1345         26.5934          8.4223         23.0981 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 55/125 [01:00<01:18,  1.12s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 56/125 [01:01<01:18,  1.13s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 57/125 [01:02<01:16,  1.13s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 58/125 [01:03<01:15,  1.12s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 59/125 [01:04<01:13,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 60/125 [01:05<01:11,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 61/125 [01:07<01:10,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 62/125 [01:08<01:09,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 63/125 [01:09<01:07,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 64/125 [01:10<01:06,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 65/125 [01:11<01:05,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 66/125 [01:12<01:04,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 67/125 [01:13<01:04,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 68/125 [01:14<01:02,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 69/125 [01:15<01:01,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 70/125 [01:16<01:00,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 71/125 [01:18<00:59,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 72/125 [01:19<00:58,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 73/125 [01:20<00:57,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 74/125 [01:21<00:55,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 75/125 [01:22<00:54,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 76/125 [01:23<00:54,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 77/125 [01:24<00:53,  1.12s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 78/125 [01:25<00:52,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 79/125 [01:26<00:50,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 80/125 [01:28<00:49,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 81/125 [01:29<00:48,  1.10s/it]\u001b[A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 12:07:31. Total running time: 30min 1s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722        1            922.143        1.1345         26.5934          8.4223         23.0981 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 82/125 [01:30<00:47,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 83/125 [01:31<00:45,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 84/125 [01:32<00:44,  1.08s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 85/125 [01:33<00:43,  1.08s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 86/125 [01:34<00:42,  1.08s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 87/125 [01:35<00:41,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 88/125 [01:36<00:40,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 89/125 [01:37<00:39,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 90/125 [01:38<00:38,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 91/125 [01:40<00:37,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 92/125 [01:41<00:36,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 93/125 [01:42<00:35,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 94/125 [01:43<00:34,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 95/125 [01:44<00:32,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 96/125 [01:45<00:31,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 97/125 [01:46<00:30,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 98/125 [01:47<00:29,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 99/125 [01:48<00:28,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 100/125 [01:49<00:27,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 101/125 [01:51<00:26,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 102/125 [01:52<00:25,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 103/125 [01:53<00:24,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 104/125 [01:54<00:23,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 105/125 [01:55<00:22,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 106/125 [01:56<00:20,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 107/125 [01:57<00:19,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 108/125 [01:58<00:18,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-08-17 12:08:01. Total running time: 30min 31s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status       learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   RUNNING        4.32845e-05                       16                        8                    2        0.0801722        1            922.143        1.1345         26.5934          8.4223         23.0981 |\n",
            "| _objective_15fb9_00001   PENDING        0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \r 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 109/125 [01:59<00:17,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 110/125 [02:00<00:16,  1.08s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 111/125 [02:01<00:15,  1.08s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 112/125 [02:03<00:14,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 113/125 [02:04<00:13,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 114/125 [02:05<00:12,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 115/125 [02:06<00:11,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 116/125 [02:07<00:09,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 117/125 [02:08<00:08,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 118/125 [02:09<00:07,  1.08s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 119/125 [02:10<00:06,  1.08s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 120/125 [02:11<00:05,  1.08s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 121/125 [02:12<00:04,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 122/125 [02:14<00:03,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 123/125 [02:15<00:02,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 124/125 [02:16<00:01,  1.10s/it]\u001b[AThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [02:16<00:00,  1.12it/s]\u001b[A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial _objective_15fb9_00000 finished iteration 2 at 2024-08-17 12:08:21. Total running time: 30min 51s\n",
            "+-------------------------------------------------+\n",
            "| Trial _objective_15fb9_00000 result             |\n",
            "+-------------------------------------------------+\n",
            "| checkpoint_dir_name                             |\n",
            "| time_this_iter_s                        925.977 |\n",
            "| time_total_s                            1848.12 |\n",
            "| training_iteration                            2 |\n",
            "| epoch                                         2 |\n",
            "| eval_gen_len                                 19 |\n",
            "| eval_loss                               1.10895 |\n",
            "| eval_rouge1                             28.4621 |\n",
            "| eval_rouge2                             10.0175 |\n",
            "| eval_rougeL                             24.4471 |\n",
            "| eval_rougeLsum                           27.356 |\n",
            "| eval_runtime                            141.636 |\n",
            "| eval_samples_per_second                    7.06 |\n",
            "| eval_steps_per_second                     0.883 |\n",
            "| objective                               109.283 |\n",
            "+-------------------------------------------------+\n",
            "\n",
            "Trial _objective_15fb9_00000 completed after 2 iterations at 2024-08-17 12:08:21. Total running time: 30min 51s\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m {'eval_loss': 1.108945608139038, 'eval_rouge1': 28.4621, 'eval_rouge2': 10.0175, 'eval_rougeL': 24.4471, 'eval_rougeLsum': 27.356, 'eval_gen_len': 19.0, 'eval_runtime': 141.6356, 'eval_samples_per_second': 7.06, 'eval_steps_per_second': 0.883, 'epoch': 2.0}\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m {'train_runtime': 1839.6362, 'train_samples_per_second': 6.523, 'train_steps_per_second': 0.408, 'train_loss': 1.178037801106771, 'epoch': 2.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_objective pid=10843)\u001b[0m \r                                                 \n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \r                                                 \r\u001b[A\r100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 750/750 [30:39<00:00,  1.61s/it]\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \r100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [02:19<00:00,  1.12it/s]\u001b[A\n",
            "\u001b[36m(_objective pid=10843)\u001b[0m \r                                                 \u001b[A\r                                                 \r\r100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 750/750 [30:39<00:00,  1.61s/it]\r100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 750/750 [30:39<00:00,  2.45s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial _objective_15fb9_00001 started with configuration:\n",
            "+-------------------------------------------------+\n",
            "| Trial _objective_15fb9_00001 config             |\n",
            "+-------------------------------------------------+\n",
            "| learning_rate                            0.0001 |\n",
            "| num_train_epochs                              2 |\n",
            "| per_device_eval_batch_size                    8 |\n",
            "| per_device_train_batch_size                  32 |\n",
            "| weight_decay                            0.01523 |\n",
            "+-------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_objective pid=19019)\u001b[0m 2024-08-17 12:08:26.632723: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m 2024-08-17 12:08:26.658350: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m 2024-08-17 12:08:26.667411: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m 2024-08-17 12:08:27.757827: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:08:31. Total running time: 31min 1s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2            1848.12       1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_objective pid=19019)\u001b[0m Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.crossattention.c_attn.bias', 'h.0.crossattention.c_attn.weight', 'h.0.crossattention.c_proj.bias', 'h.0.crossattention.c_proj.weight', 'h.0.crossattention.q_attn.bias', 'h.0.crossattention.q_attn.weight', 'h.0.ln_cross_attn.bias', 'h.0.ln_cross_attn.weight', 'h.1.crossattention.c_attn.bias', 'h.1.crossattention.c_attn.weight', 'h.1.crossattention.c_proj.bias', 'h.1.crossattention.c_proj.weight', 'h.1.crossattention.q_attn.bias', 'h.1.crossattention.q_attn.weight', 'h.1.ln_cross_attn.bias', 'h.1.ln_cross_attn.weight', 'h.10.crossattention.c_attn.bias', 'h.10.crossattention.c_attn.weight', 'h.10.crossattention.c_proj.bias', 'h.10.crossattention.c_proj.weight', 'h.10.crossattention.q_attn.bias', 'h.10.crossattention.q_attn.weight', 'h.10.ln_cross_attn.bias', 'h.10.ln_cross_attn.weight', 'h.11.crossattention.c_attn.bias', 'h.11.crossattention.c_attn.weight', 'h.11.crossattention.c_proj.bias', 'h.11.crossattention.c_proj.weight', 'h.11.crossattention.q_attn.bias', 'h.11.crossattention.q_attn.weight', 'h.11.ln_cross_attn.bias', 'h.11.ln_cross_attn.weight', 'h.2.crossattention.c_attn.bias', 'h.2.crossattention.c_attn.weight', 'h.2.crossattention.c_proj.bias', 'h.2.crossattention.c_proj.weight', 'h.2.crossattention.q_attn.bias', 'h.2.crossattention.q_attn.weight', 'h.2.ln_cross_attn.bias', 'h.2.ln_cross_attn.weight', 'h.3.crossattention.c_attn.bias', 'h.3.crossattention.c_attn.weight', 'h.3.crossattention.c_proj.bias', 'h.3.crossattention.c_proj.weight', 'h.3.crossattention.q_attn.bias', 'h.3.crossattention.q_attn.weight', 'h.3.ln_cross_attn.bias', 'h.3.ln_cross_attn.weight', 'h.4.crossattention.c_attn.bias', 'h.4.crossattention.c_attn.weight', 'h.4.crossattention.c_proj.bias', 'h.4.crossattention.c_proj.weight', 'h.4.crossattention.q_attn.bias', 'h.4.crossattention.q_attn.weight', 'h.4.ln_cross_attn.bias', 'h.4.ln_cross_attn.weight', 'h.5.crossattention.c_attn.bias', 'h.5.crossattention.c_attn.weight', 'h.5.crossattention.c_proj.bias', 'h.5.crossattention.c_proj.weight', 'h.5.crossattention.q_attn.bias', 'h.5.crossattention.q_attn.weight', 'h.5.ln_cross_attn.bias', 'h.5.ln_cross_attn.weight', 'h.6.crossattention.c_attn.bias', 'h.6.crossattention.c_attn.weight', 'h.6.crossattention.c_proj.bias', 'h.6.crossattention.c_proj.weight', 'h.6.crossattention.q_attn.bias', 'h.6.crossattention.q_attn.weight', 'h.6.ln_cross_attn.bias', 'h.6.ln_cross_attn.weight', 'h.7.crossattention.c_attn.bias', 'h.7.crossattention.c_attn.weight', 'h.7.crossattention.c_proj.bias', 'h.7.crossattention.c_proj.weight', 'h.7.crossattention.q_attn.bias', 'h.7.crossattention.q_attn.weight', 'h.7.ln_cross_attn.bias', 'h.7.ln_cross_attn.weight', 'h.8.crossattention.c_attn.bias', 'h.8.crossattention.c_attn.weight', 'h.8.crossattention.c_proj.bias', 'h.8.crossattention.c_proj.weight', 'h.8.crossattention.q_attn.bias', 'h.8.crossattention.q_attn.weight', 'h.8.ln_cross_attn.bias', 'h.8.ln_cross_attn.weight', 'h.9.crossattention.c_attn.bias', 'h.9.crossattention.c_attn.weight', 'h.9.crossattention.c_proj.bias', 'h.9.crossattention.c_proj.weight', 'h.9.crossattention.q_attn.bias', 'h.9.crossattention.q_attn.weight', 'h.9.ln_cross_attn.bias', 'h.9.ln_cross_attn.weight']\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "  0%|          | 0/376 [00:00<?, ?it/s]\n",
            "  0%|          | 1/376 [00:07<47:15,  7.56s/it]\n",
            "  1%|          | 2/376 [00:11<33:45,  5.42s/it]\n",
            "  1%|          | 3/376 [00:15<29:30,  4.75s/it]\n",
            "  1%|          | 4/376 [00:19<27:24,  4.42s/it]\n",
            "  1%|â–         | 5/376 [00:23<26:14,  4.24s/it]\n",
            "  2%|â–         | 6/376 [00:27<25:31,  4.14s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:09:01. Total running time: 31min 31s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2            1848.12       1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|â–         | 7/376 [00:31<25:20,  4.12s/it]\n",
            "  2%|â–         | 8/376 [00:35<24:56,  4.07s/it]\n",
            "  2%|â–         | 9/376 [00:39<25:11,  4.12s/it]\n",
            "  3%|â–         | 10/376 [00:43<24:44,  4.06s/it]\n",
            "  3%|â–         | 11/376 [00:47<24:23,  4.01s/it]\n",
            "  3%|â–         | 12/376 [00:51<24:06,  3.97s/it]\n",
            "  3%|â–         | 13/376 [00:55<23:54,  3.95s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:09:31. Total running time: 32min 1s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2            1848.12       1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|â–         | 14/376 [00:59<23:46,  3.94s/it]\n",
            "  4%|â–         | 15/376 [01:02<23:38,  3.93s/it]\n",
            "  4%|â–         | 16/376 [01:06<23:34,  3.93s/it]\n",
            "  5%|â–         | 17/376 [01:10<23:28,  3.92s/it]\n",
            "  5%|â–         | 18/376 [01:14<23:22,  3.92s/it]\n",
            "  5%|â–Œ         | 19/376 [01:18<23:18,  3.92s/it]\n",
            "  5%|â–Œ         | 20/376 [01:22<23:16,  3.92s/it]\n",
            "  6%|â–Œ         | 21/376 [01:26<23:45,  4.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:10:01. Total running time: 32min 31s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2            1848.12       1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|â–Œ         | 22/376 [01:30<23:35,  4.00s/it]\n",
            "  6%|â–Œ         | 23/376 [01:34<23:23,  3.98s/it]\n",
            "  6%|â–‹         | 24/376 [01:38<23:15,  3.96s/it]\n",
            "  7%|â–‹         | 25/376 [01:42<23:05,  3.95s/it]\n",
            "  7%|â–‹         | 26/376 [01:46<22:58,  3.94s/it]\n",
            "  7%|â–‹         | 27/376 [01:50<22:51,  3.93s/it]\n",
            "  7%|â–‹         | 28/376 [01:54<22:47,  3.93s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:10:31. Total running time: 33min 1s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2            1848.12       1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|â–Š         | 29/376 [01:58<22:41,  3.92s/it]\n",
            "  8%|â–Š         | 30/376 [02:02<22:38,  3.93s/it]\n",
            "  8%|â–Š         | 31/376 [02:06<23:03,  4.01s/it]\n",
            "  9%|â–Š         | 32/376 [02:10<22:51,  3.99s/it]\n",
            "  9%|â–‰         | 33/376 [02:14<22:41,  3.97s/it]\n",
            "  9%|â–‰         | 34/376 [02:18<22:32,  3.95s/it]\n",
            "  9%|â–‰         | 35/376 [02:21<22:24,  3.94s/it]\n",
            " 10%|â–‰         | 36/376 [02:25<22:16,  3.93s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:11:01. Total running time: 33min 31s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2            1848.12       1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|â–‰         | 37/376 [02:29<22:17,  3.95s/it]\n",
            " 10%|â–ˆ         | 38/376 [02:33<22:15,  3.95s/it]\n",
            " 10%|â–ˆ         | 39/376 [02:37<22:08,  3.94s/it]\n",
            " 11%|â–ˆ         | 40/376 [02:41<22:02,  3.94s/it]\n",
            " 11%|â–ˆ         | 41/376 [02:45<21:57,  3.93s/it]\n",
            " 11%|â–ˆ         | 42/376 [02:49<22:24,  4.03s/it]\n",
            " 11%|â–ˆâ–        | 43/376 [02:53<22:09,  3.99s/it]\n",
            " 12%|â–ˆâ–        | 44/376 [02:57<22:01,  3.98s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:11:31. Total running time: 34min 1s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2            1848.12       1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|â–ˆâ–        | 45/376 [03:01<21:51,  3.96s/it]\n",
            " 12%|â–ˆâ–        | 46/376 [03:05<21:44,  3.95s/it]\n",
            " 12%|â–ˆâ–        | 47/376 [03:09<21:39,  3.95s/it]\n",
            " 13%|â–ˆâ–        | 48/376 [03:13<21:33,  3.94s/it]\n",
            " 13%|â–ˆâ–        | 49/376 [03:17<21:25,  3.93s/it]\n",
            " 13%|â–ˆâ–        | 50/376 [03:21<21:19,  3.93s/it]\n",
            " 14%|â–ˆâ–        | 51/376 [03:25<21:15,  3.92s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:12:02. Total running time: 34min 31s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2            1848.12       1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|â–ˆâ–        | 52/376 [03:29<21:10,  3.92s/it]\n",
            " 14%|â–ˆâ–        | 53/376 [03:33<21:10,  3.93s/it]\n",
            " 14%|â–ˆâ–        | 54/376 [03:37<21:38,  4.03s/it]\n",
            " 15%|â–ˆâ–        | 55/376 [03:41<21:23,  4.00s/it]\n",
            " 15%|â–ˆâ–        | 56/376 [03:45<21:09,  3.97s/it]\n",
            " 15%|â–ˆâ–Œ        | 57/376 [03:49<21:03,  3.96s/it]\n",
            " 15%|â–ˆâ–Œ        | 58/376 [03:52<20:54,  3.95s/it]\n",
            " 16%|â–ˆâ–Œ        | 59/376 [03:56<20:45,  3.93s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:12:32. Total running time: 35min 1s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2            1848.12       1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|â–ˆâ–Œ        | 60/376 [04:00<20:39,  3.92s/it]\n",
            " 16%|â–ˆâ–Œ        | 61/376 [04:04<20:35,  3.92s/it]\n",
            " 16%|â–ˆâ–‹        | 62/376 [04:08<20:29,  3.92s/it]\n",
            " 17%|â–ˆâ–‹        | 63/376 [04:12<20:26,  3.92s/it]\n",
            " 17%|â–ˆâ–‹        | 64/376 [04:16<20:49,  4.00s/it]\n",
            " 17%|â–ˆâ–‹        | 65/376 [04:20<20:34,  3.97s/it]\n",
            " 18%|â–ˆâ–Š        | 66/376 [04:24<20:23,  3.95s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:13:02. Total running time: 35min 31s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2            1848.12       1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|â–ˆâ–Š        | 67/376 [04:28<20:17,  3.94s/it]\n",
            " 18%|â–ˆâ–Š        | 68/376 [04:32<20:10,  3.93s/it]\n",
            " 18%|â–ˆâ–Š        | 69/376 [04:36<20:07,  3.93s/it]\n",
            " 19%|â–ˆâ–Š        | 70/376 [04:40<20:02,  3.93s/it]\n",
            " 19%|â–ˆâ–‰        | 71/376 [04:44<19:59,  3.93s/it]\n",
            " 19%|â–ˆâ–‰        | 72/376 [04:47<19:51,  3.92s/it]\n",
            " 19%|â–ˆâ–‰        | 73/376 [04:51<19:52,  3.93s/it]\n",
            " 20%|â–ˆâ–‰        | 74/376 [04:55<19:52,  3.95s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:13:32. Total running time: 36min 2s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2            1848.12       1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|â–ˆâ–‰        | 75/376 [05:00<20:15,  4.04s/it]\n",
            " 20%|â–ˆâ–ˆ        | 76/376 [05:04<20:03,  4.01s/it]\n",
            " 20%|â–ˆâ–ˆ        | 77/376 [05:08<19:55,  4.00s/it]\n",
            " 21%|â–ˆâ–ˆ        | 78/376 [05:12<19:43,  3.97s/it]\n",
            " 21%|â–ˆâ–ˆ        | 79/376 [05:15<19:33,  3.95s/it]\n",
            " 21%|â–ˆâ–ˆâ–       | 80/376 [05:19<19:25,  3.94s/it]\n",
            " 22%|â–ˆâ–ˆâ–       | 81/376 [05:23<19:19,  3.93s/it]\n",
            " 22%|â–ˆâ–ˆâ–       | 82/376 [05:27<19:16,  3.93s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:14:02. Total running time: 36min 32s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2            1848.12       1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|â–ˆâ–ˆâ–       | 83/376 [05:31<19:09,  3.92s/it]\n",
            " 22%|â–ˆâ–ˆâ–       | 84/376 [05:35<19:14,  3.95s/it]\n",
            " 23%|â–ˆâ–ˆâ–       | 85/376 [05:39<19:03,  3.93s/it]\n",
            " 23%|â–ˆâ–ˆâ–       | 86/376 [05:43<18:58,  3.92s/it]\n",
            " 23%|â–ˆâ–ˆâ–       | 87/376 [05:47<19:20,  4.02s/it]\n",
            " 23%|â–ˆâ–ˆâ–       | 88/376 [05:51<19:08,  3.99s/it]\n",
            " 24%|â–ˆâ–ˆâ–       | 89/376 [05:55<18:56,  3.96s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:14:32. Total running time: 37min 2s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2            1848.12       1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|â–ˆâ–ˆâ–       | 90/376 [05:59<18:48,  3.95s/it]\n",
            " 24%|â–ˆâ–ˆâ–       | 91/376 [06:03<18:41,  3.93s/it]\n",
            " 24%|â–ˆâ–ˆâ–       | 92/376 [06:07<18:35,  3.93s/it]\n",
            " 25%|â–ˆâ–ˆâ–       | 93/376 [06:11<18:29,  3.92s/it]\n",
            " 25%|â–ˆâ–ˆâ–Œ       | 94/376 [06:15<18:30,  3.94s/it]\n",
            " 25%|â–ˆâ–ˆâ–Œ       | 95/376 [06:18<18:20,  3.92s/it]\n",
            " 26%|â–ˆâ–ˆâ–Œ       | 96/376 [06:22<18:15,  3.91s/it]\n",
            " 26%|â–ˆâ–ˆâ–Œ       | 97/376 [06:27<18:36,  4.00s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:15:02. Total running time: 37min 32s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2            1848.12       1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|â–ˆâ–ˆâ–Œ       | 98/376 [06:30<18:26,  3.98s/it]\n",
            " 26%|â–ˆâ–ˆâ–‹       | 99/376 [06:34<18:15,  3.95s/it]\n",
            " 27%|â–ˆâ–ˆâ–‹       | 100/376 [06:38<18:12,  3.96s/it]\n",
            " 27%|â–ˆâ–ˆâ–‹       | 101/376 [06:42<18:04,  3.94s/it]\n",
            " 27%|â–ˆâ–ˆâ–‹       | 102/376 [06:46<17:55,  3.93s/it]\n",
            " 27%|â–ˆâ–ˆâ–‹       | 103/376 [06:50<17:49,  3.92s/it]\n",
            " 28%|â–ˆâ–ˆâ–Š       | 104/376 [06:54<17:45,  3.92s/it]\n",
            " 28%|â–ˆâ–ˆâ–Š       | 105/376 [06:58<17:39,  3.91s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:15:32. Total running time: 38min 2s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2            1848.12       1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|â–ˆâ–ˆâ–Š       | 106/376 [07:02<17:36,  3.91s/it]\n",
            " 28%|â–ˆâ–ˆâ–Š       | 107/376 [07:06<17:31,  3.91s/it]\n",
            " 29%|â–ˆâ–ˆâ–Š       | 108/376 [07:10<17:53,  4.00s/it]\n",
            " 29%|â–ˆâ–ˆâ–‰       | 109/376 [07:14<17:41,  3.98s/it]\n",
            " 29%|â–ˆâ–ˆâ–‰       | 110/376 [07:18<17:32,  3.96s/it]\n",
            " 30%|â–ˆâ–ˆâ–‰       | 111/376 [07:22<17:26,  3.95s/it]\n",
            " 30%|â–ˆâ–ˆâ–‰       | 112/376 [07:26<17:19,  3.94s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:16:02. Total running time: 38min 32s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2            1848.12       1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|â–ˆâ–ˆâ–ˆ       | 113/376 [07:29<17:13,  3.93s/it]\n",
            " 30%|â–ˆâ–ˆâ–ˆ       | 114/376 [07:33<17:07,  3.92s/it]\n",
            " 31%|â–ˆâ–ˆâ–ˆ       | 115/376 [07:37<17:03,  3.92s/it]\n",
            " 31%|â–ˆâ–ˆâ–ˆ       | 116/376 [07:41<16:59,  3.92s/it]\n",
            " 31%|â–ˆâ–ˆâ–ˆ       | 117/376 [07:45<16:53,  3.91s/it]\n",
            " 31%|â–ˆâ–ˆâ–ˆâ–      | 118/376 [07:49<16:49,  3.91s/it]\n",
            " 32%|â–ˆâ–ˆâ–ˆâ–      | 119/376 [07:53<16:44,  3.91s/it]\n",
            " 32%|â–ˆâ–ˆâ–ˆâ–      | 120/376 [07:57<17:00,  3.99s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:16:32. Total running time: 39min 2s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2            1848.12       1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|â–ˆâ–ˆâ–ˆâ–      | 121/376 [08:01<16:56,  3.99s/it]\n",
            " 32%|â–ˆâ–ˆâ–ˆâ–      | 122/376 [08:05<16:46,  3.96s/it]\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–      | 123/376 [08:09<16:38,  3.95s/it]\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–      | 124/376 [08:13<16:32,  3.94s/it]\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–      | 125/376 [08:17<16:26,  3.93s/it]\n",
            " 34%|â–ˆâ–ˆâ–ˆâ–      | 126/376 [08:21<16:20,  3.92s/it]\n",
            " 34%|â–ˆâ–ˆâ–ˆâ–      | 127/376 [08:25<16:14,  3.91s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:17:02. Total running time: 39min 32s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2            1848.12       1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|â–ˆâ–ˆâ–ˆâ–      | 128/376 [08:28<16:12,  3.92s/it]\n",
            " 34%|â–ˆâ–ˆâ–ˆâ–      | 129/376 [08:32<16:06,  3.91s/it]\n",
            " 35%|â–ˆâ–ˆâ–ˆâ–      | 130/376 [08:37<16:24,  4.00s/it]\n",
            " 35%|â–ˆâ–ˆâ–ˆâ–      | 131/376 [08:41<16:18,  3.99s/it]\n",
            " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 132/376 [08:44<16:08,  3.97s/it]\n",
            " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 133/376 [08:48<15:59,  3.95s/it]\n",
            " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 134/376 [08:52<15:51,  3.93s/it]\n",
            " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 135/376 [08:56<15:48,  3.94s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:17:32. Total running time: 40min 2s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2            1848.12       1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 136/376 [09:00<15:42,  3.93s/it]\n",
            " 36%|â–ˆâ–ˆâ–ˆâ–‹      | 137/376 [09:04<15:36,  3.92s/it]\n",
            " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 138/376 [09:08<15:32,  3.92s/it]\n",
            " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 139/376 [09:12<15:27,  3.91s/it]\n",
            " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 140/376 [09:16<15:24,  3.92s/it]\n",
            " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 141/376 [09:20<15:45,  4.02s/it]\n",
            " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 142/376 [09:24<15:34,  3.99s/it]\n",
            " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 143/376 [09:28<15:24,  3.97s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:18:02. Total running time: 40min 32s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2            1848.12       1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 144/376 [09:32<15:15,  3.95s/it]\n",
            " 39%|â–ˆâ–ˆâ–ˆâ–Š      | 145/376 [09:36<15:09,  3.94s/it]\n",
            " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 146/376 [09:40<15:05,  3.94s/it]\n",
            " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 147/376 [09:44<15:02,  3.94s/it]\n",
            " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 148/376 [09:47<15:00,  3.95s/it]\n",
            " 40%|â–ˆâ–ˆâ–ˆâ–‰      | 149/376 [09:51<14:52,  3.93s/it]\n",
            " 40%|â–ˆâ–ˆâ–ˆâ–‰      | 150/376 [09:55<14:47,  3.93s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:18:32. Total running time: 41min 2s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2            1848.12       1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 151/376 [09:59<14:42,  3.92s/it]\n",
            " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 152/376 [10:03<14:37,  3.92s/it]\n",
            " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 153/376 [10:07<14:49,  3.99s/it]\n",
            " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 154/376 [10:11<14:41,  3.97s/it]\n",
            " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 155/376 [10:15<14:39,  3.98s/it]\n",
            " 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 156/376 [10:19<14:31,  3.96s/it]\n",
            " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 157/376 [10:23<14:23,  3.94s/it]\n",
            " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 158/376 [10:27<14:17,  3.94s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:19:02. Total running time: 41min 32s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2            1848.12       1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 159/376 [10:31<14:11,  3.92s/it]\n",
            " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 160/376 [10:35<14:06,  3.92s/it]\n",
            " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 161/376 [10:39<14:02,  3.92s/it]\n",
            " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 162/376 [10:43<14:02,  3.94s/it]\n",
            " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 163/376 [10:47<14:16,  4.02s/it]\n",
            " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 164/376 [10:51<14:05,  3.99s/it]\n",
            " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 165/376 [10:55<13:56,  3.96s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:19:33. Total running time: 42min 2s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2            1848.12       1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 166/376 [10:59<13:48,  3.95s/it]\n",
            " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 167/376 [11:02<13:41,  3.93s/it]\n",
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 168/376 [11:06<13:36,  3.92s/it]\n",
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 169/376 [11:10<13:29,  3.91s/it]\n",
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 170/376 [11:14<13:24,  3.91s/it]\n",
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 171/376 [11:18<13:22,  3.91s/it]\n",
            " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 172/376 [11:22<13:20,  3.92s/it]\n",
            " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 173/376 [11:26<13:16,  3.92s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:20:03. Total running time: 42min 32s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2            1848.12       1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 174/376 [11:30<13:30,  4.01s/it]\n",
            " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 175/376 [11:34<13:21,  3.99s/it]\n",
            " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 176/376 [11:38<13:13,  3.97s/it]\n",
            " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 177/376 [11:42<13:05,  3.95s/it]\n",
            " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 178/376 [11:46<13:05,  3.97s/it]\n",
            " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 179/376 [11:50<12:59,  3.96s/it]\n",
            " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 180/376 [11:54<12:53,  3.95s/it]\n",
            " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 181/376 [11:58<12:50,  3.95s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:20:33. Total running time: 43min 2s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2            1848.12       1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 182/376 [12:02<12:45,  3.95s/it]\n",
            " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 183/376 [12:06<12:38,  3.93s/it]\n",
            " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 184/376 [12:10<12:33,  3.93s/it]\n",
            " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 185/376 [12:13<12:29,  3.92s/it]\n",
            " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 186/376 [12:18<12:41,  4.01s/it]\n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 187/376 [12:20<11:12,  3.56s/it]\n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 188/376 [12:21<08:23,  2.68s/it]\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m /usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            "  0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            "  2%|â–         | 2/125 [00:01<01:06,  1.84it/s]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            "  2%|â–         | 3/125 [00:02<01:33,  1.31it/s]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            "  3%|â–         | 4/125 [00:03<01:47,  1.12it/s]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            "  4%|â–         | 5/125 [00:04<01:56,  1.03it/s]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            "  5%|â–         | 6/125 [00:05<01:58,  1.00it/s]\u001b[A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:21:03. Total running time: 43min 33s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2            1848.12       1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            "  6%|â–Œ         | 7/125 [00:06<02:00,  1.02s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            "  6%|â–‹         | 8/125 [00:07<02:00,  1.03s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            "  7%|â–‹         | 9/125 [00:08<02:01,  1.05s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            "  8%|â–Š         | 10/125 [00:09<02:01,  1.05s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            "  9%|â–‰         | 11/125 [00:10<02:00,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 10%|â–‰         | 12/125 [00:11<01:59,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 10%|â–ˆ         | 13/125 [00:12<01:58,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 11%|â–ˆ         | 14/125 [00:13<01:57,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 12%|â–ˆâ–        | 15/125 [00:15<01:57,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 13%|â–ˆâ–        | 16/125 [00:16<01:56,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 14%|â–ˆâ–        | 17/125 [00:17<01:55,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 14%|â–ˆâ–        | 18/125 [00:18<01:54,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 15%|â–ˆâ–Œ        | 19/125 [00:19<01:53,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 16%|â–ˆâ–Œ        | 20/125 [00:20<01:52,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 17%|â–ˆâ–‹        | 21/125 [00:21<01:51,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 18%|â–ˆâ–Š        | 22/125 [00:22<01:51,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 18%|â–ˆâ–Š        | 23/125 [00:23<01:50,  1.08s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 19%|â–ˆâ–‰        | 24/125 [00:24<01:48,  1.08s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 20%|â–ˆâ–ˆ        | 25/125 [00:25<01:47,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 21%|â–ˆâ–ˆ        | 26/125 [00:26<01:45,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 22%|â–ˆâ–ˆâ–       | 27/125 [00:27<01:44,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 22%|â–ˆâ–ˆâ–       | 28/125 [00:28<01:43,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 23%|â–ˆâ–ˆâ–       | 29/125 [00:30<01:43,  1.08s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 24%|â–ˆâ–ˆâ–       | 30/125 [00:31<01:41,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 25%|â–ˆâ–ˆâ–       | 31/125 [00:32<01:41,  1.08s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 26%|â–ˆâ–ˆâ–Œ       | 32/125 [00:33<01:40,  1.08s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 26%|â–ˆâ–ˆâ–‹       | 33/125 [00:34<01:38,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 27%|â–ˆâ–ˆâ–‹       | 34/125 [00:35<01:37,  1.07s/it]\u001b[A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:21:33. Total running time: 44min 3s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2            1848.12       1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 28%|â–ˆâ–ˆâ–Š       | 35/125 [00:36<01:36,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 29%|â–ˆâ–ˆâ–‰       | 36/125 [00:37<01:35,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 30%|â–ˆâ–ˆâ–‰       | 37/125 [00:38<01:33,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 30%|â–ˆâ–ˆâ–ˆ       | 38/125 [00:39<01:32,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 31%|â–ˆâ–ˆâ–ˆ       | 39/125 [00:40<01:31,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 32%|â–ˆâ–ˆâ–ˆâ–      | 40/125 [00:41<01:30,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 33%|â–ˆâ–ˆâ–ˆâ–      | 41/125 [00:42<01:30,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 34%|â–ˆâ–ˆâ–ˆâ–      | 42/125 [00:43<01:28,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 34%|â–ˆâ–ˆâ–ˆâ–      | 43/125 [00:45<01:27,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 44/125 [00:46<01:26,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 45/125 [00:47<01:25,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 46/125 [00:48<01:23,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 47/125 [00:49<01:22,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 48/125 [00:50<01:21,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 49/125 [00:51<01:20,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 50/125 [00:52<01:19,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 51/125 [00:53<01:18,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 52/125 [00:54<01:17,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 53/125 [00:55<01:16,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 54/125 [00:56<01:15,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 55/125 [00:57<01:14,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 56/125 [00:58<01:13,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 57/125 [00:59<01:11,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 58/125 [01:00<01:10,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 59/125 [01:01<01:09,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 60/125 [01:03<01:08,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 61/125 [01:04<01:07,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 62/125 [01:05<01:06,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:22:03. Total running time: 44min 33s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2            1848.12       1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \r 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 63/125 [01:06<01:06,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 64/125 [01:07<01:05,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 65/125 [01:08<01:04,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 66/125 [01:09<01:04,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 67/125 [01:10<01:02,  1.08s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 68/125 [01:11<01:01,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 69/125 [01:12<00:59,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 70/125 [01:13<00:58,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 71/125 [01:14<00:57,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 72/125 [01:15<00:56,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 73/125 [01:16<00:54,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 74/125 [01:17<00:53,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 75/125 [01:19<00:52,  1.05s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 76/125 [01:20<00:51,  1.05s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 77/125 [01:21<00:50,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 78/125 [01:22<00:49,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 79/125 [01:23<00:49,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 80/125 [01:24<00:48,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 81/125 [01:25<00:46,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 82/125 [01:26<00:45,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 83/125 [01:27<00:44,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 84/125 [01:28<00:43,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 85/125 [01:29<00:42,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 86/125 [01:30<00:41,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 87/125 [01:31<00:40,  1.05s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 88/125 [01:32<00:39,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 89/125 [01:33<00:38,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 90/125 [01:34<00:37,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 91/125 [01:36<00:36,  1.07s/it]\u001b[A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:22:33. Total running time: 45min 3s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2            1848.12       1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 92/125 [01:37<00:35,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 93/125 [01:38<00:34,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 94/125 [01:39<00:33,  1.08s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 95/125 [01:40<00:32,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 96/125 [01:41<00:33,  1.17s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 97/125 [01:42<00:31,  1.14s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 98/125 [01:43<00:29,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 99/125 [01:44<00:28,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 100/125 [01:45<00:26,  1.08s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 101/125 [01:47<00:25,  1.08s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 102/125 [01:48<00:24,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 103/125 [01:49<00:23,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 104/125 [01:50<00:22,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 105/125 [01:51<00:21,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 106/125 [01:52<00:20,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 107/125 [01:53<00:19,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 108/125 [01:54<00:18,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 109/125 [01:55<00:17,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 110/125 [01:56<00:15,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 111/125 [01:57<00:14,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 112/125 [01:58<00:13,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 113/125 [01:59<00:12,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 114/125 [02:00<00:11,  1.05s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 115/125 [02:01<00:10,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 116/125 [02:02<00:09,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 117/125 [02:03<00:08,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 118/125 [02:05<00:07,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 119/125 [02:06<00:06,  1.06s/it]\u001b[A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:23:03. Total running time: 45min 33s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275                                                                                           |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2            1848.12       1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 120/125 [02:07<00:05,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 121/125 [02:08<00:04,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 122/125 [02:09<00:03,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 123/125 [02:10<00:02,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 124/125 [02:11<00:01,  1.07s/it]\u001b[AThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [02:11<00:00,  1.16it/s]\u001b[A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial _objective_15fb9_00001 finished iteration 1 at 2024-08-17 12:23:12. Total running time: 45min 41s\n",
            "+-------------------------------------------------+\n",
            "| Trial _objective_15fb9_00001 result             |\n",
            "+-------------------------------------------------+\n",
            "| checkpoint_dir_name                             |\n",
            "| time_this_iter_s                        886.585 |\n",
            "| time_total_s                            886.585 |\n",
            "| training_iteration                            1 |\n",
            "| epoch                                         1 |\n",
            "| eval_gen_len                                 19 |\n",
            "| eval_loss                               1.11475 |\n",
            "| eval_rouge1                             26.9866 |\n",
            "| eval_rouge2                              8.7848 |\n",
            "| eval_rougeL                             23.3812 |\n",
            "| eval_rougeLsum                          25.7526 |\n",
            "| eval_runtime                            136.855 |\n",
            "| eval_samples_per_second                   7.307 |\n",
            "| eval_steps_per_second                     0.913 |\n",
            "| objective                               103.905 |\n",
            "+-------------------------------------------------+\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m {'eval_loss': 1.1147475242614746, 'eval_rouge1': 26.9866, 'eval_rouge2': 8.7848, 'eval_rougeL': 23.3812, 'eval_rougeLsum': 25.7526, 'eval_gen_len': 19.0, 'eval_runtime': 136.8547, 'eval_samples_per_second': 7.307, 'eval_steps_per_second': 0.913, 'epoch': 1.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_objective pid=19019)\u001b[0m \r                                                 \n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \r                                                 \r\u001b[A\r 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 188/376 [14:38<08:23,  2.68s/it]\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \r100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [02:15<00:00,  1.16it/s]\u001b[A\n",
            "                                                 \u001b[A\n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 189/376 [14:44<2:19:57, 44.91s/it]\n",
            " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 190/376 [14:48<1:41:05, 32.61s/it]\n",
            " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 191/376 [14:52<1:14:00, 24.00s/it]\n",
            " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 192/376 [14:56<55:07, 17.98s/it]  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:23:33. Total running time: 46min 3s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275        1            886.585       1.11475         26.9866          8.7848         23.3812 |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2           1848.12        1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 193/376 [15:00<41:57, 13.76s/it]\n",
            " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 194/376 [15:04<32:46, 10.80s/it]\n",
            " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 195/376 [15:08<26:21,  8.74s/it]\n",
            " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 196/376 [15:12<22:05,  7.37s/it]\n",
            " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 197/376 [15:16<18:52,  6.33s/it]\n",
            " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 198/376 [15:20<16:37,  5.61s/it]\n",
            " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 199/376 [15:24<15:02,  5.10s/it]\n",
            " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 200/376 [15:27<13:52,  4.73s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:24:03. Total running time: 46min 33s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275        1            886.585       1.11475         26.9866          8.7848         23.3812 |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2           1848.12        1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 201/376 [15:31<13:03,  4.48s/it]\n",
            " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 202/376 [15:35<12:28,  4.30s/it]\n",
            " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 203/376 [15:39<12:01,  4.17s/it]\n",
            " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 204/376 [15:43<11:43,  4.09s/it]\n",
            " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 205/376 [15:47<11:32,  4.05s/it]\n",
            " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 206/376 [15:51<11:41,  4.13s/it]\n",
            " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 207/376 [15:55<11:26,  4.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:24:33. Total running time: 47min 3s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275        1            886.585       1.11475         26.9866          8.7848         23.3812 |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2           1848.12        1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 208/376 [15:59<11:15,  4.02s/it]\n",
            " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 209/376 [16:03<11:06,  3.99s/it]\n",
            " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 210/376 [16:07<10:58,  3.97s/it]\n",
            " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 211/376 [16:11<10:51,  3.95s/it]\n",
            " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 212/376 [16:15<10:44,  3.93s/it]\n",
            " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 213/376 [16:19<10:38,  3.92s/it]\n",
            " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 214/376 [16:23<10:33,  3.91s/it]\n",
            " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 215/376 [16:26<10:30,  3.92s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:25:03. Total running time: 47min 33s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275        1            886.585       1.11475         26.9866          8.7848         23.3812 |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2           1848.12        1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 216/376 [16:30<10:29,  3.94s/it]\n",
            " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 217/376 [16:34<10:24,  3.93s/it]\n",
            " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 218/376 [16:39<10:33,  4.01s/it]\n",
            " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 219/376 [16:42<10:23,  3.97s/it]\n",
            " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 220/376 [16:46<10:15,  3.95s/it]\n",
            " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 221/376 [16:50<10:08,  3.93s/it]\n",
            " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 222/376 [16:54<10:03,  3.92s/it]\n",
            " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 223/376 [16:58<09:57,  3.91s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:25:33. Total running time: 48min 3s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275        1            886.585       1.11475         26.9866          8.7848         23.3812 |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2           1848.12        1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 224/376 [17:02<09:52,  3.90s/it]\n",
            " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 225/376 [17:06<09:57,  3.96s/it]\n",
            " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 226/376 [17:10<09:52,  3.95s/it]\n",
            " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 227/376 [17:14<09:46,  3.93s/it]\n",
            " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 228/376 [17:18<09:44,  3.95s/it]\n",
            " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 229/376 [17:22<09:50,  4.02s/it]\n",
            " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 230/376 [17:26<09:41,  3.98s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:26:03. Total running time: 48min 33s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275        1            886.585       1.11475         26.9866          8.7848         23.3812 |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2           1848.12        1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 231/376 [17:30<09:33,  3.95s/it]\n",
            " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 232/376 [17:34<09:27,  3.94s/it]\n",
            " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 233/376 [17:38<09:22,  3.93s/it]\n",
            " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 234/376 [17:41<09:16,  3.92s/it]\n",
            " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 235/376 [17:45<09:12,  3.92s/it]\n",
            " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 236/376 [17:49<09:08,  3.91s/it]\n",
            " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 237/376 [17:53<09:05,  3.92s/it]\n",
            " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 238/376 [17:57<08:59,  3.91s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:26:33. Total running time: 49min 3s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275        1            886.585       1.11475         26.9866          8.7848         23.3812 |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2           1848.12        1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 239/376 [18:01<09:12,  4.03s/it]\n",
            " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 240/376 [18:05<09:03,  3.99s/it]\n",
            " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 241/376 [18:09<08:55,  3.97s/it]\n",
            " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 242/376 [18:13<08:50,  3.96s/it]\n",
            " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 243/376 [18:17<08:43,  3.94s/it]\n",
            " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 244/376 [18:21<08:38,  3.92s/it]\n",
            " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 245/376 [18:25<08:33,  3.92s/it]\n",
            " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 246/376 [18:29<08:28,  3.91s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:27:03. Total running time: 49min 33s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275        1            886.585       1.11475         26.9866          8.7848         23.3812 |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2           1848.12        1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 247/376 [18:33<08:23,  3.90s/it]\n",
            " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 248/376 [18:37<08:20,  3.91s/it]\n",
            " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 249/376 [18:41<08:19,  3.93s/it]\n",
            " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 250/376 [18:44<08:14,  3.93s/it]\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 251/376 [18:49<08:18,  3.99s/it]\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 252/376 [18:52<08:12,  3.97s/it]\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 253/376 [18:56<08:07,  3.96s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:27:34. Total running time: 50min 3s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275        1            886.585       1.11475         26.9866          8.7848         23.3812 |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2           1848.12        1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 254/376 [19:00<08:00,  3.93s/it]\n",
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 255/376 [19:04<07:55,  3.93s/it]\n",
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 256/376 [19:08<07:50,  3.92s/it]\n",
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 257/376 [19:12<07:45,  3.91s/it]\n",
            " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 258/376 [19:16<07:41,  3.91s/it]\n",
            " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 259/376 [19:20<07:38,  3.91s/it]\n",
            " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 260/376 [19:24<07:34,  3.92s/it]\n",
            " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 261/376 [19:28<07:31,  3.93s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:28:04. Total running time: 50min 33s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275        1            886.585       1.11475         26.9866          8.7848         23.3812 |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2           1848.12        1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 262/376 [19:32<07:37,  4.01s/it]\n",
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 263/376 [19:36<07:28,  3.97s/it]\n",
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 264/376 [19:40<07:21,  3.95s/it]\n",
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 265/376 [19:44<07:18,  3.95s/it]\n",
            " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 266/376 [19:48<07:12,  3.93s/it]\n",
            " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 267/376 [19:51<07:07,  3.92s/it]\n",
            " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 268/376 [19:55<07:04,  3.93s/it]\n",
            " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 269/376 [19:59<06:59,  3.92s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:28:34. Total running time: 51min 3s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275        1            886.585       1.11475         26.9866          8.7848         23.3812 |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2           1848.12        1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 270/376 [20:03<06:54,  3.91s/it]\n",
            " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 271/376 [20:07<06:50,  3.91s/it]\n",
            " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 272/376 [20:11<06:57,  4.02s/it]\n",
            " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 273/376 [20:15<06:49,  3.98s/it]\n",
            " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 274/376 [20:19<06:43,  3.95s/it]\n",
            " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 275/376 [20:23<06:37,  3.94s/it]\n",
            " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 276/376 [20:27<06:33,  3.93s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:29:04. Total running time: 51min 33s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275        1            886.585       1.11475         26.9866          8.7848         23.3812 |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2           1848.12        1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 277/376 [20:31<06:27,  3.92s/it]\n",
            " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 278/376 [20:35<06:23,  3.91s/it]\n",
            " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 279/376 [20:39<06:19,  3.92s/it]\n",
            " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 280/376 [20:43<06:14,  3.91s/it]\n",
            " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 281/376 [20:46<06:12,  3.92s/it]\n",
            " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 282/376 [20:50<06:08,  3.92s/it]\n",
            " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 283/376 [20:54<06:04,  3.92s/it]\n",
            " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 284/376 [20:59<06:09,  4.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:29:34. Total running time: 52min 4s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275        1            886.585       1.11475         26.9866          8.7848         23.3812 |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2           1848.12        1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 285/376 [21:02<06:02,  3.98s/it]\n",
            " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 286/376 [21:06<05:57,  3.97s/it]\n",
            " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 287/376 [21:10<05:51,  3.95s/it]\n",
            " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 288/376 [21:14<05:46,  3.94s/it]\n",
            " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 289/376 [21:18<05:43,  3.94s/it]\n",
            " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 290/376 [21:22<05:38,  3.94s/it]\n",
            " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 291/376 [21:26<05:33,  3.93s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:30:04. Total running time: 52min 34s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275        1            886.585       1.11475         26.9866          8.7848         23.3812 |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2           1848.12        1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 292/376 [21:30<05:29,  3.93s/it]\n",
            " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 293/376 [21:34<05:25,  3.93s/it]\n",
            " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 294/376 [21:38<05:21,  3.92s/it]\n",
            " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 295/376 [21:42<05:23,  4.00s/it]\n",
            " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 296/376 [21:46<05:18,  3.98s/it]\n",
            " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 297/376 [21:50<05:12,  3.96s/it]\n",
            " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 298/376 [21:54<05:06,  3.93s/it]\n",
            " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 299/376 [21:58<05:02,  3.92s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:30:34. Total running time: 53min 4s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275        1            886.585       1.11475         26.9866          8.7848         23.3812 |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2           1848.12        1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 300/376 [22:01<04:57,  3.91s/it]\n",
            " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 301/376 [22:05<04:52,  3.90s/it]\n",
            " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 302/376 [22:09<04:49,  3.91s/it]\n",
            " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 303/376 [22:13<04:45,  3.91s/it]\n",
            " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 304/376 [22:17<04:41,  3.91s/it]\n",
            " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 305/376 [22:21<04:44,  4.01s/it]\n",
            " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 306/376 [22:25<04:39,  3.99s/it]\n",
            " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 307/376 [22:29<04:33,  3.96s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:31:04. Total running time: 53min 34s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275        1            886.585       1.11475         26.9866          8.7848         23.3812 |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2           1848.12        1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 308/376 [22:33<04:27,  3.94s/it]\n",
            " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 309/376 [22:37<04:23,  3.93s/it]\n",
            " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 310/376 [22:41<04:18,  3.92s/it]\n",
            " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 311/376 [22:45<04:14,  3.92s/it]\n",
            " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 312/376 [22:49<04:11,  3.93s/it]\n",
            " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 313/376 [22:53<04:07,  3.92s/it]\n",
            " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 314/376 [22:57<04:02,  3.91s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:31:34. Total running time: 54min 4s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275        1            886.585       1.11475         26.9866          8.7848         23.3812 |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2           1848.12        1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 315/376 [23:00<03:59,  3.92s/it]\n",
            " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 316/376 [23:04<03:56,  3.94s/it]\n",
            " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 317/376 [23:09<03:56,  4.02s/it]\n",
            " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 318/376 [23:13<03:50,  3.98s/it]\n",
            " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 319/376 [23:16<03:45,  3.95s/it]\n",
            " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 320/376 [23:20<03:40,  3.94s/it]\n",
            " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 321/376 [23:24<03:36,  3.93s/it]\n",
            " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 322/376 [23:28<03:31,  3.91s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:32:04. Total running time: 54min 34s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275        1            886.585       1.11475         26.9866          8.7848         23.3812 |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2           1848.12        1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 323/376 [23:32<03:27,  3.91s/it]\n",
            " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 324/376 [23:36<03:23,  3.90s/it]\n",
            " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 325/376 [23:40<03:19,  3.91s/it]\n",
            " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 326/376 [23:44<03:15,  3.91s/it]\n",
            " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 327/376 [23:48<03:11,  3.90s/it]\n",
            " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 328/376 [23:52<03:11,  3.99s/it]\n",
            " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 329/376 [23:56<03:06,  3.96s/it]\n",
            " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 330/376 [24:00<03:01,  3.94s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:32:34. Total running time: 55min 4s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275        1            886.585       1.11475         26.9866          8.7848         23.3812 |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2           1848.12        1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 331/376 [24:04<02:57,  3.94s/it]\n",
            " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 332/376 [24:07<02:52,  3.93s/it]\n",
            " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 333/376 [24:11<02:49,  3.93s/it]\n",
            " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 334/376 [24:15<02:44,  3.92s/it]\n",
            " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 335/376 [24:19<02:40,  3.92s/it]\n",
            " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 336/376 [24:23<02:36,  3.92s/it]\n",
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 337/376 [24:27<02:32,  3.92s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:33:04. Total running time: 55min 34s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275        1            886.585       1.11475         26.9866          8.7848         23.3812 |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2           1848.12        1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 338/376 [24:31<02:32,  4.02s/it]\n",
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 339/376 [24:35<02:27,  3.99s/it]\n",
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 340/376 [24:39<02:23,  3.98s/it]\n",
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 341/376 [24:43<02:18,  3.96s/it]\n",
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 342/376 [24:47<02:14,  3.95s/it]\n",
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 343/376 [24:51<02:09,  3.94s/it]\n",
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 344/376 [24:55<02:05,  3.92s/it]\n",
            " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 345/376 [24:59<02:01,  3.93s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:33:34. Total running time: 56min 4s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275        1            886.585       1.11475         26.9866          8.7848         23.3812 |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2           1848.12        1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 346/376 [25:03<01:58,  3.96s/it]\n",
            " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 347/376 [25:07<01:54,  3.94s/it]\n",
            " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 348/376 [25:11<01:50,  3.94s/it]\n",
            " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 349/376 [25:15<01:46,  3.95s/it]\n",
            " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 350/376 [25:19<01:44,  4.02s/it]\n",
            " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 351/376 [25:23<01:39,  3.98s/it]\n",
            " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 352/376 [25:27<01:35,  3.96s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:34:04. Total running time: 56min 34s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275        1            886.585       1.11475         26.9866          8.7848         23.3812 |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2           1848.12        1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 353/376 [25:31<01:31,  3.96s/it]\n",
            " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 354/376 [25:34<01:26,  3.94s/it]\n",
            " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 355/376 [25:38<01:22,  3.93s/it]\n",
            " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 356/376 [25:42<01:18,  3.93s/it]\n",
            " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 357/376 [25:46<01:14,  3.93s/it]\n",
            " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 358/376 [25:50<01:10,  3.92s/it]\n",
            " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 359/376 [25:54<01:06,  3.92s/it]\n",
            " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 360/376 [25:58<01:02,  3.93s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:34:34. Total running time: 57min 4s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275        1            886.585       1.11475         26.9866          8.7848         23.3812 |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2           1848.12        1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 361/376 [26:02<01:00,  4.01s/it]\n",
            " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 362/376 [26:06<00:55,  3.99s/it]\n",
            " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 363/376 [26:10<00:51,  3.97s/it]\n",
            " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 364/376 [26:14<00:47,  3.95s/it]\n",
            " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 365/376 [26:18<00:43,  3.93s/it]\n",
            " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 366/376 [26:22<00:39,  3.92s/it]\n",
            " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 367/376 [26:26<00:35,  3.91s/it]\n",
            " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 368/376 [26:30<00:31,  3.91s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:35:04. Total running time: 57min 34s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275        1            886.585       1.11475         26.9866          8.7848         23.3812 |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2           1848.12        1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 369/376 [26:33<00:27,  3.91s/it]\n",
            " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 370/376 [26:37<00:23,  3.90s/it]\n",
            " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 371/376 [26:42<00:19,  4.00s/it]\n",
            " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 372/376 [26:45<00:15,  3.97s/it]\n",
            " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 373/376 [26:49<00:11,  3.95s/it]\n",
            " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 374/376 [26:53<00:07,  3.93s/it]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 375/376 [26:56<00:03,  3.50s/it]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 376/376 [26:56<00:00,  2.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:35:35. Total running time: 58min 4s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275        1            886.585       1.11475         26.9866          8.7848         23.3812 |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2           1848.12        1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m /usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            "  0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            "  2%|â–         | 2/125 [00:01<01:05,  1.88it/s]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            "  2%|â–         | 3/125 [00:02<01:31,  1.33it/s]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            "  3%|â–         | 4/125 [00:03<01:44,  1.16it/s]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            "  4%|â–         | 5/125 [00:04<01:51,  1.07it/s]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            "  5%|â–         | 6/125 [00:05<01:55,  1.03it/s]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            "  6%|â–Œ         | 7/125 [00:06<01:57,  1.00it/s]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            "  6%|â–‹         | 8/125 [00:07<01:58,  1.01s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            "  7%|â–‹         | 9/125 [00:08<01:59,  1.03s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            "  8%|â–Š         | 10/125 [00:09<01:58,  1.03s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            "  9%|â–‰         | 11/125 [00:10<01:58,  1.04s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 10%|â–‰         | 12/125 [00:11<01:59,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 10%|â–ˆ         | 13/125 [00:12<01:58,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 11%|â–ˆ         | 14/125 [00:13<01:57,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 12%|â–ˆâ–        | 15/125 [00:14<01:56,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 13%|â–ˆâ–        | 16/125 [00:15<01:55,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 14%|â–ˆâ–        | 17/125 [00:16<01:54,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 14%|â–ˆâ–        | 18/125 [00:17<01:53,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 15%|â–ˆâ–Œ        | 19/125 [00:19<01:51,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 16%|â–ˆâ–Œ        | 20/125 [00:20<01:50,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 17%|â–ˆâ–‹        | 21/125 [00:21<01:50,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 18%|â–ˆâ–Š        | 22/125 [00:22<01:50,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 18%|â–ˆâ–Š        | 23/125 [00:23<01:49,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 19%|â–ˆâ–‰        | 24/125 [00:24<01:48,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 20%|â–ˆâ–ˆ        | 25/125 [00:25<01:46,  1.07s/it]\u001b[A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:36:05. Total running time: 58min 34s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275        1            886.585       1.11475         26.9866          8.7848         23.3812 |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2           1848.12        1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 21%|â–ˆâ–ˆ        | 26/125 [00:26<01:45,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 22%|â–ˆâ–ˆâ–       | 27/125 [00:27<01:43,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 22%|â–ˆâ–ˆâ–       | 28/125 [00:28<01:42,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 23%|â–ˆâ–ˆâ–       | 29/125 [00:29<01:41,  1.05s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 24%|â–ˆâ–ˆâ–       | 30/125 [00:30<01:40,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 25%|â–ˆâ–ˆâ–       | 31/125 [00:31<01:39,  1.05s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 26%|â–ˆâ–ˆâ–Œ       | 32/125 [00:32<01:37,  1.05s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 26%|â–ˆâ–ˆâ–‹       | 33/125 [00:33<01:36,  1.05s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 27%|â–ˆâ–ˆâ–‹       | 34/125 [00:34<01:36,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 28%|â–ˆâ–ˆâ–Š       | 35/125 [00:36<01:35,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 29%|â–ˆâ–ˆâ–‰       | 36/125 [00:37<01:36,  1.08s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 30%|â–ˆâ–ˆâ–‰       | 37/125 [00:38<01:34,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 30%|â–ˆâ–ˆâ–ˆ       | 38/125 [00:39<01:33,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 31%|â–ˆâ–ˆâ–ˆ       | 39/125 [00:40<01:31,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 32%|â–ˆâ–ˆâ–ˆâ–      | 40/125 [00:41<01:30,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 33%|â–ˆâ–ˆâ–ˆâ–      | 41/125 [00:42<01:29,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 34%|â–ˆâ–ˆâ–ˆâ–      | 42/125 [00:43<01:27,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 34%|â–ˆâ–ˆâ–ˆâ–      | 43/125 [00:44<01:26,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 44/125 [00:45<01:25,  1.05s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 45/125 [00:46<01:24,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 46/125 [00:47<01:23,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 47/125 [00:48<01:22,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 48/125 [00:49<01:21,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 49/125 [00:50<01:20,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 50/125 [00:51<01:20,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 51/125 [00:53<01:18,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 52/125 [00:54<01:17,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 53/125 [00:55<01:16,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:36:35. Total running time: 59min 4s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275        1            886.585       1.11475         26.9866          8.7848         23.3812 |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2           1848.12        1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \r 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 54/125 [00:56<01:15,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 55/125 [00:57<01:13,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 56/125 [00:58<01:13,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 57/125 [00:59<01:12,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 58/125 [01:00<01:10,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 59/125 [01:01<01:10,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 60/125 [01:02<01:09,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 61/125 [01:03<01:08,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 62/125 [01:04<01:07,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 63/125 [01:05<01:06,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 64/125 [01:06<01:04,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 65/125 [01:07<01:03,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 66/125 [01:08<01:02,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 67/125 [01:10<01:01,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 68/125 [01:11<01:00,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 69/125 [01:12<00:59,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 70/125 [01:13<00:58,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 71/125 [01:14<00:57,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 72/125 [01:15<00:56,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 73/125 [01:16<00:55,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 74/125 [01:17<00:54,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 75/125 [01:18<00:57,  1.16s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 76/125 [01:19<00:55,  1.13s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 77/125 [01:21<00:53,  1.11s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 78/125 [01:22<00:51,  1.10s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 79/125 [01:23<00:50,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 80/125 [01:24<00:49,  1.09s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 81/125 [01:25<00:47,  1.08s/it]\u001b[A\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:37:05. Total running time: 59min 35s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275        1            886.585       1.11475         26.9866          8.7848         23.3812 |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2           1848.12        1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 82/125 [01:26<00:46,  1.08s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 83/125 [01:27<00:45,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 84/125 [01:28<00:43,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 85/125 [01:29<00:42,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 86/125 [01:30<00:41,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 87/125 [01:31<00:40,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 88/125 [01:32<00:39,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 89/125 [01:33<00:38,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 90/125 [01:34<00:37,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 91/125 [01:35<00:35,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 92/125 [01:36<00:34,  1.05s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 93/125 [01:38<00:33,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 94/125 [01:39<00:33,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 95/125 [01:40<00:32,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 96/125 [01:41<00:31,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 97/125 [01:42<00:29,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 98/125 [01:43<00:29,  1.08s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 99/125 [01:44<00:27,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 100/125 [01:45<00:26,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 101/125 [01:46<00:25,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 102/125 [01:47<00:24,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 103/125 [01:48<00:23,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 104/125 [01:49<00:22,  1.05s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 105/125 [01:50<00:21,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 106/125 [01:51<00:20,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 107/125 [01:52<00:19,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 108/125 [01:53<00:17,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 109/125 [01:55<00:16,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-08-17 12:37:35. Total running time: 1hr 0min 5s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00001   RUNNING          0.000103283                       32                        8                    2        0.0152275        1            886.585       1.11475         26.9866          8.7848         23.3812 |\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2           1848.12        1.10895         28.4621         10.0175         24.4471 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \r 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 110/125 [01:56<00:15,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 111/125 [01:57<00:14,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 112/125 [01:58<00:14,  1.08s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 113/125 [01:59<00:12,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 114/125 [02:00<00:11,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 115/125 [02:01<00:10,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 116/125 [02:02<00:09,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 117/125 [02:03<00:08,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 118/125 [02:04<00:07,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 119/125 [02:05<00:06,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 120/125 [02:06<00:05,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 121/125 [02:07<00:04,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 122/125 [02:08<00:03,  1.06s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 123/125 [02:09<00:02,  1.07s/it]\u001b[A\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 124/125 [02:11<00:01,  1.07s/it]\u001b[AThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "\u001b[36m(_objective pid=19019)\u001b[0m \n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [02:11<00:00,  1.16it/s]\u001b[A\n",
            "2024-08-17 12:37:53,891\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/_objective_2024-08-17_11-37-30' in 0.0042s.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial _objective_15fb9_00001 finished iteration 2 at 2024-08-17 12:37:53. Total running time: 1hr 0min 23s\n",
            "+-------------------------------------------------+\n",
            "| Trial _objective_15fb9_00001 result             |\n",
            "+-------------------------------------------------+\n",
            "| checkpoint_dir_name                             |\n",
            "| time_this_iter_s                        881.678 |\n",
            "| time_total_s                            1768.26 |\n",
            "| training_iteration                            2 |\n",
            "| epoch                                         2 |\n",
            "| eval_gen_len                                 19 |\n",
            "| eval_loss                               1.08526 |\n",
            "| eval_rouge1                             29.6116 |\n",
            "| eval_rouge2                              11.072 |\n",
            "| eval_rougeL                             25.3957 |\n",
            "| eval_rougeLsum                          28.4143 |\n",
            "| eval_runtime                            136.392 |\n",
            "| eval_samples_per_second                   7.332 |\n",
            "| eval_steps_per_second                     0.916 |\n",
            "| objective                               113.494 |\n",
            "+-------------------------------------------------+\n",
            "\n",
            "Trial _objective_15fb9_00001 completed after 2 iterations at 2024-08-17 12:37:53. Total running time: 1hr 0min 23s\n",
            "\n",
            "Trial status: 2 TERMINATED\n",
            "Current time: 2024-08-17 12:37:53. Total running time: 1hr 0min 23s\n",
            "Logical resource usage: 1.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:L4)\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name               status         learning_rate     ..._train_batch_size     ...e_eval_batch_size     num_train_epochs     weight_decay     iter     total time (s)     eval_loss     eval_rouge1     eval_rouge2     eval_rougeL |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| _objective_15fb9_00000   TERMINATED       4.32845e-05                       16                        8                    2        0.0801722        2            1848.12       1.10895         28.4621         10.0175         24.4471 |\n",
            "| _objective_15fb9_00001   TERMINATED       0.000103283                       32                        8                    2        0.0152275        2            1768.26       1.08526         29.6116         11.072          25.3957 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the best hyperparameters\n",
        "print(\"Best hyperparameters found:\", best_run.hyperparameters)"
      ],
      "metadata": {
        "id": "GQQbuYUYNbQI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc11321e-5944-4710-e9cc-08470171337b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters found: {'learning_rate': 0.0001032833974654987, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 8, 'num_train_epochs': 2, 'weight_decay': 0.015227525095137952}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OEkw5My6c5PE",
        "outputId": "eb27276d-f13c-4de7-835e-22aa70273f37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4500' max='4500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4500/4500 1:15:05, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.943500</td>\n",
              "      <td>1.072284</td>\n",
              "      <td>31.313600</td>\n",
              "      <td>12.777500</td>\n",
              "      <td>26.839700</td>\n",
              "      <td>30.034000</td>\n",
              "      <td>19.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.843200</td>\n",
              "      <td>1.072725</td>\n",
              "      <td>31.919000</td>\n",
              "      <td>13.553200</td>\n",
              "      <td>27.110000</td>\n",
              "      <td>30.708100</td>\n",
              "      <td>19.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.774300</td>\n",
              "      <td>1.090021</td>\n",
              "      <td>32.137200</td>\n",
              "      <td>13.869500</td>\n",
              "      <td>27.219500</td>\n",
              "      <td>30.900100</td>\n",
              "      <td>19.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1501' max='4500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1501/4500 20:30 < 41:02, 1.22 it/s, Epoch 1/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 28:54]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4500, training_loss=0.8533239610460069, metrics={'train_runtime': 4506.89, 'train_samples_per_second': 3.994, 'train_steps_per_second': 0.998, 'total_flos': 3.248350040162304e+18, 'train_loss': 0.8533239610460069, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9f67b533d44d4c0bb6ae2352adc3e4e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_504519c4802141a6811973288ce00085",
              "IPY_MODEL_cd67146131cf4b7aa3aa03877020924a",
              "IPY_MODEL_e983649caf9c4c0c838b9314dd37c5b5"
            ],
            "layout": "IPY_MODEL_02c9312b4e4c4a2b8380ab8c3b0ce6c2"
          }
        },
        "504519c4802141a6811973288ce00085": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba0adf6afc9946469e5b7f6151d648f3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7f65b9856e324e19971050d73d0e62b1",
            "value": "Downloadingâ€‡builderâ€‡script:â€‡100%"
          }
        },
        "cd67146131cf4b7aa3aa03877020924a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46a7b148a8ee43c4ba5cd993523901c3",
            "max": 3539,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1f55904845742379b7b8727b2bc2c0b",
            "value": 3539
          }
        },
        "e983649caf9c4c0c838b9314dd37c5b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_100b1f3f94bd4a25ac8b943286102ac9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_729261233d504ca58accc1cfde689773",
            "value": "â€‡3.54k/3.54kâ€‡[00:00&lt;00:00,â€‡14.3kB/s]"
          }
        },
        "02c9312b4e4c4a2b8380ab8c3b0ce6c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba0adf6afc9946469e5b7f6151d648f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f65b9856e324e19971050d73d0e62b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46a7b148a8ee43c4ba5cd993523901c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1f55904845742379b7b8727b2bc2c0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "100b1f3f94bd4a25ac8b943286102ac9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "729261233d504ca58accc1cfde689773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29da2e2812ed4f2c9165b8b1bb403e66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f98a85a885fd4d2ba98988411376ac90",
              "IPY_MODEL_6e92babd9efe4e2895c5a62f12409892",
              "IPY_MODEL_ffcca17bcb4e4ced905eb27efba8f63d"
            ],
            "layout": "IPY_MODEL_92bcc154ea8f4560841bf65681d0f7a8"
          }
        },
        "f98a85a885fd4d2ba98988411376ac90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_522aa4d9dff6458ba324f91d995bec52",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8be5fc3a3597498eae789593749a7894",
            "value": "Downloadingâ€‡readme:â€‡100%"
          }
        },
        "6e92babd9efe4e2895c5a62f12409892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd55876ec6be488c910101df657a50e3",
            "max": 923,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b45a9af3884a4e6fac1bedad0c6eae63",
            "value": 923
          }
        },
        "ffcca17bcb4e4ced905eb27efba8f63d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d83f92c033bc4455ad65a2e65e6a56c7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_dc1c4e4389594855955e40c17ee39fcd",
            "value": "â€‡923/923â€‡[00:00&lt;00:00,â€‡3.64kB/s]"
          }
        },
        "92bcc154ea8f4560841bf65681d0f7a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "522aa4d9dff6458ba324f91d995bec52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8be5fc3a3597498eae789593749a7894": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd55876ec6be488c910101df657a50e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b45a9af3884a4e6fac1bedad0c6eae63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d83f92c033bc4455ad65a2e65e6a56c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc1c4e4389594855955e40c17ee39fcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04fbb41304be4a1b8716fb5e66a4770d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_710d02aedb9945ef803707f215e7374b",
              "IPY_MODEL_51c57c2f59e74d20b169e07bf58da524",
              "IPY_MODEL_45592865abc24e7fb670a628348dc5e3"
            ],
            "layout": "IPY_MODEL_414abc5860ee4a1e96efe7011f147085"
          }
        },
        "710d02aedb9945ef803707f215e7374b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d14556762a5b460c9da32db786c78f20",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_110c4f36acce4caf83758c8caac6d551",
            "value": "Generatingâ€‡trainâ€‡split:â€‡"
          }
        },
        "51c57c2f59e74d20b169e07bf58da524": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b17112bf1e924677808d8c49a10b4d29",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_730eccdc87bd443b9cb4cc567ccc843c",
            "value": 1
          }
        },
        "45592865abc24e7fb670a628348dc5e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b3b7a166ffa410992ea31b4127592a8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_852372aa56f84cf484542603ee76f79c",
            "value": "â€‡6000/0â€‡[03:43&lt;00:00,â€‡27.11â€‡examples/s]"
          }
        },
        "414abc5860ee4a1e96efe7011f147085": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d14556762a5b460c9da32db786c78f20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "110c4f36acce4caf83758c8caac6d551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b17112bf1e924677808d8c49a10b4d29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "730eccdc87bd443b9cb4cc567ccc843c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b3b7a166ffa410992ea31b4127592a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "852372aa56f84cf484542603ee76f79c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad4a3405218e48178a4bad414387aba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0834c3ea4204add8546c737fa3742bb",
              "IPY_MODEL_a65cd1b4f72b446dbc344cb0bbeed530",
              "IPY_MODEL_d3cd71a9d2724a17977484a4185ffc30"
            ],
            "layout": "IPY_MODEL_ed95addafb8744f1933648a141bd25b0"
          }
        },
        "e0834c3ea4204add8546c737fa3742bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d2f52a4374a43a091e4d9723230425d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e00f83f0224a46a488520d09fc1d7bdf",
            "value": "Generatingâ€‡testâ€‡split:â€‡"
          }
        },
        "a65cd1b4f72b446dbc344cb0bbeed530": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8eeb31a3ff44f2ca5253044f29e58ed",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_149f7982971e4d7a8da81d9fc875420a",
            "value": 1
          }
        },
        "d3cd71a9d2724a17977484a4185ffc30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8fbfa4d6b6b4a7dab3507ed8807e02d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_21c9e164bd4d4e128fec99f1057cb648",
            "value": "â€‡1000/0â€‡[00:36&lt;00:00,â€‡26.72â€‡examples/s]"
          }
        },
        "ed95addafb8744f1933648a141bd25b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d2f52a4374a43a091e4d9723230425d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e00f83f0224a46a488520d09fc1d7bdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8eeb31a3ff44f2ca5253044f29e58ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "149f7982971e4d7a8da81d9fc875420a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8fbfa4d6b6b4a7dab3507ed8807e02d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21c9e164bd4d4e128fec99f1057cb648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d606410f1f7544f2940f97c41e31c90a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a751bda0cd04d038ba4d6aa9cf177ac",
              "IPY_MODEL_af871f043eef476c98a6e12d847098f7",
              "IPY_MODEL_35d8a7b4c8e8480a855544e4d8b78a3e"
            ],
            "layout": "IPY_MODEL_70c4948e459d4293924ff8dd4aec34fb"
          }
        },
        "5a751bda0cd04d038ba4d6aa9cf177ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c03c0feb188403892ed2726160a5b38",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_afcd21eeaeb84e3a95c39ad41d89249a",
            "value": "Generatingâ€‡validationâ€‡split:â€‡"
          }
        },
        "af871f043eef476c98a6e12d847098f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc21c54a59f64bb183ec0af2c2a77152",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd3f3da062e447949514feb8aeae55a5",
            "value": 1
          }
        },
        "35d8a7b4c8e8480a855544e4d8b78a3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2aa82482dab04c2fae451850fd6e50b4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_97c9b9c3efa74d538c7318a82224f0dc",
            "value": "â€‡1000/0â€‡[00:37&lt;00:00,â€‡26.64â€‡examples/s]"
          }
        },
        "70c4948e459d4293924ff8dd4aec34fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c03c0feb188403892ed2726160a5b38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afcd21eeaeb84e3a95c39ad41d89249a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc21c54a59f64bb183ec0af2c2a77152": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "dd3f3da062e447949514feb8aeae55a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2aa82482dab04c2fae451850fd6e50b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97c9b9c3efa74d538c7318a82224f0dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c77ccf9fdca4696b4e89b9b1586beef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_908e2e7349b44d5a9af9c59816677cf3",
              "IPY_MODEL_d37ca6f611054470b42f0cb3d0a5e7ea",
              "IPY_MODEL_30ec3c7b1edf4dfbac81dd4170b9161a"
            ],
            "layout": "IPY_MODEL_a70808d4d638477f9cc417916cb22759"
          }
        },
        "908e2e7349b44d5a9af9c59816677cf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0118616952964f10b9cdc2fa1e7b7071",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c20f3a464af1464ebb32da11aef2a302",
            "value": "Map:â€‡100%"
          }
        },
        "d37ca6f611054470b42f0cb3d0a5e7ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4313254204b5444f9e7bc2672b4d4b23",
            "max": 6000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f23bb5eee7014c9581882e42ae6b10c2",
            "value": 6000
          }
        },
        "30ec3c7b1edf4dfbac81dd4170b9161a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_844b2f19833f46cabb9a7a89f3c2baeb",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6710d69b082a4e18b448b7fa5fe5f629",
            "value": "â€‡6000/6000â€‡[00:49&lt;00:00,â€‡123.70â€‡examples/s]"
          }
        },
        "a70808d4d638477f9cc417916cb22759": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0118616952964f10b9cdc2fa1e7b7071": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c20f3a464af1464ebb32da11aef2a302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4313254204b5444f9e7bc2672b4d4b23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f23bb5eee7014c9581882e42ae6b10c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "844b2f19833f46cabb9a7a89f3c2baeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6710d69b082a4e18b448b7fa5fe5f629": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc1a600c274a40a8b066d547ba043abc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7240dbd3f5f4df790b0b657736f1a6e",
              "IPY_MODEL_026597d8c212491f98ab9f6434723755",
              "IPY_MODEL_1131040efbd84d4badb9cc829cd4c3dd"
            ],
            "layout": "IPY_MODEL_fcff2761b9e64c699a87d73b375c9e18"
          }
        },
        "a7240dbd3f5f4df790b0b657736f1a6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_437bc5428ef646428e506ea30f222227",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9c30b489575e48d68512bf966d4538bb",
            "value": "Map:â€‡100%"
          }
        },
        "026597d8c212491f98ab9f6434723755": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_116a0970d373400ba3167df7e239bda5",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e574e3520afa4a6382db6a06963bc9e0",
            "value": 1000
          }
        },
        "1131040efbd84d4badb9cc829cd4c3dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b513d151df147d181ea0518f20fd29e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_880267d077234c0090de40c0a367146b",
            "value": "â€‡1000/1000â€‡[00:08&lt;00:00,â€‡123.51â€‡examples/s]"
          }
        },
        "fcff2761b9e64c699a87d73b375c9e18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "437bc5428ef646428e506ea30f222227": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c30b489575e48d68512bf966d4538bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "116a0970d373400ba3167df7e239bda5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e574e3520afa4a6382db6a06963bc9e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b513d151df147d181ea0518f20fd29e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "880267d077234c0090de40c0a367146b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b71b93375ca546b09fb658967b3ad8cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd0ea5d6cb5b49ecb8541767285d1918",
              "IPY_MODEL_103dee40e18240ec91aa773cefef4236",
              "IPY_MODEL_b46f927bd84e4eb39b7a73b6bdf2638a"
            ],
            "layout": "IPY_MODEL_5de358a1c55b4d83aa4146b2e559a2c8"
          }
        },
        "cd0ea5d6cb5b49ecb8541767285d1918": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_634f4e6abf9f4c1dac154b941686905f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f51e9f5533104be9ab68e7b8f34cd3ba",
            "value": "Map:â€‡100%"
          }
        },
        "103dee40e18240ec91aa773cefef4236": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46d605ebda1840c080804e26ae32d9cd",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_728ec47ca75e49d895c82be3c6d7fa44",
            "value": 1000
          }
        },
        "b46f927bd84e4eb39b7a73b6bdf2638a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24ba2f227eba4e2784924e6188a22046",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_804733ac73e64a6eb8f69a41b20385fd",
            "value": "â€‡1000/1000â€‡[00:08&lt;00:00,â€‡124.74â€‡examples/s]"
          }
        },
        "5de358a1c55b4d83aa4146b2e559a2c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "634f4e6abf9f4c1dac154b941686905f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f51e9f5533104be9ab68e7b8f34cd3ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46d605ebda1840c080804e26ae32d9cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "728ec47ca75e49d895c82be3c6d7fa44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24ba2f227eba4e2784924e6188a22046": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "804733ac73e64a6eb8f69a41b20385fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6f0ddf440e8450e8aa6336a32c93f7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3aff9eb968ef4492826dae5b8e6d6e49",
              "IPY_MODEL_6f12f7daf3244d3fb49b2778529c10b1",
              "IPY_MODEL_236aebf489844c7e934324cc368f0ea4"
            ],
            "layout": "IPY_MODEL_1b4d99e0c60d49259c1226e8768e503c"
          }
        },
        "3aff9eb968ef4492826dae5b8e6d6e49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e47710118e84d36bcc463d27472da80",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1060966bf06746b2bf7fcc3a17b04df1",
            "value": "Downloadingâ€‡builderâ€‡script:â€‡100%"
          }
        },
        "6f12f7daf3244d3fb49b2778529c10b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d594c8182904a6e982f5552ae7abcb1",
            "max": 6270,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf64e0a562834a37b93b3789dc4024db",
            "value": 6270
          }
        },
        "236aebf489844c7e934324cc368f0ea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e010864c7aad44dd976f49a8b3e8c24b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_97dd757227db47f89707b548eb2d38c7",
            "value": "â€‡6.27k/6.27kâ€‡[00:00&lt;00:00,â€‡480kB/s]"
          }
        },
        "1b4d99e0c60d49259c1226e8768e503c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e47710118e84d36bcc463d27472da80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1060966bf06746b2bf7fcc3a17b04df1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d594c8182904a6e982f5552ae7abcb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf64e0a562834a37b93b3789dc4024db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e010864c7aad44dd976f49a8b3e8c24b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97dd757227db47f89707b548eb2d38c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81a3480b1edb4613a52ed2dfdc628a69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0009a7e5976b457880641fd033ef467e",
              "IPY_MODEL_be227ba7950d49f29ff8861f1f80d138",
              "IPY_MODEL_f69f42d78dbc4b45bd577d77449b9e00"
            ],
            "layout": "IPY_MODEL_06e512261eb9469287820cae85074601"
          }
        },
        "0009a7e5976b457880641fd033ef467e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_755ae29629f54573b31d8699d9ea437e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3bd8768a6c6740ec97e59b0723e75142",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "be227ba7950d49f29ff8861f1f80d138": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_254c86ea12da48a1a7bc401e49390ab3",
            "max": 345579424,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23ee56dd8afc495f807854ae23f7db2a",
            "value": 345579424
          }
        },
        "f69f42d78dbc4b45bd577d77449b9e00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd28913cb80c4bc086402528479db476",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ad63e057b3a34c34963a03d52f7f9070",
            "value": "â€‡346M/346Mâ€‡[00:01&lt;00:00,â€‡348MB/s]"
          }
        },
        "06e512261eb9469287820cae85074601": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "755ae29629f54573b31d8699d9ea437e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bd8768a6c6740ec97e59b0723e75142": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "254c86ea12da48a1a7bc401e49390ab3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23ee56dd8afc495f807854ae23f7db2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd28913cb80c4bc086402528479db476": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad63e057b3a34c34963a03d52f7f9070": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc620d6023d84b30b29778a0c22d5ea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3e9074c48804f7b965e6ddf75bb6689",
              "IPY_MODEL_57398c42d91a4b218286ad6c3201e6d4",
              "IPY_MODEL_dc875ad0121849228a635412f9820947"
            ],
            "layout": "IPY_MODEL_f03caeac52ed4a96a7403fc5e18d1c4c"
          }
        },
        "e3e9074c48804f7b965e6ddf75bb6689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_959d8b0deae146cf9aece0adb1670e23",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_813021d9084b42e5ae6ed8e2a9ad5101",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "57398c42d91a4b218286ad6c3201e6d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a65a8d8ffe36409ca4036e300d56ea31",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0555dfa20b3346959b0fac52f60032f3",
            "value": 548105171
          }
        },
        "dc875ad0121849228a635412f9820947": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65244703ce564fba983ede9ac2c289e2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a2cca16549e5450fba32c27a0bafec40",
            "value": "â€‡548M/548Mâ€‡[00:02&lt;00:00,â€‡247MB/s]"
          }
        },
        "f03caeac52ed4a96a7403fc5e18d1c4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "959d8b0deae146cf9aece0adb1670e23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "813021d9084b42e5ae6ed8e2a9ad5101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a65a8d8ffe36409ca4036e300d56ea31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0555dfa20b3346959b0fac52f60032f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "65244703ce564fba983ede9ac2c289e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2cca16549e5450fba32c27a0bafec40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c44c0d78ad04b98b10155cb0303d06c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_564abac2c4c34394bb7079cca8d901db",
              "IPY_MODEL_feea1f5ed93442d0a9f96a5fb6790371",
              "IPY_MODEL_48dc2e4a7f144ff482e5422ab7c30fed"
            ],
            "layout": "IPY_MODEL_73c95f77bb8a44a6812aae9f1c8e8660"
          }
        },
        "564abac2c4c34394bb7079cca8d901db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60b41ffe0cfe45ea8354f02aa7a3d835",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0f9d77d1029c4f11ba819767a694f956",
            "value": "generation_config.json:â€‡100%"
          }
        },
        "feea1f5ed93442d0a9f96a5fb6790371": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd63f6387aa34ef5806b2b21f633a4f2",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba8b539d69d542c79fbb1be56bf60ea1",
            "value": 124
          }
        },
        "48dc2e4a7f144ff482e5422ab7c30fed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_538c20c0dfc34e4380aa2349c9e36125",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_287a5c89b77c4dc0ac10d25c70898863",
            "value": "â€‡124/124â€‡[00:00&lt;00:00,â€‡8.19kB/s]"
          }
        },
        "73c95f77bb8a44a6812aae9f1c8e8660": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60b41ffe0cfe45ea8354f02aa7a3d835": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f9d77d1029c4f11ba819767a694f956": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd63f6387aa34ef5806b2b21f633a4f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba8b539d69d542c79fbb1be56bf60ea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "538c20c0dfc34e4380aa2349c9e36125": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "287a5c89b77c4dc0ac10d25c70898863": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8346a9659944bc1a3109afb2aa2f87b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c48ce7cf38f54226b8e35c1789833d64",
              "IPY_MODEL_aaf79cdd42df4185abf020b5e85cc76b",
              "IPY_MODEL_7ac5b96c5a3c440aad5eb6758ba8deee"
            ],
            "layout": "IPY_MODEL_b7121f214a744050ae80fc24c55abb22"
          }
        },
        "c48ce7cf38f54226b8e35c1789833d64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_387b30bf21ed4b00ac797cfe707a607b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3e1a1c881bf94657bca5a56bee3bc852",
            "value": "preprocessor_config.json:â€‡100%"
          }
        },
        "aaf79cdd42df4185abf020b5e85cc76b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_564849fcfd2a44ae98bb20353cef71b1",
            "max": 160,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_922a0e13a12540fc8410fe8caa8e5f83",
            "value": 160
          }
        },
        "7ac5b96c5a3c440aad5eb6758ba8deee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_761fa8061df649368c9b2e091652af02",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1ad57d58fa62484a817266101d2e4d8f",
            "value": "â€‡160/160â€‡[00:00&lt;00:00,â€‡9.14kB/s]"
          }
        },
        "b7121f214a744050ae80fc24c55abb22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "387b30bf21ed4b00ac797cfe707a607b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e1a1c881bf94657bca5a56bee3bc852": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "564849fcfd2a44ae98bb20353cef71b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "922a0e13a12540fc8410fe8caa8e5f83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "761fa8061df649368c9b2e091652af02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ad57d58fa62484a817266101d2e4d8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e3693a08c0b42ff8e1a099ced150438": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_895400a9df9b47889683135da9cbf0b7",
              "IPY_MODEL_2e2416d3315d46a4a30917240872a349",
              "IPY_MODEL_130b39ba133640069ecd06d848dc629a"
            ],
            "layout": "IPY_MODEL_dfe71389b6c049b5b1db88d8d3a74fca"
          }
        },
        "895400a9df9b47889683135da9cbf0b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad62f344c44e43a18d93d153a93f0e60",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_854fdd49fd0141e285514bd68f061453",
            "value": "config.json:â€‡100%"
          }
        },
        "2e2416d3315d46a4a30917240872a349": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fc3423cd3174fc1951626d4bb2d64b9",
            "max": 502,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0cc7ffc991e242ed9551ecdd1b0527cc",
            "value": 502
          }
        },
        "130b39ba133640069ecd06d848dc629a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ae0dd9eb5834702b82b1a3a7a778b29",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d236a93f9a2746b8aeb41015ff7ef785",
            "value": "â€‡502/502â€‡[00:00&lt;00:00,â€‡30.2kB/s]"
          }
        },
        "dfe71389b6c049b5b1db88d8d3a74fca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad62f344c44e43a18d93d153a93f0e60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "854fdd49fd0141e285514bd68f061453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fc3423cd3174fc1951626d4bb2d64b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cc7ffc991e242ed9551ecdd1b0527cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ae0dd9eb5834702b82b1a3a7a778b29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d236a93f9a2746b8aeb41015ff7ef785": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86c2b76bd0a8465b8c9e052e5955e52d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_250c413a71164457be7d6c398ee63790",
              "IPY_MODEL_ca666bca40ed4fdca9d8e8a739484098",
              "IPY_MODEL_2de809244c3c4c36bdf9df2ae698f0dc"
            ],
            "layout": "IPY_MODEL_dbfb243092ed4a0eb41a56ed43d9f61d"
          }
        },
        "250c413a71164457be7d6c398ee63790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c2d874aaa3a4c0dac7aedd795be5204",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e2d9567aa8bd45829a69faa10002fb9a",
            "value": "tokenizer_config.json:â€‡100%"
          }
        },
        "ca666bca40ed4fdca9d8e8a739484098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_669cdd83fd65459496814ac4e52d8aac",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9155d02fb82a4e408ecff170a6073725",
            "value": 26
          }
        },
        "2de809244c3c4c36bdf9df2ae698f0dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45ac68c0175144ea903a65262007c53e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6859e3ae303d4d72abfa523d2094361f",
            "value": "â€‡26.0/26.0â€‡[00:00&lt;00:00,â€‡2.00kB/s]"
          }
        },
        "dbfb243092ed4a0eb41a56ed43d9f61d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c2d874aaa3a4c0dac7aedd795be5204": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2d9567aa8bd45829a69faa10002fb9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "669cdd83fd65459496814ac4e52d8aac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9155d02fb82a4e408ecff170a6073725": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45ac68c0175144ea903a65262007c53e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6859e3ae303d4d72abfa523d2094361f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b035b1eaafac40ec95395d4fd07dadff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d2b232290bc4edcb78f6c1ee3de10a6",
              "IPY_MODEL_b9b5c1d60f3c4aedbaa9f763ef97187a",
              "IPY_MODEL_d4729bebe2564e9e9a4de6f9bbe708c4"
            ],
            "layout": "IPY_MODEL_594d5188c145403c92467dd8dfba80ce"
          }
        },
        "5d2b232290bc4edcb78f6c1ee3de10a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4cb585e24a44e80aaceedd4798e56a8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3c5457fb7e22442b9bcb625a5b4e48c2",
            "value": "config.json:â€‡100%"
          }
        },
        "b9b5c1d60f3c4aedbaa9f763ef97187a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03196e9c428a4aee96369a74c16b71d0",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5dd0683d45744bdb830cc2d236ad14f2",
            "value": 665
          }
        },
        "d4729bebe2564e9e9a4de6f9bbe708c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_783a29d818d34a2190dfb937b0e7356d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_14ed875e175846f48860146fb7d04faf",
            "value": "â€‡665/665â€‡[00:00&lt;00:00,â€‡52.0kB/s]"
          }
        },
        "594d5188c145403c92467dd8dfba80ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4cb585e24a44e80aaceedd4798e56a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c5457fb7e22442b9bcb625a5b4e48c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03196e9c428a4aee96369a74c16b71d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dd0683d45744bdb830cc2d236ad14f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "783a29d818d34a2190dfb937b0e7356d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14ed875e175846f48860146fb7d04faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c95cfa17591425b98763db52d7770a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d41adc0bb5249e59c47e277f3c0121a",
              "IPY_MODEL_dbaaa4555377434ea8bb590a93a52acd",
              "IPY_MODEL_5196acf1b3f048309d8887d0edc3429c"
            ],
            "layout": "IPY_MODEL_c3352947e7b542c7b37ba0eba15047e5"
          }
        },
        "3d41adc0bb5249e59c47e277f3c0121a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f82535222764aaea4eca3a6419814c6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2def9644176041019d56971bb4874c13",
            "value": "vocab.json:â€‡100%"
          }
        },
        "dbaaa4555377434ea8bb590a93a52acd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02760ba510f74517a50d75c7983d85e2",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16d31b6b093f4cd781640bb283cc7a81",
            "value": 1042301
          }
        },
        "5196acf1b3f048309d8887d0edc3429c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_011794bb501b49e49cd842d178d63be0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1d2936e913f94f648f3c1a8b5a22dbfc",
            "value": "â€‡1.04M/1.04Mâ€‡[00:00&lt;00:00,â€‡4.93MB/s]"
          }
        },
        "c3352947e7b542c7b37ba0eba15047e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f82535222764aaea4eca3a6419814c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2def9644176041019d56971bb4874c13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02760ba510f74517a50d75c7983d85e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16d31b6b093f4cd781640bb283cc7a81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "011794bb501b49e49cd842d178d63be0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d2936e913f94f648f3c1a8b5a22dbfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "202c200dac944a8ea6d615bd12fed5f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3271b5281484b93a97ed2beaee68758",
              "IPY_MODEL_0d7b87708be447ffa6a3da6998477e01",
              "IPY_MODEL_33e9d1caa744492faeff219072d1e93a"
            ],
            "layout": "IPY_MODEL_2153a1422ee64cd891eff12df43633dc"
          }
        },
        "e3271b5281484b93a97ed2beaee68758": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46512ed135564a13aa2dd46c0887da72",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_eb46d7d76555484787c309d165272525",
            "value": "merges.txt:â€‡100%"
          }
        },
        "0d7b87708be447ffa6a3da6998477e01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36a83fa54d5242f6a670cbc4b967d826",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ba15d6cb64b4d5ea1892e76471fc63d",
            "value": 456318
          }
        },
        "33e9d1caa744492faeff219072d1e93a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2df751346f046a393d4a4e472d9a7af",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_12cc5252fc324bea8503dd08fbf7ad43",
            "value": "â€‡456k/456kâ€‡[00:00&lt;00:00,â€‡716kB/s]"
          }
        },
        "2153a1422ee64cd891eff12df43633dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46512ed135564a13aa2dd46c0887da72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb46d7d76555484787c309d165272525": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36a83fa54d5242f6a670cbc4b967d826": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ba15d6cb64b4d5ea1892e76471fc63d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2df751346f046a393d4a4e472d9a7af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12cc5252fc324bea8503dd08fbf7ad43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e374fa9ba7ae4ffda8dba6049a0ad69f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b8e0b5596566460490984c23577a8bd1",
              "IPY_MODEL_8a0dd7d0321d47f2ac93aa6dc4df6cd4",
              "IPY_MODEL_4a1dbf3f888e423ab18098076d744c7e"
            ],
            "layout": "IPY_MODEL_7a7f73b776cd49ad98bb52b8a1c79387"
          }
        },
        "b8e0b5596566460490984c23577a8bd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52e0375031cf4991862ebfa9ca2cf71a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a5414aed27e443bca080dbba144b6845",
            "value": "tokenizer.json:â€‡100%"
          }
        },
        "8a0dd7d0321d47f2ac93aa6dc4df6cd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3f52c910f3a4350b71e79b3f9dbe99a",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c50b215b94941f7b042616373cc792b",
            "value": 1355256
          }
        },
        "4a1dbf3f888e423ab18098076d744c7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bc5b9b157f94590a08d7e9878a2fcae",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1073aaa758454612a4bcf15b0d0cbc3f",
            "value": "â€‡1.36M/1.36Mâ€‡[00:00&lt;00:00,â€‡3.15MB/s]"
          }
        },
        "7a7f73b776cd49ad98bb52b8a1c79387": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52e0375031cf4991862ebfa9ca2cf71a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5414aed27e443bca080dbba144b6845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3f52c910f3a4350b71e79b3f9dbe99a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c50b215b94941f7b042616373cc792b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0bc5b9b157f94590a08d7e9878a2fcae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1073aaa758454612a4bcf15b0d0cbc3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}